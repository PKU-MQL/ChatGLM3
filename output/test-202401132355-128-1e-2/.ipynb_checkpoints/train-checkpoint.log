[2024-01-14 00:00:52,456] torch.distributed.run: [WARNING] master_addr is only used for static rdzv_backend and when rdzv_endpoint is not specified.
2024-01-14 00:00:55.429402: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-01-14 00:00:55.475840: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-01-14 00:00:55.475879: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-01-14 00:00:55.475903: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-01-14 00:00:55.484676: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.
2024-01-14 00:00:55.484947: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-01-14 00:00:56.578435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
01/14/2024 00:01:01 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
01/14/2024 00:01:01 - INFO - __main__ - Training/evaluation parameters Seq2SeqTrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=0,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=False,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=False,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=no,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
generation_config=None,
generation_max_length=None,
generation_num_beams=None,
gradient_accumulation_steps=16,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=None,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=0.01,
length_column_name=length,
load_best_model_at_end=False,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=output/test-202401132355-128-1e-2/runs/Jan14_00-00-59_dsw-305162-bfbfdc4c5-m6whp,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=1.0,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=500,
metric_for_best_model=None,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=3.0,
optim=adamw_torch,
optim_args=None,
output_dir=output/test-202401132355-128-1e-2,
overwrite_output_dir=False,
past_index=-1,
per_device_eval_batch_size=8,
per_device_train_batch_size=1,
predict_with_generate=False,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=True,
report_to=['tensorboard'],
resume_from_checkpoint=True,
run_name=output/test-202401132355-128-1e-2,
save_on_each_node=False,
save_only_model=False,
save_safetensors=False,
save_steps=100,
save_strategy=steps,
save_total_limit=None,
seed=42,
skip_memory_metrics=True,
sortish_sampler=False,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.0,
warmup_steps=0,
weight_decay=0.0,
)
[INFO|configuration_utils.py:737] 2024-01-14 00:01:01,421 >> loading configuration file /mnt/workspace/.cache/modelscope/ZhipuAI/chatglm3-6b/config.json
[INFO|configuration_utils.py:737] 2024-01-14 00:01:01,424 >> loading configuration file /mnt/workspace/.cache/modelscope/ZhipuAI/chatglm3-6b/config.json
[INFO|configuration_utils.py:802] 2024-01-14 00:01:01,425 >> Model config ChatGLMConfig {
  "_name_or_path": "/mnt/workspace/.cache/modelscope/ZhipuAI/chatglm3-6b",
  "add_bias_linear": false,
  "add_qkv_bias": true,
  "apply_query_key_layer_scaling": true,
  "apply_residual_connection_post_layernorm": false,
  "architectures": [
    "ChatGLMModel"
  ],
  "attention_dropout": 0.0,
  "attention_softmax_in_fp32": true,
  "auto_map": {
    "AutoConfig": "configuration_chatglm.ChatGLMConfig",
    "AutoModel": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForCausalLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSeq2SeqLM": "modeling_chatglm.ChatGLMForConditionalGeneration",
    "AutoModelForSequenceClassification": "modeling_chatglm.ChatGLMForSequenceClassification"
  },
  "bias_dropout_fusion": true,
  "classifier_dropout": null,
  "eos_token_id": 2,
  "ffn_hidden_size": 13696,
  "fp32_residual_connection": false,
  "hidden_dropout": 0.0,
  "hidden_size": 4096,
  "kv_channels": 128,
  "layernorm_epsilon": 1e-05,
  "model_type": "chatglm",
  "multi_query_attention": true,
  "multi_query_group_num": 2,
  "num_attention_heads": 32,
  "num_layers": 28,
  "original_rope": true,
  "pad_token_id": 0,
  "padded_vocab_size": 65024,
  "post_layer_norm": true,
  "pre_seq_len": null,
  "prefix_projection": false,
  "quantization_bit": 0,
  "rmsnorm": true,
  "seq_length": 8192,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.36.2",
  "use_cache": true,
  "vocab_size": 65024
}

[INFO|tokenization_utils_base.py:2024] 2024-01-14 00:01:01,428 >> loading file tokenizer.model
[INFO|tokenization_utils_base.py:2024] 2024-01-14 00:01:01,428 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2024] 2024-01-14 00:01:01,428 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2024] 2024-01-14 00:01:01,428 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2024] 2024-01-14 00:01:01,428 >> loading file tokenizer.json
[INFO|modeling_utils.py:3341] 2024-01-14 00:01:01,743 >> loading weights file /mnt/workspace/.cache/modelscope/ZhipuAI/chatglm3-6b/pytorch_model.bin.index.json
[INFO|configuration_utils.py:826] 2024-01-14 00:01:01,744 >> Generate config GenerationConfig {
  "eos_token_id": 2,
  "pad_token_id": 0,
  "use_cache": false
}

Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:11,  1.84s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:03<00:09,  1.96s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:05<00:07,  1.97s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:07<00:05,  1.95s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:09<00:03,  1.99s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:11<00:02,  2.01s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:13<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:13<00:00,  1.89s/it]
[INFO|modeling_utils.py:4185] 2024-01-14 00:01:15,002 >> All model checkpoint weights were used when initializing ChatGLMForConditionalGeneration.

[WARNING|modeling_utils.py:4187] 2024-01-14 00:01:15,002 >> Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at /mnt/workspace/.cache/modelscope/ZhipuAI/chatglm3-6b and are newly initialized: ['transformer.prefix_encoder.embedding.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
[INFO|modeling_utils.py:3751] 2024-01-14 00:01:15,004 >> Generation config file not found, using a generation config created from the model config.
Sanity Check >>>>>>>>>>>>>
           '[gMASK]':  64790 ->   -100
               'sop':  64792 ->   -100
        '<|system|>':  64794 ->   -100
                  '':  30910 ->   -100
                '\n':     13 ->   -100
                  '':  30910 ->   -100
                '背景':  32797 ->   -100
                '知识':  31848 ->   -100
                 '：':  31211 ->   -100
                '查询':  34262 ->   -100
                '会给':  44185 ->   -100
                 '定':  54621 ->   -100
                '一个':  31623 ->   -100
                 'x':  30948 ->   -100
                'ls':   7463 ->   -100
                 'x':  30948 ->   -100
               '文件的':  52483 ->   -100
                '路径':  35816 ->   -100
                 '，':  31123 ->   -100
                '包含':  33302 ->   -100
                 '的':  54530 ->   -100
                 '各':  54752 ->   -100
                 '张':  54940 ->   -100
                '工作':  31624 ->   -100
                 '表':  54670 ->   -100
             'sheet':  20352 ->   -100
                 '的':  54530 ->   -100
                '名称':  33624 ->   -100
                 '，':  31123 ->   -100
                '数据':  31786 ->   -100
                 '列':  55065 ->   -100
                 '名':  54653 ->   -100
                 '从':  54708 ->   -100
                 '第':  54616 ->   -100
                 '几':  55013 ->   -100
                 '行':  54560 ->   -100
                '开始':  31699 ->   -100
                 '，':  31123 ->   -100
                '行列':  42559 ->   -100
               '有哪些':  34953 ->   -100
                '属性':  37027 ->   -100
                 '，':  31123 ->   -100
                 '请':  55073 ->   -100
                '根据':  31793 ->   -100
               '下面的':  42603 ->   -100
                '查询':  34262 ->   -100
                '要求':  31696 ->   -100
                 '，':  31123 ->   -100
                '输出':  35898 ->   -100
                '格式':  36844 ->   -100
                 '和':  54542 ->   -100
                '结果':  31951 ->   -100
               '正确的':  34897 ->   -100
                 '可':  54568 ->   -100
                '执行':  32101 ->   -100
            'python':  23720 ->   -100
                '代码':  35089 ->   -100
          '<|user|>':  64795 ->   -100
                  '':  30910 ->   -100
                '\n':     13 ->   -100
                 '.':    918 ->   -100
                 '/':  30967 ->   -100
              'file':   3743 ->   -100
                 '/':  30967 ->   -100
                '民用':  41801 ->   -100
                '汽车':  32031 ->   -100
                '拥有':  32104 ->   -100
                 '量':  54698 ->   -100
                '汇总':  39060 ->   -100
                 '.':  30930 ->   -100
                 'x':  30948 ->   -100
                'ls':   7463 ->   -100
                 'x':  30948 ->   -100
                '文件':  32410 ->   -100
                 '中':  54538 ->   -100
                '文件':  32410 ->   -100
                '中共':  32601 ->   -100
                 '有':  54536 ->   -100
                 '4':  30972 ->   -100
                 '个':  54550 ->   -100
               '独立的':  41082 ->   -100
             'sheet':  20352 ->   -100
                 '，':  31123 ->   -100
               '分别为':  35222 ->   -100
                 '“':  30989 ->   -100
                '民用':  41801 ->   -100
                '汽车':  32031 ->   -100
                '拥有':  32104 ->   -100
                 '量':  54698 ->   -100
                '汇总':  39060 ->   -100
               '”、“':  32442 ->   -100
                '民用':  41801 ->   -100
                 '载':  55387 ->   -100
                 '货':  55466 ->   -100
               '”、“':  32442 ->   -100
                '民用':  41801 ->   -100
                 '载':  55387 ->   -100
                 '客':  54992 ->   -100
               '”、“':  32442 ->   -100
                '民用':  41801 ->   -100
                '其他':  31722 ->   -100
               '”。“':  41969 ->   -100
                '民用':  41801 ->   -100
                '汽车':  32031 ->   -100
                '拥有':  32104 ->   -100
                 '量':  54698 ->   -100
                '汇总':  39060 ->   -100
                 '”':  30991 ->   -100
                 '的':  54530 ->   -100
                 '列':  55065 ->   -100
                 '名':  54653 ->   -100
                 '从':  54708 ->   -100
                 '第':  54616 ->   -100
                 '5':  30970 ->   -100
                 '行':  54560 ->   -100
                '开始':  31699 ->   -100
                '，“':  31771 ->   -100
                '民用':  41801 ->   -100
                 '载':  55387 ->   -100
                 '货':  55466 ->   -100
               '”、“':  32442 ->   -100
                '民用':  41801 ->   -100
                 '载':  55387 ->   -100
                 '客':  54992 ->   -100
                 '”':  30991 ->   -100
                 '的':  54530 ->   -100
                 '列':  55065 ->   -100
                 '名':  54653 ->   -100
                 '从':  54708 ->   -100
                 '第':  54616 ->   -100
                 '4':  30972 ->   -100
                 '行':  54560 ->   -100
                '开始':  31699 ->   -100
                 '，':  31123 ->   -100
                 '列':  55065 ->   -100
                 '名':  54653 ->   -100
                 '有':  54536 ->   -100
                '省份':  38063 ->   -100
                 '、':  31201 ->   -100
                 '2':  30943 ->   -100
                 '0':  30940 ->   -100
                 '0':  30940 ->   -100
                 '2':  30943 ->   -100
                 '年':  54540 ->   -100
                 '、':  31201 ->   -100
                 '2':  30943 ->   -100
                 '0':  30940 ->   -100
                 '0':  30940 ->   -100
                 '3':  30966 ->   -100
                 '年':  54540 ->   -100
                '……':   6512 ->   -100
               '一直到':  44188 ->   -100
                 '2':  30943 ->   -100
                 '0':  30940 ->   -100
                 '2':  30943 ->   -100
                 '0':  30940 ->   -100
                 '年':  54540 ->   -100
                 '等':  54609 ->   -100
                 '项':  54794 ->   -100
                 '，':  31123 ->   -100
               '不存在':  39974 ->   -100
                '汇总':  39060 ->   -100
                '各个':  33402 ->   -100
                '省份':  38063 ->   -100
                 '的':  54530 ->   -100
                '全国':  31742 ->   -100
                 '项':  54794 ->   -100
                 '。':  31155 ->   -100
                '单位':  31790 ->   -100
                 '为':  54541 ->   -100
                '万辆':  40453 ->   -100
                 '，':  31123 ->   -100
                 '请':  55073 ->   -100
                '查询':  34262 ->   -100
                 '2':  30943 ->   -100
                 '0':  30940 ->   -100
                 '2':  30943 ->   -100
                 '0':  30940 ->   -100
                 '年':  54540 ->   -100
                 '，':  31123 ->   -100
                '北京':  31719 ->   -100
                 '和':  54542 ->   -100
               '上海的':  48750 ->   -100
                '民用':  41801 ->   -100
                '汽车':  32031 ->   -100
                '拥有':  32104 ->   -100
                 '量':  54698 ->   -100
               '分别是':  36733 ->   -100
                '多少':  32326 ->   -100
                 '？':  31514 ->   -100
     '<|assistant|>':  64796 ->   -100
                  '':  30910 ->  30910
                '\n':     13 ->     13
            'import':    937 ->    937
              'pand':  12833 ->  12833
                'as':    298 ->    298
                'as':    362 ->    362
                'pd':  23382 ->  23382
                '\n':     13 ->     13
            'import':  12787 ->  12787
             'numpy':  22215 ->  22215
                'as':    362 ->    362
                'np':   8036 ->   8036
                '\n':     13 ->     13
              'file':   3743 ->   3743
                 '_':  30962 ->  30962
              'path':   3295 ->   3295
                 '=':  30980 ->  30980
                "'.":   6263 ->   6263
                 '/':  30967 ->  30967
              'file':   3743 ->   3743
                 '/':  30967 ->  30967
                '民用':  41801 ->  41801
                '汽车':  32031 ->  32031
                '拥有':  32104 ->  32104
                 '量':  54698 ->  54698
                '汇总':  39060 ->  39060
                 '.':  30930 ->  30930
                 'x':  30948 ->  30948
                'ls':   7463 ->   7463
                 'x':  30948 ->  30948
                 "'":  30953 ->  30953
                '\n':     13 ->     13
              'data':   1166 ->   1166
                 '=':    542 ->    542
                'pd':  23382 ->  23382
                 '.':  30930 ->  30930
              'read':   1042 ->   1042
                 '_':  30962 ->  30962
                'ex':    914 ->    914
               'cel':   4397 ->   4397
                 '(':  30946 ->  30946
              'file':   3743 ->   3743
                 '_':  30962 ->  30962
              'path':   3295 ->   3295
                 ',':  30932 ->  30932
             'sheet':   8791 ->   8791
                 '_':  30962 ->  30962
              'name':   2323 ->   2323
                "='":   6521 ->   6521
                '民用':  41801 ->  41801
                '汽车':  32031 ->  32031
                '拥有':  32104 ->  32104
                 '量':  54698 ->  54698
                '汇总':  39060 ->  39060
                "',":   1589 ->   1589
            'engine':   2809 ->   2809
                "='":   6521 ->   6521
              'open':   7237 ->   7237
                'py':   6433 ->   6433
                 'x':  30948 ->  30948
                 'l':  30920 ->  30920
                "',":   1589 ->   1589
            'header':  12990 ->  12990
                 '=':  30980 ->  30980
                 '4':  30972 ->  30972
                 ')':  30945 ->  30945
                 ' ':    265 ->    265
                 '#':  31010 ->  31010
                 '从':  37708 ->  37708
                '第五':  32771 ->  32771
                 '行':  54560 ->  54560
                '开始':  31699 ->  31699
                 '读':  55116 ->  55116
                 '取':  54891 ->  54891
                '数据':  31786 ->  31786
                '\n':     13 ->     13
                 '#':  31010 ->  31010
                 '要':  43159 ->  43159
                '查询':  34262 ->  34262
               '的城市':  36226 ->  36226
                 '和':  54542 ->  54542
                '年份':  43489 ->  43489
                '\n':     13 ->     13
              'city':  17654 ->  17654
                 '_':  30962 ->  30962
                 '1':  30939 ->  30939
                 '=':    542 ->    542
                 "'":    765 ->    765
                '北京':  31719 ->  31719
                 "'":  30953 ->  30953
                 ' ':    265 ->    265
                 '#':  31010 ->  31010
                  '':  30910 ->  30910
              '可以根据':  43909 ->  43909
                '需要':  31665 ->  31665
                '修改':  33608 ->  33608
                 '为':  54541 ->  54541
                '其他':  31722 ->  31722
                '城市':  31733 ->  31733
                '\n':     13 ->     13
              'city':  17654 ->  17654
                 '_':  30962 ->  30962
                 '2':  30943 ->  30943
                 '=':    542 ->    542
                 "'":    765 ->    765
                '上海':  31770 ->  31770
                 "'":  30953 ->  30953
                 ' ':    265 ->    265
                 '#':  31010 ->  31010
                  '':  30910 ->  30910
              '可以根据':  43909 ->  43909
                '需要':  31665 ->  31665
                '修改':  33608 ->  33608
                 '为':  54541 ->  54541
                '其他':  31722 ->  31722
                '城市':  31733 ->  31733
                '\n':     13 ->     13
              'year':   2475 ->   2475
                 '_':  30962 ->  30962
                'to':   1143 ->   1143
                 '_':  30962 ->  30962
             'check':   7170 ->   7170
                 '=':    542 ->    542
                 "'":    765 ->    765
                 '2':  30943 ->  30943
                 '0':  30940 ->  30940
                 '2':  30943 ->  30943
                 '0':  30940 ->  30940
                 "'":  30953 ->  30953
                 ' ':    265 ->    265
                 '#':  31010 ->  31010
                  '':  30910 ->  30910
              '可以根据':  43909 ->  43909
                '需要':  31665 ->  31665
                '修改':  33608 ->  33608
                 '为':  54541 ->  54541
                '其他':  31722 ->  31722
                '年份':  43489 ->  43489
                '\n':     13 ->     13
                 '#':  31010 ->  31010
                  '':  30910 ->  30910
                '获取':  34073 ->  34073
                '特定':  35743 ->  35743
                '城市':  31733 ->  31733
                 '在':  54534 ->  54534
                '特定':  35743 ->  35743
                '年份':  43489 ->  43489
                 '的':  54530 ->  54530
                '民用':  41801 ->  41801
                '汽车':  32031 ->  32031
                '拥有':  32104 ->  32104
                 '量':  54698 ->  54698
                '\n':     13 ->     13
               'car':   6747 ->   6747
                 '_':  30962 ->  30962
             'count':   5597 ->   5597
                 '_':  30962 ->  30962
              'city':  17654 ->  17654
                 '_':  30962 ->  30962
                 '1':  30939 ->  30939
                 '=':    542 ->    542
              'data':   1166 ->   1166
                 '.':  30930 ->  30930
               'loc':  12687 ->  12687
                 '[':  30995 ->  30995
              'data':   2899 ->   2899
                "['":   4005 ->   4005
                '省份':  38063 ->  38063
                "']":   4960 ->   4960
                '==':   2731 ->   2731
              'city':   1911 ->   1911
                 '_':  30962 ->  30962
                 '1':  30939 ->  30939
                 ',':  30932 ->  30932
                 'f':    279 ->    279
                 "'":  30953 ->  30953
                 '{':  30982 ->  30982
              'year':   2475 ->   2475
                 '_':  30962 ->  30962
                'to':   1143 ->   1143
                 '_':  30962 ->  30962
             'check':   7170 ->   7170
                 '}':  30983 ->  30983
                 '年':  54540 ->  54540
               "'].":  28380 ->  28380
            'values':  12297 ->  12297
                 '[':  30995 ->  30995
                 '0':  30940 ->  30940
                 ']':  30996 ->  30996
                '\n':     13 ->     13
               'car':   6747 ->   6747
                 '_':  30962 ->  30962
             'count':   5597 ->   5597
                 '_':  30962 ->  30962
              'city':  17654 ->  17654
                 '_':  30962 ->  30962
                 '2':  30943 ->  30943
                 '=':    542 ->    542
              'data':   1166 ->   1166
                 '.':  30930 ->  30930
               'loc':  12687 ->  12687
                 '[':  30995 ->  30995
              'data':   2899 ->   2899
                "['":   4005 ->   4005
                '省份':  38063 ->  38063
                "']":   4960 ->   4960
                '==':   2731 ->   2731
              'city':   1911 ->   1911
                 '_':  30962 ->  30962
                 '2':  30943 ->  30943
                 ',':  30932 ->  30932
                 'f':    279 ->    279
                 "'":  30953 ->  30953
                 '{':  30982 ->  30982
              'year':   2475 ->   2475
                 '_':  30962 ->  30962
                'to':   1143 ->   1143
                 '_':  30962 ->  30962
             'check':   7170 ->   7170
                 '}':  30983 ->  30983
                 '年':  54540 ->  54540
               "'].":  28380 ->  28380
            'values':  12297 ->  12297
                 '[':  30995 ->  30995
                 '0':  30940 ->  30940
                 ']':  30996 ->  30996
                '\n':     13 ->     13
             'print':   4466 ->   4466
                 '(':  30946 ->  30946
                 'f':  30926 ->  30926
                 '"':  30955 ->  30955
                 '{':  30982 ->  30982
              'year':   2475 ->   2475
                 '_':  30962 ->  30962
                'to':   1143 ->   1143
                 '_':  30962 ->  30962
             'check':   7170 ->   7170
                 '}':  30983 ->  30983
                 '年':  54540 ->  54540
                 '，':  31123 ->  31123
                 '{':  30982 ->  30982
              'city':  17654 ->  17654
                 '_':  30962 ->  30962
                 '1':  30939 ->  30939
                 '}':  30983 ->  30983
                 '的':  54530 ->  54530
                '民用':  41801 ->  41801
                '汽车':  32031 ->  32031
                '拥有':  32104 ->  32104
                '量为':  44368 ->  44368
                 '：':  31211 ->  31211
                 '{':  30982 ->  30982
               'car':   6747 ->   6747
                 '_':  30962 ->  30962
             'count':   5597 ->   5597
                 '_':  30962 ->  30962
              'city':  17654 ->  17654
                 '_':  30962 ->  30962
                 '1':  30939 ->  30939
                 '}':  30983 ->  30983
                 '万':  38981 ->  38981
                 '辆':  55793 ->  55793
                '")':   2479 ->   2479
                '\n':     13 ->     13
             'print':   4466 ->   4466
                 '(':  30946 ->  30946
                 'f':  30926 ->  30926
                 '"':  30955 ->  30955
                 '{':  30982 ->  30982
              'year':   2475 ->   2475
                 '_':  30962 ->  30962
                'to':   1143 ->   1143
                 '_':  30962 ->  30962
             'check':   7170 ->   7170
                 '}':  30983 ->  30983
                 '年':  54540 ->  54540
                 '，':  31123 ->  31123
                 '{':  30982 ->  30982
              'city':  17654 ->  17654
                 '_':  30962 ->  30962
                 '2':  30943 ->  30943
                 '}':  30983 ->  30983
                 '的':  54530 ->  54530
                '民用':  41801 ->  41801
                '汽车':  32031 ->  32031
                '拥有':  32104 ->  32104
                '量为':  44368 ->  44368
                 '：':  31211 ->  31211
                 '{':  30982 ->  30982
               'car':   6747 ->   6747
                 '_':  30962 ->  30962
             'count':   5597 ->   5597
                 '_':  30962 ->  30962
              'city':  17654 ->  17654
                 '_':  30962 ->  30962
                 '2':  30943 ->  30943
                 '}':  30983 ->  30983
                 '万':  38981 ->  38981
                 '辆':  55793 ->  55793
                '")':   2479 ->   2479
                  '':      2 ->      2
<<<<<<<<<<<<< Sanity Check
01/14/2024 00:01:15 - WARNING - accelerate.utils.other - Detected kernel version 4.19.24, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:519] 2024-01-14 00:01:19,709 >> max_steps is given, it will override any value given in num_train_epochs
[WARNING|modeling_utils.py:2045] 2024-01-14 00:01:19,710 >> You are using an old version of the checkpointing format that is deprecated (We will also silently ignore `gradient_checkpointing_kwargs` in case you passed it).Please update to the new format on your modeling file. To use the new format, you need to completely remove the definition of the method `_set_gradient_checkpointing` in your model.
[INFO|trainer.py:1706] 2024-01-14 00:01:20,245 >> ***** Running training *****
[INFO|trainer.py:1707] 2024-01-14 00:01:20,245 >>   Num examples = 210
[INFO|trainer.py:1708] 2024-01-14 00:01:20,245 >>   Num Epochs = 39
[INFO|trainer.py:1709] 2024-01-14 00:01:20,245 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:1712] 2024-01-14 00:01:20,245 >>   Total train batch size (w. parallel, distributed & accumulation) = 16
[INFO|trainer.py:1713] 2024-01-14 00:01:20,245 >>   Gradient Accumulation steps = 16
[INFO|trainer.py:1714] 2024-01-14 00:01:20,245 >>   Total optimization steps = 500
[INFO|trainer.py:1715] 2024-01-14 00:01:20,246 >>   Number of trainable parameters = 1,835,008
  0%|          | 0/500 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 1/500 [00:11<1:35:48, 11.52s/it]                                                 {'loss': 1.3438, 'learning_rate': 0.009980000000000001, 'epoch': 0.08}
  0%|          | 1/500 [00:11<1:35:48, 11.52s/it]  0%|          | 2/500 [00:21<1:29:05, 10.73s/it]                                                 {'loss': 1.3173, 'learning_rate': 0.00996, 'epoch': 0.15}
  0%|          | 2/500 [00:21<1:29:05, 10.73s/it]  1%|          | 3/500 [00:31<1:27:06, 10.52s/it]                                                 {'loss': 1.1197, 'learning_rate': 0.009940000000000001, 'epoch': 0.23}
  1%|          | 3/500 [00:31<1:27:06, 10.52s/it]  1%|          | 4/500 [00:42<1:26:14, 10.43s/it]                                                 {'loss': 1.1328, 'learning_rate': 0.00992, 'epoch': 0.3}
  1%|          | 4/500 [00:42<1:26:14, 10.43s/it]  1%|          | 5/500 [00:52<1:25:40, 10.38s/it]                                                 {'loss': 1.2343, 'learning_rate': 0.0099, 'epoch': 0.38}
  1%|          | 5/500 [00:52<1:25:40, 10.38s/it]  1%|          | 6/500 [01:02<1:25:20, 10.37s/it]                                                 {'loss': 1.1754, 'learning_rate': 0.00988, 'epoch': 0.46}
  1%|          | 6/500 [01:02<1:25:20, 10.37s/it]  1%|▏         | 7/500 [01:13<1:25:09, 10.36s/it]                                                 {'loss': 1.1226, 'learning_rate': 0.00986, 'epoch': 0.53}
  1%|▏         | 7/500 [01:13<1:25:09, 10.36s/it]  2%|▏         | 8/500 [01:23<1:24:53, 10.35s/it]                                                 {'loss': 1.0839, 'learning_rate': 0.00984, 'epoch': 0.61}
  2%|▏         | 8/500 [01:23<1:24:53, 10.35s/it]  2%|▏         | 9/500 [01:33<1:24:38, 10.34s/it]                                                 {'loss': 1.0497, 'learning_rate': 0.00982, 'epoch': 0.69}
  2%|▏         | 9/500 [01:33<1:24:38, 10.34s/it]  2%|▏         | 10/500 [01:44<1:24:28, 10.34s/it]                                                  {'loss': 0.9764, 'learning_rate': 0.0098, 'epoch': 0.76}
  2%|▏         | 10/500 [01:44<1:24:28, 10.34s/it]  2%|▏         | 11/500 [01:54<1:24:19, 10.35s/it]                                                  {'loss': 0.988, 'learning_rate': 0.00978, 'epoch': 0.84}
  2%|▏         | 11/500 [01:54<1:24:19, 10.35s/it]  2%|▏         | 12/500 [02:04<1:24:06, 10.34s/it]                                                  {'loss': 0.9867, 'learning_rate': 0.00976, 'epoch': 0.91}
  2%|▏         | 12/500 [02:04<1:24:06, 10.34s/it]  3%|▎         | 13/500 [02:15<1:24:01, 10.35s/it]                                                  {'loss': 1.11, 'learning_rate': 0.00974, 'epoch': 0.99}
  3%|▎         | 13/500 [02:15<1:24:01, 10.35s/it]  3%|▎         | 14/500 [02:25<1:23:56, 10.36s/it]                                                  {'loss': 0.979, 'learning_rate': 0.00972, 'epoch': 1.07}
  3%|▎         | 14/500 [02:25<1:23:56, 10.36s/it]  3%|▎         | 15/500 [02:36<1:23:48, 10.37s/it]                                                  {'loss': 0.8116, 'learning_rate': 0.0097, 'epoch': 1.14}
  3%|▎         | 15/500 [02:36<1:23:48, 10.37s/it]  3%|▎         | 16/500 [02:46<1:23:40, 10.37s/it]                                                  {'loss': 0.868, 'learning_rate': 0.00968, 'epoch': 1.22}
  3%|▎         | 16/500 [02:46<1:23:40, 10.37s/it]  3%|▎         | 17/500 [02:56<1:23:30, 10.37s/it]                                                  {'loss': 0.8417, 'learning_rate': 0.00966, 'epoch': 1.3}
  3%|▎         | 17/500 [02:56<1:23:30, 10.37s/it]  4%|▎         | 18/500 [03:07<1:23:16, 10.37s/it]                                                  {'loss': 0.9575, 'learning_rate': 0.00964, 'epoch': 1.37}
  4%|▎         | 18/500 [03:07<1:23:16, 10.37s/it]  4%|▍         | 19/500 [03:17<1:23:10, 10.38s/it]                                                  {'loss': 0.9228, 'learning_rate': 0.00962, 'epoch': 1.45}
  4%|▍         | 19/500 [03:17<1:23:10, 10.38s/it]  4%|▍         | 20/500 [03:27<1:22:57, 10.37s/it]                                                  {'loss': 0.9866, 'learning_rate': 0.0096, 'epoch': 1.52}
  4%|▍         | 20/500 [03:27<1:22:57, 10.37s/it]  4%|▍         | 21/500 [03:38<1:22:45, 10.37s/it]                                                  {'loss': 0.9213, 'learning_rate': 0.00958, 'epoch': 1.6}
  4%|▍         | 21/500 [03:38<1:22:45, 10.37s/it]  4%|▍         | 22/500 [03:48<1:22:36, 10.37s/it]                                                  {'loss': 0.783, 'learning_rate': 0.009559999999999999, 'epoch': 1.68}
  4%|▍         | 22/500 [03:48<1:22:36, 10.37s/it]  5%|▍         | 23/500 [03:59<1:22:26, 10.37s/it]                                                  {'loss': 0.8888, 'learning_rate': 0.00954, 'epoch': 1.75}
  5%|▍         | 23/500 [03:59<1:22:26, 10.37s/it]  5%|▍         | 24/500 [04:09<1:22:13, 10.36s/it]                                                  {'loss': 0.8792, 'learning_rate': 0.009519999999999999, 'epoch': 1.83}
  5%|▍         | 24/500 [04:09<1:22:13, 10.36s/it]  5%|▌         | 25/500 [04:19<1:22:04, 10.37s/it]                                                  {'loss': 0.8625, 'learning_rate': 0.0095, 'epoch': 1.9}
  5%|▌         | 25/500 [04:19<1:22:04, 10.37s/it]  5%|▌         | 26/500 [04:30<1:21:56, 10.37s/it]                                                  {'loss': 0.7648, 'learning_rate': 0.00948, 'epoch': 1.98}
  5%|▌         | 26/500 [04:30<1:21:56, 10.37s/it]  5%|▌         | 27/500 [04:40<1:21:44, 10.37s/it]                                                  {'loss': 0.8282, 'learning_rate': 0.00946, 'epoch': 2.06}
  5%|▌         | 27/500 [04:40<1:21:44, 10.37s/it]  6%|▌         | 28/500 [04:50<1:21:36, 10.37s/it]                                                  {'loss': 0.7382, 'learning_rate': 0.00944, 'epoch': 2.13}
  6%|▌         | 28/500 [04:50<1:21:36, 10.37s/it]  6%|▌         | 29/500 [05:01<1:21:24, 10.37s/it]                                                  {'loss': 0.7784, 'learning_rate': 0.00942, 'epoch': 2.21}
  6%|▌         | 29/500 [05:01<1:21:24, 10.37s/it]  6%|▌         | 30/500 [05:11<1:21:11, 10.36s/it]                                                  {'loss': 0.7722, 'learning_rate': 0.0094, 'epoch': 2.29}
  6%|▌         | 30/500 [05:11<1:21:11, 10.36s/it]  6%|▌         | 31/500 [05:21<1:21:01, 10.37s/it]                                                  {'loss': 0.8201, 'learning_rate': 0.00938, 'epoch': 2.36}
  6%|▌         | 31/500 [05:21<1:21:01, 10.37s/it]  6%|▋         | 32/500 [05:32<1:20:56, 10.38s/it]                                                  {'loss': 0.8628, 'learning_rate': 0.00936, 'epoch': 2.44}
  6%|▋         | 32/500 [05:32<1:20:56, 10.38s/it]  7%|▋         | 33/500 [05:42<1:20:47, 10.38s/it]                                                  {'loss': 0.7178, 'learning_rate': 0.009340000000000001, 'epoch': 2.51}
  7%|▋         | 33/500 [05:42<1:20:47, 10.38s/it]  7%|▋         | 34/500 [05:53<1:20:32, 10.37s/it]                                                  {'loss': 0.8847, 'learning_rate': 0.00932, 'epoch': 2.59}
  7%|▋         | 34/500 [05:53<1:20:32, 10.37s/it]  7%|▋         | 35/500 [06:03<1:20:24, 10.38s/it]                                                  {'loss': 0.771, 'learning_rate': 0.009300000000000001, 'epoch': 2.67}
  7%|▋         | 35/500 [06:03<1:20:24, 10.38s/it]  7%|▋         | 36/500 [06:13<1:20:10, 10.37s/it]                                                  {'loss': 0.7915, 'learning_rate': 0.00928, 'epoch': 2.74}
  7%|▋         | 36/500 [06:13<1:20:10, 10.37s/it]  7%|▋         | 37/500 [06:24<1:19:57, 10.36s/it]                                                  {'loss': 0.7498, 'learning_rate': 0.009260000000000001, 'epoch': 2.82}
  7%|▋         | 37/500 [06:24<1:19:57, 10.36s/it]  8%|▊         | 38/500 [06:34<1:19:45, 10.36s/it]                                                  {'loss': 0.7777, 'learning_rate': 0.00924, 'epoch': 2.9}
  8%|▊         | 38/500 [06:34<1:19:45, 10.36s/it]  8%|▊         | 39/500 [06:44<1:19:37, 10.36s/it]                                                  {'loss': 0.7219, 'learning_rate': 0.00922, 'epoch': 2.97}
  8%|▊         | 39/500 [06:44<1:19:37, 10.36s/it]  8%|▊         | 40/500 [06:55<1:19:28, 10.37s/it]                                                  {'loss': 0.7502, 'learning_rate': 0.0092, 'epoch': 3.05}
  8%|▊         | 40/500 [06:55<1:19:28, 10.37s/it]  8%|▊         | 41/500 [07:05<1:19:17, 10.37s/it]                                                  {'loss': 0.7581, 'learning_rate': 0.00918, 'epoch': 3.12}
  8%|▊         | 41/500 [07:05<1:19:17, 10.37s/it]  8%|▊         | 42/500 [07:16<1:19:06, 10.36s/it]                                                  {'loss': 0.7929, 'learning_rate': 0.00916, 'epoch': 3.2}
  8%|▊         | 42/500 [07:16<1:19:06, 10.36s/it]  9%|▊         | 43/500 [07:26<1:18:59, 10.37s/it]                                                  {'loss': 0.6973, 'learning_rate': 0.00914, 'epoch': 3.28}
  9%|▊         | 43/500 [07:26<1:18:59, 10.37s/it]  9%|▉         | 44/500 [07:36<1:18:49, 10.37s/it]                                                  {'loss': 0.6606, 'learning_rate': 0.009120000000000001, 'epoch': 3.35}
  9%|▉         | 44/500 [07:36<1:18:49, 10.37s/it]  9%|▉         | 45/500 [07:47<1:18:39, 10.37s/it]                                                  {'loss': 0.7022, 'learning_rate': 0.0091, 'epoch': 3.43}
  9%|▉         | 45/500 [07:47<1:18:39, 10.37s/it]  9%|▉         | 46/500 [07:57<1:18:31, 10.38s/it]                                                  {'loss': 0.7217, 'learning_rate': 0.009080000000000001, 'epoch': 3.5}
  9%|▉         | 46/500 [07:57<1:18:31, 10.38s/it]  9%|▉         | 47/500 [08:07<1:18:18, 10.37s/it]                                                  {'loss': 0.6975, 'learning_rate': 0.00906, 'epoch': 3.58}
  9%|▉         | 47/500 [08:07<1:18:18, 10.37s/it] 10%|▉         | 48/500 [08:18<1:18:08, 10.37s/it]                                                  {'loss': 0.6798, 'learning_rate': 0.009040000000000001, 'epoch': 3.66}
 10%|▉         | 48/500 [08:18<1:18:08, 10.37s/it] 10%|▉         | 49/500 [08:28<1:17:55, 10.37s/it]                                                  {'loss': 0.786, 'learning_rate': 0.00902, 'epoch': 3.73}
 10%|▉         | 49/500 [08:28<1:17:55, 10.37s/it] 10%|█         | 50/500 [08:39<1:17:45, 10.37s/it]                                                  {'loss': 0.6945, 'learning_rate': 0.009000000000000001, 'epoch': 3.81}
 10%|█         | 50/500 [08:39<1:17:45, 10.37s/it] 10%|█         | 51/500 [08:49<1:17:38, 10.38s/it]                                                  {'loss': 0.7313, 'learning_rate': 0.00898, 'epoch': 3.89}
 10%|█         | 51/500 [08:49<1:17:38, 10.38s/it] 10%|█         | 52/500 [08:59<1:17:25, 10.37s/it]                                                  {'loss': 0.7411, 'learning_rate': 0.008960000000000001, 'epoch': 3.96}
 10%|█         | 52/500 [08:59<1:17:25, 10.37s/it] 11%|█         | 53/500 [09:10<1:17:14, 10.37s/it]                                                  {'loss': 0.6761, 'learning_rate': 0.00894, 'epoch': 4.04}
 11%|█         | 53/500 [09:10<1:17:14, 10.37s/it] 11%|█         | 54/500 [09:20<1:17:06, 10.37s/it]                                                  {'loss': 0.6741, 'learning_rate': 0.00892, 'epoch': 4.11}
 11%|█         | 54/500 [09:20<1:17:06, 10.37s/it] 11%|█         | 55/500 [09:30<1:16:54, 10.37s/it]                                                  {'loss': 0.676, 'learning_rate': 0.0089, 'epoch': 4.19}
 11%|█         | 55/500 [09:30<1:16:54, 10.37s/it] 11%|█         | 56/500 [09:41<1:16:44, 10.37s/it]                                                  {'loss': 0.6722, 'learning_rate': 0.00888, 'epoch': 4.27}
 11%|█         | 56/500 [09:41<1:16:44, 10.37s/it] 11%|█▏        | 57/500 [09:51<1:16:33, 10.37s/it]                                                  {'loss': 0.7346, 'learning_rate': 0.00886, 'epoch': 4.34}
 11%|█▏        | 57/500 [09:51<1:16:33, 10.37s/it] 12%|█▏        | 58/500 [10:01<1:16:25, 10.38s/it]                                                  {'loss': 0.6234, 'learning_rate': 0.00884, 'epoch': 4.42}
 12%|█▏        | 58/500 [10:01<1:16:25, 10.38s/it] 12%|█▏        | 59/500 [10:12<1:16:18, 10.38s/it]                                                  {'loss': 0.5996, 'learning_rate': 0.00882, 'epoch': 4.5}
 12%|█▏        | 59/500 [10:12<1:16:18, 10.38s/it] 12%|█▏        | 60/500 [10:22<1:16:03, 10.37s/it]                                                  {'loss': 0.666, 'learning_rate': 0.0088, 'epoch': 4.57}
 12%|█▏        | 60/500 [10:22<1:16:03, 10.37s/it] 12%|█▏        | 61/500 [10:33<1:15:51, 10.37s/it]                                                  {'loss': 0.6434, 'learning_rate': 0.00878, 'epoch': 4.65}
 12%|█▏        | 61/500 [10:33<1:15:51, 10.37s/it] 12%|█▏        | 62/500 [10:43<1:15:41, 10.37s/it]                                                  {'loss': 0.6982, 'learning_rate': 0.00876, 'epoch': 4.72}
 12%|█▏        | 62/500 [10:43<1:15:41, 10.37s/it] 13%|█▎        | 63/500 [10:53<1:15:32, 10.37s/it]                                                  {'loss': 0.6212, 'learning_rate': 0.00874, 'epoch': 4.8}
 13%|█▎        | 63/500 [10:53<1:15:32, 10.37s/it] 13%|█▎        | 64/500 [11:04<1:15:20, 10.37s/it]                                                  {'loss': 0.5961, 'learning_rate': 0.00872, 'epoch': 4.88}
 13%|█▎        | 64/500 [11:04<1:15:20, 10.37s/it] 13%|█▎        | 65/500 [11:14<1:15:10, 10.37s/it]                                                  {'loss': 0.6223, 'learning_rate': 0.0087, 'epoch': 4.95}
 13%|█▎        | 65/500 [11:14<1:15:10, 10.37s/it] 13%|█▎        | 66/500 [11:24<1:15:01, 10.37s/it]                                                  {'loss': 0.5859, 'learning_rate': 0.00868, 'epoch': 5.03}
 13%|█▎        | 66/500 [11:24<1:15:01, 10.37s/it] 13%|█▎        | 67/500 [11:35<1:14:51, 10.37s/it]                                                  {'loss': 0.5892, 'learning_rate': 0.00866, 'epoch': 5.1}
 13%|█▎        | 67/500 [11:35<1:14:51, 10.37s/it] 14%|█▎        | 68/500 [11:45<1:14:38, 10.37s/it]                                                  {'loss': 0.6813, 'learning_rate': 0.00864, 'epoch': 5.18}
 14%|█▎        | 68/500 [11:45<1:14:38, 10.37s/it] 14%|█▍        | 69/500 [11:56<1:14:28, 10.37s/it]                                                  {'loss': 0.566, 'learning_rate': 0.008620000000000001, 'epoch': 5.26}
 14%|█▍        | 69/500 [11:56<1:14:28, 10.37s/it] 14%|█▍        | 70/500 [12:06<1:14:19, 10.37s/it]                                                  {'loss': 0.6311, 'learning_rate': 0.0086, 'epoch': 5.33}
 14%|█▍        | 70/500 [12:06<1:14:19, 10.37s/it] 14%|█▍        | 71/500 [12:16<1:14:08, 10.37s/it]                                                  {'loss': 0.5818, 'learning_rate': 0.00858, 'epoch': 5.41}
 14%|█▍        | 71/500 [12:16<1:14:08, 10.37s/it] 14%|█▍        | 72/500 [12:27<1:13:58, 10.37s/it]                                                  {'loss': 0.6239, 'learning_rate': 0.00856, 'epoch': 5.49}
 14%|█▍        | 72/500 [12:27<1:13:58, 10.37s/it] 15%|█▍        | 73/500 [12:37<1:13:49, 10.37s/it]                                                  {'loss': 0.602, 'learning_rate': 0.00854, 'epoch': 5.56}
 15%|█▍        | 73/500 [12:37<1:13:49, 10.37s/it] 15%|█▍        | 74/500 [12:47<1:13:39, 10.37s/it]                                                  {'loss': 0.5783, 'learning_rate': 0.00852, 'epoch': 5.64}
 15%|█▍        | 74/500 [12:47<1:13:39, 10.37s/it] 15%|█▌        | 75/500 [12:58<1:13:26, 10.37s/it]                                                  {'loss': 0.5931, 'learning_rate': 0.0085, 'epoch': 5.71}
 15%|█▌        | 75/500 [12:58<1:13:26, 10.37s/it] 15%|█▌        | 76/500 [13:08<1:13:15, 10.37s/it]                                                  {'loss': 0.5982, 'learning_rate': 0.00848, 'epoch': 5.79}
 15%|█▌        | 76/500 [13:08<1:13:15, 10.37s/it] 15%|█▌        | 77/500 [13:19<1:13:05, 10.37s/it]                                                  {'loss': 0.5227, 'learning_rate': 0.00846, 'epoch': 5.87}
 15%|█▌        | 77/500 [13:19<1:13:05, 10.37s/it] 16%|█▌        | 78/500 [13:29<1:12:56, 10.37s/it]                                                  {'loss': 0.5826, 'learning_rate': 0.00844, 'epoch': 5.94}
 16%|█▌        | 78/500 [13:29<1:12:56, 10.37s/it] 16%|█▌        | 79/500 [13:39<1:12:50, 10.38s/it]                                                  {'loss': 0.6328, 'learning_rate': 0.00842, 'epoch': 6.02}
 16%|█▌        | 79/500 [13:39<1:12:50, 10.38s/it] 16%|█▌        | 80/500 [13:50<1:12:36, 10.37s/it]                                                  {'loss': 0.6158, 'learning_rate': 0.0084, 'epoch': 6.1}
 16%|█▌        | 80/500 [13:50<1:12:36, 10.37s/it] 16%|█▌        | 81/500 [14:00<1:12:24, 10.37s/it]                                                  {'loss': 0.5384, 'learning_rate': 0.00838, 'epoch': 6.17}
 16%|█▌        | 81/500 [14:00<1:12:24, 10.37s/it] 16%|█▋        | 82/500 [14:10<1:12:12, 10.36s/it]                                                  {'loss': 0.5381, 'learning_rate': 0.00836, 'epoch': 6.25}
 16%|█▋        | 82/500 [14:10<1:12:12, 10.36s/it] 17%|█▋        | 83/500 [14:21<1:12:00, 10.36s/it]                                                  {'loss': 0.5679, 'learning_rate': 0.00834, 'epoch': 6.32}
 17%|█▋        | 83/500 [14:21<1:12:00, 10.36s/it] 17%|█▋        | 84/500 [14:31<1:11:52, 10.37s/it]                                                  {'loss': 0.4654, 'learning_rate': 0.00832, 'epoch': 6.4}
 17%|█▋        | 84/500 [14:31<1:11:52, 10.37s/it] 17%|█▋        | 85/500 [14:41<1:11:43, 10.37s/it]                                                  {'loss': 0.63, 'learning_rate': 0.0083, 'epoch': 6.48}
 17%|█▋        | 85/500 [14:41<1:11:43, 10.37s/it] 17%|█▋        | 86/500 [14:52<1:11:35, 10.38s/it]                                                  {'loss': 0.5218, 'learning_rate': 0.00828, 'epoch': 6.55}
 17%|█▋        | 86/500 [14:52<1:11:35, 10.38s/it] 17%|█▋        | 87/500 [15:02<1:11:23, 10.37s/it]                                                  {'loss': 0.6058, 'learning_rate': 0.00826, 'epoch': 6.63}
 17%|█▋        | 87/500 [15:02<1:11:23, 10.37s/it] 18%|█▊        | 88/500 [15:13<1:11:13, 10.37s/it]                                                  {'loss': 0.6261, 'learning_rate': 0.008239999999999999, 'epoch': 6.7}
 18%|█▊        | 88/500 [15:13<1:11:13, 10.37s/it] 18%|█▊        | 89/500 [15:23<1:11:04, 10.38s/it]                                                  {'loss': 0.5237, 'learning_rate': 0.00822, 'epoch': 6.78}
 18%|█▊        | 89/500 [15:23<1:11:04, 10.38s/it] 18%|█▊        | 90/500 [15:33<1:10:54, 10.38s/it]                                                  {'loss': 0.5274, 'learning_rate': 0.008199999999999999, 'epoch': 6.86}
 18%|█▊        | 90/500 [15:33<1:10:54, 10.38s/it] 18%|█▊        | 91/500 [15:44<1:10:45, 10.38s/it]                                                  {'loss': 0.5142, 'learning_rate': 0.00818, 'epoch': 6.93}
 18%|█▊        | 91/500 [15:44<1:10:45, 10.38s/it] 18%|█▊        | 92/500 [15:54<1:10:33, 10.38s/it]                                                  {'loss': 0.555, 'learning_rate': 0.008159999999999999, 'epoch': 7.01}
 18%|█▊        | 92/500 [15:54<1:10:33, 10.38s/it] 19%|█▊        | 93/500 [16:04<1:10:23, 10.38s/it]                                                  {'loss': 0.5441, 'learning_rate': 0.00814, 'epoch': 7.09}
 19%|█▊        | 93/500 [16:04<1:10:23, 10.38s/it] 19%|█▉        | 94/500 [16:15<1:10:10, 10.37s/it]                                                  {'loss': 0.5019, 'learning_rate': 0.00812, 'epoch': 7.16}
 19%|█▉        | 94/500 [16:15<1:10:10, 10.37s/it] 19%|█▉        | 95/500 [16:25<1:10:00, 10.37s/it]                                                  {'loss': 0.5868, 'learning_rate': 0.008100000000000001, 'epoch': 7.24}
 19%|█▉        | 95/500 [16:25<1:10:00, 10.37s/it] 19%|█▉        | 96/500 [16:36<1:09:47, 10.37s/it]                                                  {'loss': 0.5361, 'learning_rate': 0.00808, 'epoch': 7.31}
 19%|█▉        | 96/500 [16:36<1:09:47, 10.37s/it] 19%|█▉        | 97/500 [16:46<1:09:38, 10.37s/it]                                                  {'loss': 0.491, 'learning_rate': 0.008060000000000001, 'epoch': 7.39}
 19%|█▉        | 97/500 [16:46<1:09:38, 10.37s/it] 20%|█▉        | 98/500 [16:56<1:09:31, 10.38s/it]                                                  {'loss': 0.5465, 'learning_rate': 0.00804, 'epoch': 7.47}
 20%|█▉        | 98/500 [16:56<1:09:31, 10.38s/it] 20%|█▉        | 99/500 [17:07<1:09:17, 10.37s/it]                                                  {'loss': 0.4524, 'learning_rate': 0.008020000000000001, 'epoch': 7.54}
 20%|█▉        | 99/500 [17:07<1:09:17, 10.37s/it] 20%|██        | 100/500 [17:17<1:09:08, 10.37s/it]                                                   {'loss': 0.6135, 'learning_rate': 0.008, 'epoch': 7.62}
 20%|██        | 100/500 [17:17<1:09:08, 10.37s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:483] 2024-01-14 00:18:37,832 >> Configuration saved in output/test-202401132355-128-1e-2/tmp-checkpoint-100/config.json
[INFO|configuration_utils.py:594] 2024-01-14 00:18:37,833 >> Configuration saved in output/test-202401132355-128-1e-2/tmp-checkpoint-100/generation_config.json
[INFO|modeling_utils.py:2382] 2024-01-14 00:18:37,845 >> Model weights saved in output/test-202401132355-128-1e-2/tmp-checkpoint-100/pytorch_model.bin
[INFO|tokenization_utils_base.py:2432] 2024-01-14 00:18:37,846 >> tokenizer config file saved in output/test-202401132355-128-1e-2/tmp-checkpoint-100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2441] 2024-01-14 00:18:37,846 >> Special tokens file saved in output/test-202401132355-128-1e-2/tmp-checkpoint-100/special_tokens_map.json
/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 20%|██        | 101/500 [17:28<1:09:05, 10.39s/it]                                                   {'loss': 0.5243, 'learning_rate': 0.007980000000000001, 'epoch': 7.7}
 20%|██        | 101/500 [17:28<1:09:05, 10.39s/it] 20%|██        | 102/500 [17:38<1:08:52, 10.38s/it]                                                   {'loss': 0.4991, 'learning_rate': 0.00796, 'epoch': 7.77}
 20%|██        | 102/500 [17:38<1:08:52, 10.38s/it] 21%|██        | 103/500 [17:48<1:08:40, 10.38s/it]                                                   {'loss': 0.5914, 'learning_rate': 0.007940000000000001, 'epoch': 7.85}
 21%|██        | 103/500 [17:48<1:08:40, 10.38s/it] 21%|██        | 104/500 [17:59<1:08:31, 10.38s/it]                                                   {'loss': 0.457, 'learning_rate': 0.00792, 'epoch': 7.92}
 21%|██        | 104/500 [17:59<1:08:31, 10.38s/it] 21%|██        | 105/500 [18:09<1:08:21, 10.38s/it]                                                   {'loss': 0.5095, 'learning_rate': 0.0079, 'epoch': 8.0}
 21%|██        | 105/500 [18:09<1:08:21, 10.38s/it] 21%|██        | 106/500 [18:19<1:08:09, 10.38s/it]                                                   {'loss': 0.5564, 'learning_rate': 0.00788, 'epoch': 8.08}
 21%|██        | 106/500 [18:19<1:08:09, 10.38s/it] 21%|██▏       | 107/500 [18:30<1:07:59, 10.38s/it]                                                   {'loss': 0.4802, 'learning_rate': 0.00786, 'epoch': 8.15}
 21%|██▏       | 107/500 [18:30<1:07:59, 10.38s/it] 22%|██▏       | 108/500 [18:40<1:07:46, 10.37s/it]                                                   {'loss': 0.5322, 'learning_rate': 0.00784, 'epoch': 8.23}
 22%|██▏       | 108/500 [18:40<1:07:46, 10.37s/it] 22%|██▏       | 109/500 [18:50<1:07:35, 10.37s/it]                                                   {'loss': 0.4811, 'learning_rate': 0.00782, 'epoch': 8.3}
 22%|██▏       | 109/500 [18:50<1:07:35, 10.37s/it] 22%|██▏       | 110/500 [19:01<1:07:25, 10.37s/it]                                                   {'loss': 0.4809, 'learning_rate': 0.0078000000000000005, 'epoch': 8.38}
 22%|██▏       | 110/500 [19:01<1:07:25, 10.37s/it] 22%|██▏       | 111/500 [19:11<1:07:16, 10.38s/it]                                                   {'loss': 0.5249, 'learning_rate': 0.0077800000000000005, 'epoch': 8.46}
 22%|██▏       | 111/500 [19:11<1:07:16, 10.38s/it] 22%|██▏       | 112/500 [19:22<1:07:06, 10.38s/it]                                                   {'loss': 0.4914, 'learning_rate': 0.00776, 'epoch': 8.53}
 22%|██▏       | 112/500 [19:22<1:07:06, 10.38s/it] 23%|██▎       | 113/500 [19:32<1:06:56, 10.38s/it]                                                   {'loss': 0.4683, 'learning_rate': 0.00774, 'epoch': 8.61}
 23%|██▎       | 113/500 [19:32<1:06:56, 10.38s/it] 23%|██▎       | 114/500 [19:42<1:06:46, 10.38s/it]                                                   {'loss': 0.4873, 'learning_rate': 0.00772, 'epoch': 8.69}
 23%|██▎       | 114/500 [19:42<1:06:46, 10.38s/it] 23%|██▎       | 115/500 [19:53<1:06:33, 10.37s/it]                                                   {'loss': 0.4893, 'learning_rate': 0.0077, 'epoch': 8.76}
 23%|██▎       | 115/500 [19:53<1:06:33, 10.37s/it] 23%|██▎       | 116/500 [20:03<1:06:21, 10.37s/it]                                                   {'loss': 0.5465, 'learning_rate': 0.00768, 'epoch': 8.84}
 23%|██▎       | 116/500 [20:03<1:06:21, 10.37s/it] 23%|██▎       | 117/500 [20:14<1:06:13, 10.38s/it]                                                   {'loss': 0.4728, 'learning_rate': 0.00766, 'epoch': 8.91}
 23%|██▎       | 117/500 [20:14<1:06:13, 10.38s/it] 24%|██▎       | 118/500 [20:24<1:06:01, 10.37s/it]                                                   {'loss': 0.5571, 'learning_rate': 0.00764, 'epoch': 8.99}
 24%|██▎       | 118/500 [20:24<1:06:01, 10.37s/it] 24%|██▍       | 119/500 [20:34<1:05:48, 10.36s/it]                                                   {'loss': 0.5766, 'learning_rate': 0.00762, 'epoch': 9.07}
 24%|██▍       | 119/500 [20:34<1:05:48, 10.36s/it] 24%|██▍       | 120/500 [20:45<1:05:40, 10.37s/it]                                                   {'loss': 0.4551, 'learning_rate': 0.0076, 'epoch': 9.14}
 24%|██▍       | 120/500 [20:45<1:05:40, 10.37s/it] 24%|██▍       | 121/500 [20:55<1:05:29, 10.37s/it]                                                   {'loss': 0.5382, 'learning_rate': 0.00758, 'epoch': 9.22}
 24%|██▍       | 121/500 [20:55<1:05:29, 10.37s/it] 24%|██▍       | 122/500 [21:05<1:05:19, 10.37s/it]                                                   {'loss': 0.4834, 'learning_rate': 0.00756, 'epoch': 9.3}
 24%|██▍       | 122/500 [21:05<1:05:19, 10.37s/it] 25%|██▍       | 123/500 [21:16<1:05:08, 10.37s/it]                                                   {'loss': 0.4538, 'learning_rate': 0.00754, 'epoch': 9.37}
 25%|██▍       | 123/500 [21:16<1:05:08, 10.37s/it] 25%|██▍       | 124/500 [21:26<1:05:01, 10.38s/it]                                                   {'loss': 0.5338, 'learning_rate': 0.00752, 'epoch': 9.45}
 25%|██▍       | 124/500 [21:26<1:05:01, 10.38s/it] 25%|██▌       | 125/500 [21:36<1:04:50, 10.38s/it]                                                   {'loss': 0.5375, 'learning_rate': 0.0075, 'epoch': 9.52}
 25%|██▌       | 125/500 [21:36<1:04:50, 10.38s/it] 25%|██▌       | 126/500 [21:47<1:04:38, 10.37s/it]                                                   {'loss': 0.4343, 'learning_rate': 0.0074800000000000005, 'epoch': 9.6}
 25%|██▌       | 126/500 [21:47<1:04:38, 10.37s/it] 25%|██▌       | 127/500 [21:57<1:04:27, 10.37s/it]                                                   {'loss': 0.4252, 'learning_rate': 0.0074600000000000005, 'epoch': 9.68}
 25%|██▌       | 127/500 [21:57<1:04:27, 10.37s/it] 26%|██▌       | 128/500 [22:08<1:04:18, 10.37s/it]                                                   {'loss': 0.5136, 'learning_rate': 0.00744, 'epoch': 9.75}
 26%|██▌       | 128/500 [22:08<1:04:18, 10.37s/it] 26%|██▌       | 129/500 [22:18<1:04:03, 10.36s/it]                                                   {'loss': 0.4042, 'learning_rate': 0.00742, 'epoch': 9.83}
 26%|██▌       | 129/500 [22:18<1:04:03, 10.36s/it] 26%|██▌       | 130/500 [22:28<1:03:55, 10.37s/it]                                                   {'loss': 0.4649, 'learning_rate': 0.0074, 'epoch': 9.9}
 26%|██▌       | 130/500 [22:28<1:03:55, 10.37s/it] 26%|██▌       | 131/500 [22:39<1:03:46, 10.37s/it]                                                   {'loss': 0.5025, 'learning_rate': 0.00738, 'epoch': 9.98}
 26%|██▌       | 131/500 [22:39<1:03:46, 10.37s/it] 26%|██▋       | 132/500 [22:49<1:03:35, 10.37s/it]                                                   {'loss': 0.4763, 'learning_rate': 0.00736, 'epoch': 10.06}
 26%|██▋       | 132/500 [22:49<1:03:35, 10.37s/it] 27%|██▋       | 133/500 [22:59<1:03:23, 10.36s/it]                                                   {'loss': 0.4488, 'learning_rate': 0.00734, 'epoch': 10.13}
 27%|██▋       | 133/500 [22:59<1:03:23, 10.36s/it] 27%|██▋       | 134/500 [23:10<1:03:12, 10.36s/it]                                                   {'loss': 0.4366, 'learning_rate': 0.00732, 'epoch': 10.21}
 27%|██▋       | 134/500 [23:10<1:03:12, 10.36s/it] 27%|██▋       | 135/500 [23:20<1:03:03, 10.37s/it]                                                   {'loss': 0.5185, 'learning_rate': 0.0073, 'epoch': 10.29}
 27%|██▋       | 135/500 [23:20<1:03:03, 10.37s/it] 27%|██▋       | 136/500 [23:31<1:02:57, 10.38s/it]                                                   {'loss': 0.4204, 'learning_rate': 0.00728, 'epoch': 10.36}
 27%|██▋       | 136/500 [23:31<1:02:57, 10.38s/it] 27%|██▋       | 137/500 [23:41<1:02:46, 10.38s/it]                                                   {'loss': 0.4431, 'learning_rate': 0.00726, 'epoch': 10.44}
 27%|██▋       | 137/500 [23:41<1:02:46, 10.38s/it] 28%|██▊       | 138/500 [23:51<1:02:36, 10.38s/it]                                                   {'loss': 0.4634, 'learning_rate': 0.00724, 'epoch': 10.51}
 28%|██▊       | 138/500 [23:51<1:02:36, 10.38s/it] 28%|██▊       | 139/500 [24:02<1:02:23, 10.37s/it]                                                   {'loss': 0.514, 'learning_rate': 0.00722, 'epoch': 10.59}
 28%|██▊       | 139/500 [24:02<1:02:23, 10.37s/it] 28%|██▊       | 140/500 [24:12<1:02:12, 10.37s/it]                                                   {'loss': 0.4348, 'learning_rate': 0.0072, 'epoch': 10.67}
 28%|██▊       | 140/500 [24:12<1:02:12, 10.37s/it] 28%|██▊       | 141/500 [24:22<1:01:59, 10.36s/it]                                                   {'loss': 0.4585, 'learning_rate': 0.00718, 'epoch': 10.74}
 28%|██▊       | 141/500 [24:22<1:01:59, 10.36s/it] 28%|██▊       | 142/500 [24:33<1:01:50, 10.36s/it]                                                   {'loss': 0.5069, 'learning_rate': 0.00716, 'epoch': 10.82}
 28%|██▊       | 142/500 [24:33<1:01:50, 10.36s/it] 29%|██▊       | 143/500 [24:43<1:01:43, 10.37s/it]                                                   {'loss': 0.4435, 'learning_rate': 0.00714, 'epoch': 10.9}
 29%|██▊       | 143/500 [24:43<1:01:43, 10.37s/it] 29%|██▉       | 144/500 [24:53<1:01:29, 10.36s/it]                                                   {'loss': 0.4996, 'learning_rate': 0.00712, 'epoch': 10.97}
 29%|██▉       | 144/500 [24:53<1:01:29, 10.36s/it] 29%|██▉       | 145/500 [25:04<1:01:20, 10.37s/it]                                                   {'loss': 0.5507, 'learning_rate': 0.0070999999999999995, 'epoch': 11.05}
 29%|██▉       | 145/500 [25:04<1:01:20, 10.37s/it] 29%|██▉       | 146/500 [25:14<1:01:10, 10.37s/it]                                                   {'loss': 0.5351, 'learning_rate': 0.0070799999999999995, 'epoch': 11.12}
 29%|██▉       | 146/500 [25:14<1:01:10, 10.37s/it] 29%|██▉       | 147/500 [25:25<1:01:01, 10.37s/it]                                                   {'loss': 0.5237, 'learning_rate': 0.0070599999999999994, 'epoch': 11.2}
 29%|██▉       | 147/500 [25:25<1:01:01, 10.37s/it] 30%|██▉       | 148/500 [25:35<1:00:50, 10.37s/it]                                                   {'loss': 0.478, 'learning_rate': 0.007039999999999999, 'epoch': 11.28}
 30%|██▉       | 148/500 [25:35<1:00:50, 10.37s/it] 30%|██▉       | 149/500 [25:45<1:00:40, 10.37s/it]                                                   {'loss': 0.3619, 'learning_rate': 0.007019999999999999, 'epoch': 11.35}
 30%|██▉       | 149/500 [25:45<1:00:40, 10.37s/it] 30%|███       | 150/500 [25:56<1:00:29, 10.37s/it]                                                   {'loss': 0.4719, 'learning_rate': 0.006999999999999999, 'epoch': 11.43}
 30%|███       | 150/500 [25:56<1:00:29, 10.37s/it] 30%|███       | 151/500 [26:06<1:00:16, 10.36s/it]                                                   {'loss': 0.4538, 'learning_rate': 0.00698, 'epoch': 11.5}
 30%|███       | 151/500 [26:06<1:00:16, 10.36s/it] 30%|███       | 152/500 [26:16<1:00:06, 10.36s/it]                                                   {'loss': 0.3762, 'learning_rate': 0.00696, 'epoch': 11.58}
 30%|███       | 152/500 [26:16<1:00:06, 10.36s/it] 31%|███       | 153/500 [26:27<59:56, 10.37s/it]                                                   {'loss': 0.4255, 'learning_rate': 0.00694, 'epoch': 11.66}
 31%|███       | 153/500 [26:27<59:56, 10.37s/it] 31%|███       | 154/500 [26:37<59:46, 10.37s/it]                                                 {'loss': 0.4201, 'learning_rate': 0.00692, 'epoch': 11.73}
 31%|███       | 154/500 [26:37<59:46, 10.37s/it] 31%|███       | 155/500 [26:48<59:39, 10.38s/it]                                                 {'loss': 0.4746, 'learning_rate': 0.0069, 'epoch': 11.81}
 31%|███       | 155/500 [26:48<59:39, 10.38s/it] 31%|███       | 156/500 [26:58<59:30, 10.38s/it]                                                 {'loss': 0.4528, 'learning_rate': 0.00688, 'epoch': 11.89}
 31%|███       | 156/500 [26:58<59:30, 10.38s/it] 31%|███▏      | 157/500 [27:08<59:18, 10.38s/it]                                                 {'loss': 0.4114, 'learning_rate': 0.006860000000000001, 'epoch': 11.96}
 31%|███▏      | 157/500 [27:08<59:18, 10.38s/it] 32%|███▏      | 158/500 [27:19<59:10, 10.38s/it]                                                 {'loss': 0.4713, 'learning_rate': 0.006840000000000001, 'epoch': 12.04}
 32%|███▏      | 158/500 [27:19<59:10, 10.38s/it] 32%|███▏      | 159/500 [27:29<58:57, 10.37s/it]                                                 {'loss': 0.4707, 'learning_rate': 0.0068200000000000005, 'epoch': 12.11}
 32%|███▏      | 159/500 [27:29<58:57, 10.37s/it] 32%|███▏      | 160/500 [27:39<58:46, 10.37s/it]                                                 {'loss': 0.4868, 'learning_rate': 0.0068000000000000005, 'epoch': 12.19}
 32%|███▏      | 160/500 [27:39<58:46, 10.37s/it] 32%|███▏      | 161/500 [27:50<58:37, 10.38s/it]                                                 {'loss': 0.4409, 'learning_rate': 0.0067800000000000004, 'epoch': 12.27}
 32%|███▏      | 161/500 [27:50<58:37, 10.38s/it] 32%|███▏      | 162/500 [28:00<58:26, 10.37s/it]                                                 {'loss': 0.4075, 'learning_rate': 0.00676, 'epoch': 12.34}
 32%|███▏      | 162/500 [28:00<58:26, 10.37s/it] 33%|███▎      | 163/500 [28:11<58:15, 10.37s/it]                                                 {'loss': 0.488, 'learning_rate': 0.00674, 'epoch': 12.42}
 33%|███▎      | 163/500 [28:11<58:15, 10.37s/it] 33%|███▎      | 164/500 [28:21<58:04, 10.37s/it]                                                 {'loss': 0.5195, 'learning_rate': 0.00672, 'epoch': 12.5}
 33%|███▎      | 164/500 [28:21<58:04, 10.37s/it] 33%|███▎      | 165/500 [28:31<57:53, 10.37s/it]                                                 {'loss': 0.4555, 'learning_rate': 0.0067, 'epoch': 12.57}
 33%|███▎      | 165/500 [28:31<57:53, 10.37s/it] 33%|███▎      | 166/500 [28:42<57:44, 10.37s/it]                                                 {'loss': 0.3877, 'learning_rate': 0.00668, 'epoch': 12.65}
 33%|███▎      | 166/500 [28:42<57:44, 10.37s/it] 33%|███▎      | 167/500 [28:52<57:34, 10.37s/it]                                                 {'loss': 0.42, 'learning_rate': 0.00666, 'epoch': 12.72}
 33%|███▎      | 167/500 [28:52<57:34, 10.37s/it] 34%|███▎      | 168/500 [29:02<57:23, 10.37s/it]                                                 {'loss': 0.3823, 'learning_rate': 0.00664, 'epoch': 12.8}
 34%|███▎      | 168/500 [29:02<57:23, 10.37s/it] 34%|███▍      | 169/500 [29:13<57:11, 10.37s/it]                                                 {'loss': 0.4488, 'learning_rate': 0.006620000000000001, 'epoch': 12.88}
 34%|███▍      | 169/500 [29:13<57:11, 10.37s/it] 34%|███▍      | 170/500 [29:23<57:01, 10.37s/it]                                                 {'loss': 0.405, 'learning_rate': 0.006600000000000001, 'epoch': 12.95}
 34%|███▍      | 170/500 [29:23<57:01, 10.37s/it] 34%|███▍      | 171/500 [29:33<56:51, 10.37s/it]                                                 {'loss': 0.425, 'learning_rate': 0.006580000000000001, 'epoch': 13.03}
 34%|███▍      | 171/500 [29:33<56:51, 10.37s/it] 34%|███▍      | 172/500 [29:44<56:41, 10.37s/it]                                                 {'loss': 0.4121, 'learning_rate': 0.006560000000000001, 'epoch': 13.1}
 34%|███▍      | 172/500 [29:44<56:41, 10.37s/it] 35%|███▍      | 173/500 [29:54<56:29, 10.36s/it]                                                 {'loss': 0.3885, 'learning_rate': 0.006540000000000001, 'epoch': 13.18}
 35%|███▍      | 173/500 [29:54<56:29, 10.36s/it] 35%|███▍      | 174/500 [30:05<56:17, 10.36s/it]                                                 {'loss': 0.4212, 'learning_rate': 0.006520000000000001, 'epoch': 13.26}
 35%|███▍      | 174/500 [30:05<56:17, 10.36s/it] 35%|███▌      | 175/500 [30:15<56:08, 10.36s/it]                                                 {'loss': 0.4755, 'learning_rate': 0.006500000000000001, 'epoch': 13.33}
 35%|███▌      | 175/500 [30:15<56:08, 10.36s/it] 35%|███▌      | 176/500 [30:25<55:58, 10.37s/it]                                                 {'loss': 0.4553, 'learning_rate': 0.0064800000000000005, 'epoch': 13.41}
 35%|███▌      | 176/500 [30:25<55:58, 10.37s/it] 35%|███▌      | 177/500 [30:36<55:45, 10.36s/it]                                                 {'loss': 0.4662, 'learning_rate': 0.0064600000000000005, 'epoch': 13.49}
 35%|███▌      | 177/500 [30:36<55:45, 10.36s/it] 36%|███▌      | 178/500 [30:46<55:36, 10.36s/it]                                                 {'loss': 0.3917, 'learning_rate': 0.00644, 'epoch': 13.56}
 36%|███▌      | 178/500 [30:46<55:36, 10.36s/it] 36%|███▌      | 179/500 [30:56<55:28, 10.37s/it]                                                 {'loss': 0.4163, 'learning_rate': 0.00642, 'epoch': 13.64}
 36%|███▌      | 179/500 [30:56<55:28, 10.37s/it] 36%|███▌      | 180/500 [31:07<55:16, 10.36s/it]                                                 {'loss': 0.3974, 'learning_rate': 0.0064, 'epoch': 13.71}
 36%|███▌      | 180/500 [31:07<55:16, 10.36s/it] 36%|███▌      | 181/500 [31:17<55:10, 10.38s/it]                                                 {'loss': 0.4976, 'learning_rate': 0.00638, 'epoch': 13.79}
 36%|███▌      | 181/500 [31:17<55:10, 10.38s/it] 36%|███▋      | 182/500 [31:28<55:02, 10.38s/it]                                                 {'loss': 0.3607, 'learning_rate': 0.00636, 'epoch': 13.87}
 36%|███▋      | 182/500 [31:28<55:02, 10.38s/it] 37%|███▋      | 183/500 [31:38<54:51, 10.38s/it]                                                 {'loss': 0.4873, 'learning_rate': 0.00634, 'epoch': 13.94}
 37%|███▋      | 183/500 [31:38<54:51, 10.38s/it] 37%|███▋      | 184/500 [31:48<54:41, 10.38s/it]                                                 {'loss': 0.5017, 'learning_rate': 0.00632, 'epoch': 14.02}
 37%|███▋      | 184/500 [31:48<54:41, 10.38s/it] 37%|███▋      | 185/500 [31:59<54:30, 10.38s/it]                                                 {'loss': 0.3945, 'learning_rate': 0.0063, 'epoch': 14.1}
 37%|███▋      | 185/500 [31:59<54:30, 10.38s/it] 37%|███▋      | 186/500 [32:09<54:17, 10.37s/it]                                                 {'loss': 0.3736, 'learning_rate': 0.00628, 'epoch': 14.17}
 37%|███▋      | 186/500 [32:09<54:17, 10.37s/it] 37%|███▋      | 187/500 [32:19<54:06, 10.37s/it]                                                 {'loss': 0.44, 'learning_rate': 0.00626, 'epoch': 14.25}
 37%|███▋      | 187/500 [32:19<54:06, 10.37s/it] 38%|███▊      | 188/500 [32:30<53:59, 10.38s/it]                                                 {'loss': 0.4801, 'learning_rate': 0.00624, 'epoch': 14.32}
 38%|███▊      | 188/500 [32:30<53:59, 10.38s/it] 38%|███▊      | 189/500 [32:40<53:49, 10.38s/it]                                                 {'loss': 0.4318, 'learning_rate': 0.00622, 'epoch': 14.4}
 38%|███▊      | 189/500 [32:40<53:49, 10.38s/it] 38%|███▊      | 190/500 [32:51<53:40, 10.39s/it]                                                 {'loss': 0.4921, 'learning_rate': 0.0062, 'epoch': 14.48}
 38%|███▊      | 190/500 [32:51<53:40, 10.39s/it] 38%|███▊      | 191/500 [33:01<53:28, 10.38s/it]                                                 {'loss': 0.3328, 'learning_rate': 0.00618, 'epoch': 14.55}
 38%|███▊      | 191/500 [33:01<53:28, 10.38s/it] 38%|███▊      | 192/500 [33:11<53:17, 10.38s/it]                                                 {'loss': 0.4026, 'learning_rate': 0.00616, 'epoch': 14.63}
 38%|███▊      | 192/500 [33:11<53:17, 10.38s/it] 39%|███▊      | 193/500 [33:22<53:05, 10.38s/it]                                                 {'loss': 0.4289, 'learning_rate': 0.00614, 'epoch': 14.7}
 39%|███▊      | 193/500 [33:22<53:05, 10.38s/it] 39%|███▉      | 194/500 [33:32<52:54, 10.37s/it]                                                 {'loss': 0.4024, 'learning_rate': 0.0061200000000000004, 'epoch': 14.78}
 39%|███▉      | 194/500 [33:32<52:54, 10.37s/it] 39%|███▉      | 195/500 [33:43<52:45, 10.38s/it]                                                 {'loss': 0.423, 'learning_rate': 0.0061, 'epoch': 14.86}
 39%|███▉      | 195/500 [33:43<52:45, 10.38s/it] 39%|███▉      | 196/500 [33:53<52:36, 10.38s/it]                                                 {'loss': 0.4735, 'learning_rate': 0.00608, 'epoch': 14.93}
 39%|███▉      | 196/500 [33:53<52:36, 10.38s/it] 39%|███▉      | 197/500 [34:03<52:25, 10.38s/it]                                                 {'loss': 0.3857, 'learning_rate': 0.00606, 'epoch': 15.01}
 39%|███▉      | 197/500 [34:03<52:25, 10.38s/it] 40%|███▉      | 198/500 [34:14<52:14, 10.38s/it]                                                 {'loss': 0.4279, 'learning_rate': 0.00604, 'epoch': 15.09}
 40%|███▉      | 198/500 [34:14<52:14, 10.38s/it] 40%|███▉      | 199/500 [34:24<52:05, 10.38s/it]                                                 {'loss': 0.3059, 'learning_rate': 0.00602, 'epoch': 15.16}
 40%|███▉      | 199/500 [34:24<52:05, 10.38s/it] 40%|████      | 200/500 [34:34<51:55, 10.38s/it]                                                 {'loss': 0.4167, 'learning_rate': 0.006, 'epoch': 15.24}
 40%|████      | 200/500 [34:34<51:55, 10.38s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:483] 2024-01-14 00:35:55,186 >> Configuration saved in output/test-202401132355-128-1e-2/tmp-checkpoint-200/config.json
[INFO|configuration_utils.py:594] 2024-01-14 00:35:55,186 >> Configuration saved in output/test-202401132355-128-1e-2/tmp-checkpoint-200/generation_config.json
[INFO|modeling_utils.py:2382] 2024-01-14 00:35:55,196 >> Model weights saved in output/test-202401132355-128-1e-2/tmp-checkpoint-200/pytorch_model.bin
[INFO|tokenization_utils_base.py:2432] 2024-01-14 00:35:55,197 >> tokenizer config file saved in output/test-202401132355-128-1e-2/tmp-checkpoint-200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2441] 2024-01-14 00:35:55,197 >> Special tokens file saved in output/test-202401132355-128-1e-2/tmp-checkpoint-200/special_tokens_map.json
/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 40%|████      | 201/500 [34:45<51:49, 10.40s/it]                                                 {'loss': 0.4371, 'learning_rate': 0.00598, 'epoch': 15.31}
 40%|████      | 201/500 [34:45<51:49, 10.40s/it] 40%|████      | 202/500 [34:55<51:37, 10.39s/it]                                                 {'loss': 0.3838, 'learning_rate': 0.00596, 'epoch': 15.39}
 40%|████      | 202/500 [34:55<51:37, 10.39s/it] 41%|████      | 203/500 [35:06<51:24, 10.39s/it]                                                 {'loss': 0.4004, 'learning_rate': 0.00594, 'epoch': 15.47}
 41%|████      | 203/500 [35:06<51:24, 10.39s/it] 41%|████      | 204/500 [35:16<51:13, 10.38s/it]                                                 {'loss': 0.4395, 'learning_rate': 0.00592, 'epoch': 15.54}
 41%|████      | 204/500 [35:16<51:13, 10.38s/it] 41%|████      | 205/500 [35:26<51:00, 10.37s/it]                                                 {'loss': 0.5148, 'learning_rate': 0.0059, 'epoch': 15.62}
 41%|████      | 205/500 [35:26<51:00, 10.37s/it] 41%|████      | 206/500 [35:37<50:50, 10.37s/it]                                                 {'loss': 0.4709, 'learning_rate': 0.00588, 'epoch': 15.7}
 41%|████      | 206/500 [35:37<50:50, 10.37s/it] 41%|████▏     | 207/500 [35:47<50:39, 10.37s/it]                                                 {'loss': 0.3325, 'learning_rate': 0.00586, 'epoch': 15.77}
 41%|████▏     | 207/500 [35:47<50:39, 10.37s/it] 42%|████▏     | 208/500 [35:57<50:30, 10.38s/it]                                                 {'loss': 0.4546, 'learning_rate': 0.00584, 'epoch': 15.85}
 42%|████▏     | 208/500 [35:57<50:30, 10.38s/it] 42%|████▏     | 209/500 [36:08<50:20, 10.38s/it]                                                 {'loss': 0.4597, 'learning_rate': 0.00582, 'epoch': 15.92}
 42%|████▏     | 209/500 [36:08<50:20, 10.38s/it] 42%|████▏     | 210/500 [36:18<50:08, 10.38s/it]                                                 {'loss': 0.3374, 'learning_rate': 0.0058, 'epoch': 16.0}
 42%|████▏     | 210/500 [36:18<50:08, 10.38s/it] 42%|████▏     | 211/500 [36:29<49:57, 10.37s/it]                                                 {'loss': 0.411, 'learning_rate': 0.0057799999999999995, 'epoch': 16.08}
 42%|████▏     | 211/500 [36:29<49:57, 10.37s/it] 42%|████▏     | 212/500 [36:39<49:46, 10.37s/it]                                                 {'loss': 0.4164, 'learning_rate': 0.0057599999999999995, 'epoch': 16.15}
 42%|████▏     | 212/500 [36:39<49:46, 10.37s/it] 43%|████▎     | 213/500 [36:49<49:37, 10.37s/it]                                                 {'loss': 0.3782, 'learning_rate': 0.0057399999999999994, 'epoch': 16.23}
 43%|████▎     | 213/500 [36:49<49:37, 10.37s/it] 43%|████▎     | 214/500 [37:00<49:28, 10.38s/it]                                                 {'loss': 0.4264, 'learning_rate': 0.005719999999999999, 'epoch': 16.3}
 43%|████▎     | 214/500 [37:00<49:28, 10.38s/it] 43%|████▎     | 215/500 [37:10<49:17, 10.38s/it]                                                 {'loss': 0.3785, 'learning_rate': 0.005699999999999999, 'epoch': 16.38}
 43%|████▎     | 215/500 [37:10<49:17, 10.38s/it] 43%|████▎     | 216/500 [37:20<49:05, 10.37s/it]                                                 {'loss': 0.364, 'learning_rate': 0.005679999999999999, 'epoch': 16.46}
 43%|████▎     | 216/500 [37:20<49:05, 10.37s/it] 43%|████▎     | 217/500 [37:31<48:58, 10.38s/it]                                                 {'loss': 0.438, 'learning_rate': 0.005659999999999999, 'epoch': 16.53}
 43%|████▎     | 217/500 [37:31<48:58, 10.38s/it] 44%|████▎     | 218/500 [37:41<48:46, 10.38s/it]                                                 {'loss': 0.4422, 'learning_rate': 0.005639999999999999, 'epoch': 16.61}
 44%|████▎     | 218/500 [37:41<48:46, 10.38s/it] 44%|████▍     | 219/500 [37:52<48:34, 10.37s/it]                                                 {'loss': 0.4055, 'learning_rate': 0.005620000000000001, 'epoch': 16.69}
 44%|████▍     | 219/500 [37:52<48:34, 10.37s/it] 44%|████▍     | 220/500 [38:02<48:23, 10.37s/it]                                                 {'loss': 0.4128, 'learning_rate': 0.005600000000000001, 'epoch': 16.76}
 44%|████▍     | 220/500 [38:02<48:23, 10.37s/it] 44%|████▍     | 221/500 [38:12<48:15, 10.38s/it]                                                 {'loss': 0.4363, 'learning_rate': 0.005580000000000001, 'epoch': 16.84}
 44%|████▍     | 221/500 [38:12<48:15, 10.38s/it] 44%|████▍     | 222/500 [38:23<48:02, 10.37s/it]                                                 {'loss': 0.3953, 'learning_rate': 0.005560000000000001, 'epoch': 16.91}
 44%|████▍     | 222/500 [38:23<48:02, 10.37s/it] 45%|████▍     | 223/500 [38:33<47:53, 10.37s/it]                                                 {'loss': 0.4241, 'learning_rate': 0.005540000000000001, 'epoch': 16.99}
 45%|████▍     | 223/500 [38:33<47:53, 10.37s/it] 45%|████▍     | 224/500 [38:43<47:43, 10.37s/it]                                                 {'loss': 0.3927, 'learning_rate': 0.005520000000000001, 'epoch': 17.07}
 45%|████▍     | 224/500 [38:43<47:43, 10.37s/it] 45%|████▌     | 225/500 [38:54<47:30, 10.37s/it]                                                 {'loss': 0.4322, 'learning_rate': 0.0055000000000000005, 'epoch': 17.14}
 45%|████▌     | 225/500 [38:54<47:30, 10.37s/it] 45%|████▌     | 226/500 [39:04<47:19, 10.36s/it]                                                 {'loss': 0.4158, 'learning_rate': 0.0054800000000000005, 'epoch': 17.22}
 45%|████▌     | 226/500 [39:04<47:19, 10.36s/it] 45%|████▌     | 227/500 [39:15<47:10, 10.37s/it]                                                 {'loss': 0.3312, 'learning_rate': 0.0054600000000000004, 'epoch': 17.3}
 45%|████▌     | 227/500 [39:15<47:10, 10.37s/it] 46%|████▌     | 228/500 [39:25<46:58, 10.36s/it]                                                 {'loss': 0.3676, 'learning_rate': 0.00544, 'epoch': 17.37}
 46%|████▌     | 228/500 [39:25<46:58, 10.36s/it] 46%|████▌     | 229/500 [39:35<46:49, 10.37s/it]                                                 {'loss': 0.4514, 'learning_rate': 0.00542, 'epoch': 17.45}
 46%|████▌     | 229/500 [39:35<46:49, 10.37s/it] 46%|████▌     | 230/500 [39:46<46:39, 10.37s/it]                                                 {'loss': 0.4699, 'learning_rate': 0.0054, 'epoch': 17.52}
 46%|████▌     | 230/500 [39:46<46:39, 10.37s/it] 46%|████▌     | 231/500 [39:56<46:29, 10.37s/it]                                                 {'loss': 0.4584, 'learning_rate': 0.00538, 'epoch': 17.6}
 46%|████▌     | 231/500 [39:56<46:29, 10.37s/it] 46%|████▋     | 232/500 [40:06<46:20, 10.37s/it]                                                 {'loss': 0.4098, 'learning_rate': 0.00536, 'epoch': 17.68}
 46%|████▋     | 232/500 [40:06<46:20, 10.37s/it] 47%|████▋     | 233/500 [40:17<46:11, 10.38s/it]                                                 {'loss': 0.3984, 'learning_rate': 0.00534, 'epoch': 17.75}
 47%|████▋     | 233/500 [40:17<46:11, 10.38s/it] 47%|████▋     | 234/500 [40:27<46:02, 10.39s/it]                                                 {'loss': 0.3999, 'learning_rate': 0.00532, 'epoch': 17.83}
 47%|████▋     | 234/500 [40:27<46:02, 10.39s/it] 47%|████▋     | 235/500 [40:38<45:49, 10.38s/it]                                                 {'loss': 0.347, 'learning_rate': 0.0053, 'epoch': 17.9}
 47%|████▋     | 235/500 [40:38<45:49, 10.38s/it] 47%|████▋     | 236/500 [40:48<45:37, 10.37s/it]                                                 {'loss': 0.4025, 'learning_rate': 0.00528, 'epoch': 17.98}
 47%|████▋     | 236/500 [40:48<45:37, 10.37s/it] 47%|████▋     | 237/500 [40:58<45:28, 10.38s/it]                                                 {'loss': 0.4209, 'learning_rate': 0.00526, 'epoch': 18.06}
 47%|████▋     | 237/500 [40:58<45:28, 10.38s/it] 48%|████▊     | 238/500 [41:09<45:16, 10.37s/it]                                                 {'loss': 0.4504, 'learning_rate': 0.005240000000000001, 'epoch': 18.13}
 48%|████▊     | 238/500 [41:09<45:16, 10.37s/it] 48%|████▊     | 239/500 [41:19<45:05, 10.37s/it]                                                 {'loss': 0.4138, 'learning_rate': 0.005220000000000001, 'epoch': 18.21}
 48%|████▊     | 239/500 [41:19<45:05, 10.37s/it] 48%|████▊     | 240/500 [41:29<44:56, 10.37s/it]                                                 {'loss': 0.3544, 'learning_rate': 0.005200000000000001, 'epoch': 18.29}
 48%|████▊     | 240/500 [41:29<44:56, 10.37s/it] 48%|████▊     | 241/500 [41:40<44:45, 10.37s/it]                                                 {'loss': 0.3714, 'learning_rate': 0.005180000000000001, 'epoch': 18.36}
 48%|████▊     | 241/500 [41:40<44:45, 10.37s/it] 48%|████▊     | 242/500 [41:50<44:36, 10.37s/it]                                                 {'loss': 0.3516, 'learning_rate': 0.0051600000000000005, 'epoch': 18.44}
 48%|████▊     | 242/500 [41:50<44:36, 10.37s/it] 49%|████▊     | 243/500 [42:00<44:24, 10.37s/it]                                                 {'loss': 0.43, 'learning_rate': 0.0051400000000000005, 'epoch': 18.51}
 49%|████▊     | 243/500 [42:00<44:24, 10.37s/it] 49%|████▉     | 244/500 [42:11<44:14, 10.37s/it]                                                 {'loss': 0.3672, 'learning_rate': 0.00512, 'epoch': 18.59}
 49%|████▉     | 244/500 [42:11<44:14, 10.37s/it] 49%|████▉     | 245/500 [42:21<44:04, 10.37s/it]                                                 {'loss': 0.4141, 'learning_rate': 0.0051, 'epoch': 18.67}
 49%|████▉     | 245/500 [42:21<44:04, 10.37s/it] 49%|████▉     | 246/500 [42:32<43:55, 10.38s/it]                                                 {'loss': 0.4265, 'learning_rate': 0.00508, 'epoch': 18.74}
 49%|████▉     | 246/500 [42:32<43:55, 10.38s/it] 49%|████▉     | 247/500 [42:42<43:44, 10.38s/it]                                                 {'loss': 0.3551, 'learning_rate': 0.00506, 'epoch': 18.82}
 49%|████▉     | 247/500 [42:42<43:44, 10.38s/it] 50%|████▉     | 248/500 [42:52<43:34, 10.38s/it]                                                 {'loss': 0.442, 'learning_rate': 0.00504, 'epoch': 18.9}
 50%|████▉     | 248/500 [42:52<43:34, 10.38s/it] 50%|████▉     | 249/500 [43:03<43:24, 10.38s/it]                                                 {'loss': 0.3901, 'learning_rate': 0.00502, 'epoch': 18.97}
 50%|████▉     | 249/500 [43:03<43:24, 10.38s/it] 50%|█████     | 250/500 [43:13<43:15, 10.38s/it]                                                 {'loss': 0.4392, 'learning_rate': 0.005, 'epoch': 19.05}
 50%|█████     | 250/500 [43:13<43:15, 10.38s/it] 50%|█████     | 251/500 [43:24<43:02, 10.37s/it]                                                 {'loss': 0.4057, 'learning_rate': 0.00498, 'epoch': 19.12}
 50%|█████     | 251/500 [43:24<43:02, 10.37s/it] 50%|█████     | 252/500 [43:34<42:52, 10.37s/it]                                                 {'loss': 0.3455, 'learning_rate': 0.00496, 'epoch': 19.2}
 50%|█████     | 252/500 [43:34<42:52, 10.37s/it] 51%|█████     | 253/500 [43:44<42:42, 10.38s/it]                                                 {'loss': 0.4086, 'learning_rate': 0.00494, 'epoch': 19.28}
 51%|█████     | 253/500 [43:44<42:42, 10.38s/it] 51%|█████     | 254/500 [43:55<42:29, 10.37s/it]                                                 {'loss': 0.3583, 'learning_rate': 0.00492, 'epoch': 19.35}
 51%|█████     | 254/500 [43:55<42:29, 10.37s/it] 51%|█████     | 255/500 [44:05<42:18, 10.36s/it]                                                 {'loss': 0.4292, 'learning_rate': 0.0049, 'epoch': 19.43}
 51%|█████     | 255/500 [44:05<42:18, 10.36s/it] 51%|█████     | 256/500 [44:15<42:07, 10.36s/it]                                                 {'loss': 0.3848, 'learning_rate': 0.00488, 'epoch': 19.5}
 51%|█████     | 256/500 [44:15<42:07, 10.36s/it] 51%|█████▏    | 257/500 [44:26<41:58, 10.37s/it]                                                 {'loss': 0.3879, 'learning_rate': 0.00486, 'epoch': 19.58}
 51%|█████▏    | 257/500 [44:26<41:58, 10.37s/it] 52%|█████▏    | 258/500 [44:36<41:50, 10.37s/it]                                                 {'loss': 0.4517, 'learning_rate': 0.00484, 'epoch': 19.66}
 52%|█████▏    | 258/500 [44:36<41:50, 10.37s/it] 52%|█████▏    | 259/500 [44:46<41:40, 10.37s/it]                                                 {'loss': 0.3357, 'learning_rate': 0.00482, 'epoch': 19.73}
 52%|█████▏    | 259/500 [44:46<41:40, 10.37s/it] 52%|█████▏    | 260/500 [44:57<41:30, 10.38s/it]                                                 {'loss': 0.404, 'learning_rate': 0.0048, 'epoch': 19.81}
 52%|█████▏    | 260/500 [44:57<41:30, 10.38s/it] 52%|█████▏    | 261/500 [45:07<41:20, 10.38s/it]                                                 {'loss': 0.4408, 'learning_rate': 0.0047799999999999995, 'epoch': 19.89}
 52%|█████▏    | 261/500 [45:07<41:20, 10.38s/it] 52%|█████▏    | 262/500 [45:18<41:12, 10.39s/it]                                                 {'loss': 0.4387, 'learning_rate': 0.0047599999999999995, 'epoch': 19.96}
 52%|█████▏    | 262/500 [45:18<41:12, 10.39s/it] 53%|█████▎    | 263/500 [45:28<40:59, 10.38s/it]                                                 {'loss': 0.3608, 'learning_rate': 0.00474, 'epoch': 20.04}
 53%|█████▎    | 263/500 [45:28<40:59, 10.38s/it] 53%|█████▎    | 264/500 [45:38<40:46, 10.37s/it]                                                 {'loss': 0.3772, 'learning_rate': 0.00472, 'epoch': 20.11}
 53%|█████▎    | 264/500 [45:38<40:46, 10.37s/it] 53%|█████▎    | 265/500 [45:49<40:37, 10.37s/it]                                                 {'loss': 0.3885, 'learning_rate': 0.0047, 'epoch': 20.19}
 53%|█████▎    | 265/500 [45:49<40:37, 10.37s/it] 53%|█████▎    | 266/500 [45:59<40:28, 10.38s/it]                                                 {'loss': 0.3399, 'learning_rate': 0.00468, 'epoch': 20.27}
 53%|█████▎    | 266/500 [45:59<40:28, 10.38s/it] 53%|█████▎    | 267/500 [46:10<40:19, 10.38s/it]                                                 {'loss': 0.3775, 'learning_rate': 0.00466, 'epoch': 20.34}
 53%|█████▎    | 267/500 [46:10<40:19, 10.38s/it] 54%|█████▎    | 268/500 [46:20<40:08, 10.38s/it]                                                 {'loss': 0.3193, 'learning_rate': 0.00464, 'epoch': 20.42}
 54%|█████▎    | 268/500 [46:20<40:08, 10.38s/it] 54%|█████▍    | 269/500 [46:30<39:58, 10.38s/it]                                                 {'loss': 0.3928, 'learning_rate': 0.00462, 'epoch': 20.5}
 54%|█████▍    | 269/500 [46:30<39:58, 10.38s/it] 54%|█████▍    | 270/500 [46:41<39:45, 10.37s/it]                                                 {'loss': 0.4362, 'learning_rate': 0.0046, 'epoch': 20.57}
 54%|█████▍    | 270/500 [46:41<39:45, 10.37s/it] 54%|█████▍    | 271/500 [46:51<39:36, 10.38s/it]                                                 {'loss': 0.36, 'learning_rate': 0.00458, 'epoch': 20.65}
 54%|█████▍    | 271/500 [46:51<39:36, 10.38s/it] 54%|█████▍    | 272/500 [47:01<39:26, 10.38s/it]                                                 {'loss': 0.4454, 'learning_rate': 0.004560000000000001, 'epoch': 20.72}
 54%|█████▍    | 272/500 [47:01<39:26, 10.38s/it] 55%|█████▍    | 273/500 [47:12<39:14, 10.37s/it]                                                 {'loss': 0.3849, 'learning_rate': 0.004540000000000001, 'epoch': 20.8}
 55%|█████▍    | 273/500 [47:12<39:14, 10.37s/it] 55%|█████▍    | 274/500 [47:22<39:05, 10.38s/it]                                                 {'loss': 0.4507, 'learning_rate': 0.004520000000000001, 'epoch': 20.88}
 55%|█████▍    | 274/500 [47:22<39:05, 10.38s/it] 55%|█████▌    | 275/500 [47:33<38:55, 10.38s/it]                                                 {'loss': 0.4471, 'learning_rate': 0.0045000000000000005, 'epoch': 20.95}
 55%|█████▌    | 275/500 [47:33<38:55, 10.38s/it] 55%|█████▌    | 276/500 [47:43<38:44, 10.38s/it]                                                 {'loss': 0.4837, 'learning_rate': 0.0044800000000000005, 'epoch': 21.03}
 55%|█████▌    | 276/500 [47:43<38:44, 10.38s/it] 55%|█████▌    | 277/500 [47:53<38:32, 10.37s/it]                                                 {'loss': 0.417, 'learning_rate': 0.00446, 'epoch': 21.1}
 55%|█████▌    | 277/500 [47:53<38:32, 10.37s/it] 56%|█████▌    | 278/500 [48:04<38:22, 10.37s/it]                                                 {'loss': 0.3521, 'learning_rate': 0.00444, 'epoch': 21.18}
 56%|█████▌    | 278/500 [48:04<38:22, 10.37s/it] 56%|█████▌    | 279/500 [48:14<38:12, 10.38s/it]                                                 {'loss': 0.4344, 'learning_rate': 0.00442, 'epoch': 21.26}
 56%|█████▌    | 279/500 [48:14<38:12, 10.38s/it] 56%|█████▌    | 280/500 [48:24<38:02, 10.38s/it]                                                 {'loss': 0.3861, 'learning_rate': 0.0044, 'epoch': 21.33}
 56%|█████▌    | 280/500 [48:24<38:02, 10.38s/it] 56%|█████▌    | 281/500 [48:35<37:51, 10.37s/it]                                                 {'loss': 0.4687, 'learning_rate': 0.00438, 'epoch': 21.41}
 56%|█████▌    | 281/500 [48:35<37:51, 10.37s/it] 56%|█████▋    | 282/500 [48:45<37:41, 10.37s/it]                                                 {'loss': 0.4582, 'learning_rate': 0.00436, 'epoch': 21.49}
 56%|█████▋    | 282/500 [48:45<37:41, 10.37s/it] 57%|█████▋    | 283/500 [48:56<37:31, 10.38s/it]                                                 {'loss': 0.3828, 'learning_rate': 0.00434, 'epoch': 21.56}
 57%|█████▋    | 283/500 [48:56<37:31, 10.38s/it] 57%|█████▋    | 284/500 [49:06<37:21, 10.38s/it]                                                 {'loss': 0.4717, 'learning_rate': 0.00432, 'epoch': 21.64}
 57%|█████▋    | 284/500 [49:06<37:21, 10.38s/it] 57%|█████▋    | 285/500 [49:16<37:11, 10.38s/it]                                                 {'loss': 0.3939, 'learning_rate': 0.0043, 'epoch': 21.71}
 57%|█████▋    | 285/500 [49:16<37:11, 10.38s/it] 57%|█████▋    | 286/500 [49:27<37:00, 10.38s/it]                                                 {'loss': 0.3067, 'learning_rate': 0.00428, 'epoch': 21.79}
 57%|█████▋    | 286/500 [49:27<37:00, 10.38s/it] 57%|█████▋    | 287/500 [49:37<36:50, 10.38s/it]                                                 {'loss': 0.3752, 'learning_rate': 0.00426, 'epoch': 21.87}
 57%|█████▋    | 287/500 [49:37<36:50, 10.38s/it] 58%|█████▊    | 288/500 [49:47<36:39, 10.38s/it]                                                 {'loss': 0.377, 'learning_rate': 0.00424, 'epoch': 21.94}
 58%|█████▊    | 288/500 [49:47<36:39, 10.38s/it] 58%|█████▊    | 289/500 [49:58<36:30, 10.38s/it]                                                 {'loss': 0.4151, 'learning_rate': 0.00422, 'epoch': 22.02}
 58%|█████▊    | 289/500 [49:58<36:30, 10.38s/it] 58%|█████▊    | 290/500 [50:08<36:19, 10.38s/it]                                                 {'loss': 0.3518, 'learning_rate': 0.0042, 'epoch': 22.1}
 58%|█████▊    | 290/500 [50:08<36:19, 10.38s/it] 58%|█████▊    | 291/500 [50:19<36:08, 10.37s/it]                                                 {'loss': 0.3374, 'learning_rate': 0.00418, 'epoch': 22.17}
 58%|█████▊    | 291/500 [50:19<36:08, 10.37s/it] 58%|█████▊    | 292/500 [50:29<35:58, 10.38s/it]                                                 {'loss': 0.4228, 'learning_rate': 0.00416, 'epoch': 22.25}
 58%|█████▊    | 292/500 [50:29<35:58, 10.38s/it] 59%|█████▊    | 293/500 [50:39<35:46, 10.37s/it]                                                 {'loss': 0.4171, 'learning_rate': 0.00414, 'epoch': 22.32}
 59%|█████▊    | 293/500 [50:39<35:46, 10.37s/it] 59%|█████▉    | 294/500 [50:50<35:37, 10.38s/it]                                                 {'loss': 0.4387, 'learning_rate': 0.0041199999999999995, 'epoch': 22.4}
 59%|█████▉    | 294/500 [50:50<35:37, 10.38s/it] 59%|█████▉    | 295/500 [51:00<35:26, 10.37s/it]                                                 {'loss': 0.3861, 'learning_rate': 0.0040999999999999995, 'epoch': 22.48}
 59%|█████▉    | 295/500 [51:00<35:26, 10.37s/it] 59%|█████▉    | 296/500 [51:10<35:17, 10.38s/it]                                                 {'loss': 0.4059, 'learning_rate': 0.004079999999999999, 'epoch': 22.55}
 59%|█████▉    | 296/500 [51:10<35:17, 10.38s/it] 59%|█████▉    | 297/500 [51:21<35:07, 10.38s/it]                                                 {'loss': 0.3845, 'learning_rate': 0.00406, 'epoch': 22.63}
 59%|█████▉    | 297/500 [51:21<35:07, 10.38s/it] 60%|█████▉    | 298/500 [51:31<34:57, 10.38s/it]                                                 {'loss': 0.412, 'learning_rate': 0.00404, 'epoch': 22.7}
 60%|█████▉    | 298/500 [51:31<34:57, 10.38s/it] 60%|█████▉    | 299/500 [51:42<34:47, 10.38s/it]                                                 {'loss': 0.3916, 'learning_rate': 0.00402, 'epoch': 22.78}
 60%|█████▉    | 299/500 [51:42<34:47, 10.38s/it] 60%|██████    | 300/500 [51:52<34:35, 10.38s/it]                                                 {'loss': 0.3964, 'learning_rate': 0.004, 'epoch': 22.86}
 60%|██████    | 300/500 [51:52<34:35, 10.38s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:483] 2024-01-14 00:53:12,700 >> Configuration saved in output/test-202401132355-128-1e-2/tmp-checkpoint-300/config.json
[INFO|configuration_utils.py:594] 2024-01-14 00:53:12,700 >> Configuration saved in output/test-202401132355-128-1e-2/tmp-checkpoint-300/generation_config.json
[INFO|modeling_utils.py:2382] 2024-01-14 00:53:12,710 >> Model weights saved in output/test-202401132355-128-1e-2/tmp-checkpoint-300/pytorch_model.bin
[INFO|tokenization_utils_base.py:2432] 2024-01-14 00:53:12,711 >> tokenizer config file saved in output/test-202401132355-128-1e-2/tmp-checkpoint-300/tokenizer_config.json
[INFO|tokenization_utils_base.py:2441] 2024-01-14 00:53:12,711 >> Special tokens file saved in output/test-202401132355-128-1e-2/tmp-checkpoint-300/special_tokens_map.json
/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 60%|██████    | 301/500 [52:02<34:26, 10.38s/it]                                                 {'loss': 0.4788, 'learning_rate': 0.00398, 'epoch': 22.93}
 60%|██████    | 301/500 [52:02<34:26, 10.38s/it] 60%|██████    | 302/500 [52:13<34:15, 10.38s/it]                                                 {'loss': 0.4517, 'learning_rate': 0.00396, 'epoch': 23.01}
 60%|██████    | 302/500 [52:13<34:15, 10.38s/it] 61%|██████    | 303/500 [52:23<34:04, 10.38s/it]                                                 {'loss': 0.3864, 'learning_rate': 0.00394, 'epoch': 23.09}
 61%|██████    | 303/500 [52:23<34:04, 10.38s/it] 61%|██████    | 304/500 [52:33<33:53, 10.37s/it]                                                 {'loss': 0.4201, 'learning_rate': 0.00392, 'epoch': 23.16}
 61%|██████    | 304/500 [52:33<33:53, 10.37s/it] 61%|██████    | 305/500 [52:44<33:44, 10.38s/it]                                                 {'loss': 0.4292, 'learning_rate': 0.0039000000000000003, 'epoch': 23.24}
 61%|██████    | 305/500 [52:44<33:44, 10.38s/it] 61%|██████    | 306/500 [52:54<33:32, 10.37s/it]                                                 {'loss': 0.4229, 'learning_rate': 0.00388, 'epoch': 23.31}
 61%|██████    | 306/500 [52:54<33:32, 10.37s/it] 61%|██████▏   | 307/500 [53:05<33:21, 10.37s/it]                                                 {'loss': 0.4426, 'learning_rate': 0.00386, 'epoch': 23.39}
 61%|██████▏   | 307/500 [53:05<33:21, 10.37s/it] 62%|██████▏   | 308/500 [53:15<33:10, 10.37s/it]                                                 {'loss': 0.4496, 'learning_rate': 0.00384, 'epoch': 23.47}
 62%|██████▏   | 308/500 [53:15<33:10, 10.37s/it] 62%|██████▏   | 309/500 [53:25<32:59, 10.37s/it]                                                 {'loss': 0.4187, 'learning_rate': 0.00382, 'epoch': 23.54}
 62%|██████▏   | 309/500 [53:25<32:59, 10.37s/it] 62%|██████▏   | 310/500 [53:36<32:50, 10.37s/it]                                                 {'loss': 0.3819, 'learning_rate': 0.0038, 'epoch': 23.62}
 62%|██████▏   | 310/500 [53:36<32:50, 10.37s/it] 62%|██████▏   | 311/500 [53:46<32:39, 10.37s/it]                                                 {'loss': 0.4225, 'learning_rate': 0.00378, 'epoch': 23.7}
 62%|██████▏   | 311/500 [53:46<32:39, 10.37s/it] 62%|██████▏   | 312/500 [53:56<32:30, 10.37s/it]                                                 {'loss': 0.3733, 'learning_rate': 0.00376, 'epoch': 23.77}
 62%|██████▏   | 312/500 [53:56<32:30, 10.37s/it] 63%|██████▎   | 313/500 [54:07<32:19, 10.37s/it]                                                 {'loss': 0.3715, 'learning_rate': 0.0037400000000000003, 'epoch': 23.85}
 63%|██████▎   | 313/500 [54:07<32:19, 10.37s/it] 63%|██████▎   | 314/500 [54:17<32:08, 10.37s/it]                                                 {'loss': 0.3557, 'learning_rate': 0.00372, 'epoch': 23.92}
 63%|██████▎   | 314/500 [54:17<32:08, 10.37s/it] 63%|██████▎   | 315/500 [54:28<31:58, 10.37s/it]                                                 {'loss': 0.418, 'learning_rate': 0.0037, 'epoch': 24.0}
 63%|██████▎   | 315/500 [54:28<31:58, 10.37s/it] 63%|██████▎   | 316/500 [54:38<31:48, 10.37s/it]                                                 {'loss': 0.4306, 'learning_rate': 0.00368, 'epoch': 24.08}
 63%|██████▎   | 316/500 [54:38<31:48, 10.37s/it] 63%|██████▎   | 317/500 [54:48<31:39, 10.38s/it]                                                 {'loss': 0.4149, 'learning_rate': 0.00366, 'epoch': 24.15}
 63%|██████▎   | 317/500 [54:48<31:39, 10.38s/it] 64%|██████▎   | 318/500 [54:59<31:28, 10.38s/it]                                                 {'loss': 0.3655, 'learning_rate': 0.00364, 'epoch': 24.23}
 64%|██████▎   | 318/500 [54:59<31:28, 10.38s/it] 64%|██████▍   | 319/500 [55:09<31:16, 10.37s/it]                                                 {'loss': 0.4093, 'learning_rate': 0.00362, 'epoch': 24.3}
 64%|██████▍   | 319/500 [55:09<31:16, 10.37s/it] 64%|██████▍   | 320/500 [55:19<31:06, 10.37s/it]                                                 {'loss': 0.4467, 'learning_rate': 0.0036, 'epoch': 24.38}
 64%|██████▍   | 320/500 [55:19<31:06, 10.37s/it] 64%|██████▍   | 321/500 [55:30<30:54, 10.36s/it]                                                 {'loss': 0.3196, 'learning_rate': 0.00358, 'epoch': 24.46}
 64%|██████▍   | 321/500 [55:30<30:54, 10.36s/it] 64%|██████▍   | 322/500 [55:40<30:45, 10.37s/it]                                                 {'loss': 0.4206, 'learning_rate': 0.00356, 'epoch': 24.53}
 64%|██████▍   | 322/500 [55:40<30:45, 10.37s/it] 65%|██████▍   | 323/500 [55:50<30:35, 10.37s/it]                                                 {'loss': 0.3799, 'learning_rate': 0.0035399999999999997, 'epoch': 24.61}
 65%|██████▍   | 323/500 [55:50<30:35, 10.37s/it] 65%|██████▍   | 324/500 [56:01<30:26, 10.38s/it]                                                 {'loss': 0.439, 'learning_rate': 0.0035199999999999997, 'epoch': 24.69}
 65%|██████▍   | 324/500 [56:01<30:26, 10.38s/it] 65%|██████▌   | 325/500 [56:11<30:16, 10.38s/it]                                                 {'loss': 0.4146, 'learning_rate': 0.0034999999999999996, 'epoch': 24.76}
 65%|██████▌   | 325/500 [56:11<30:16, 10.38s/it] 65%|██████▌   | 326/500 [56:22<30:05, 10.38s/it]                                                 {'loss': 0.4028, 'learning_rate': 0.00348, 'epoch': 24.84}
 65%|██████▌   | 326/500 [56:22<30:05, 10.38s/it] 65%|██████▌   | 327/500 [56:32<29:54, 10.38s/it]                                                 {'loss': 0.3971, 'learning_rate': 0.00346, 'epoch': 24.91}
 65%|██████▌   | 327/500 [56:32<29:54, 10.38s/it] 66%|██████▌   | 328/500 [56:42<29:44, 10.38s/it]                                                 {'loss': 0.4732, 'learning_rate': 0.00344, 'epoch': 24.99}
 66%|██████▌   | 328/500 [56:42<29:44, 10.38s/it] 66%|██████▌   | 329/500 [56:53<29:32, 10.37s/it]                                                 {'loss': 0.3487, 'learning_rate': 0.0034200000000000003, 'epoch': 25.07}
 66%|██████▌   | 329/500 [56:53<29:32, 10.37s/it] 66%|██████▌   | 330/500 [57:03<29:23, 10.37s/it]                                                 {'loss': 0.374, 'learning_rate': 0.0034000000000000002, 'epoch': 25.14}
 66%|██████▌   | 330/500 [57:03<29:23, 10.37s/it] 66%|██████▌   | 331/500 [57:13<29:12, 10.37s/it]                                                 {'loss': 0.4149, 'learning_rate': 0.00338, 'epoch': 25.22}
 66%|██████▌   | 331/500 [57:13<29:12, 10.37s/it] 66%|██████▋   | 332/500 [57:24<29:02, 10.37s/it]                                                 {'loss': 0.4566, 'learning_rate': 0.00336, 'epoch': 25.3}
 66%|██████▋   | 332/500 [57:24<29:02, 10.37s/it] 67%|██████▋   | 333/500 [57:34<28:51, 10.37s/it]                                                 {'loss': 0.4077, 'learning_rate': 0.00334, 'epoch': 25.37}
 67%|██████▋   | 333/500 [57:34<28:51, 10.37s/it] 67%|██████▋   | 334/500 [57:45<28:42, 10.37s/it]                                                 {'loss': 0.3864, 'learning_rate': 0.00332, 'epoch': 25.45}
 67%|██████▋   | 334/500 [57:45<28:42, 10.37s/it] 67%|██████▋   | 335/500 [57:55<28:32, 10.38s/it]                                                 {'loss': 0.4026, 'learning_rate': 0.0033000000000000004, 'epoch': 25.52}
 67%|██████▋   | 335/500 [57:55<28:32, 10.38s/it] 67%|██████▋   | 336/500 [58:05<28:21, 10.38s/it]                                                 {'loss': 0.3604, 'learning_rate': 0.0032800000000000004, 'epoch': 25.6}
 67%|██████▋   | 336/500 [58:05<28:21, 10.38s/it] 67%|██████▋   | 337/500 [58:16<28:12, 10.38s/it]                                                 {'loss': 0.4472, 'learning_rate': 0.0032600000000000003, 'epoch': 25.68}
 67%|██████▋   | 337/500 [58:16<28:12, 10.38s/it] 68%|██████▊   | 338/500 [58:26<28:01, 10.38s/it]                                                 {'loss': 0.418, 'learning_rate': 0.0032400000000000003, 'epoch': 25.75}
 68%|██████▊   | 338/500 [58:26<28:01, 10.38s/it] 68%|██████▊   | 339/500 [58:37<27:50, 10.38s/it]                                                 {'loss': 0.3644, 'learning_rate': 0.00322, 'epoch': 25.83}
 68%|██████▊   | 339/500 [58:37<27:50, 10.38s/it] 68%|██████▊   | 340/500 [58:47<27:39, 10.37s/it]                                                 {'loss': 0.4773, 'learning_rate': 0.0032, 'epoch': 25.9}
 68%|██████▊   | 340/500 [58:47<27:39, 10.37s/it] 68%|██████▊   | 341/500 [58:57<27:29, 10.37s/it]                                                 {'loss': 0.4206, 'learning_rate': 0.00318, 'epoch': 25.98}
 68%|██████▊   | 341/500 [58:57<27:29, 10.37s/it] 68%|██████▊   | 342/500 [59:08<27:18, 10.37s/it]                                                 {'loss': 0.506, 'learning_rate': 0.00316, 'epoch': 26.06}
 68%|██████▊   | 342/500 [59:08<27:18, 10.37s/it] 69%|██████▊   | 343/500 [59:18<27:09, 10.38s/it]                                                 {'loss': 0.3848, 'learning_rate': 0.00314, 'epoch': 26.13}
 69%|██████▊   | 343/500 [59:18<27:09, 10.38s/it] 69%|██████▉   | 344/500 [59:28<26:58, 10.38s/it]                                                 {'loss': 0.4066, 'learning_rate': 0.00312, 'epoch': 26.21}
 69%|██████▉   | 344/500 [59:28<26:58, 10.38s/it] 69%|██████▉   | 345/500 [59:39<26:47, 10.37s/it]                                                 {'loss': 0.3505, 'learning_rate': 0.0031, 'epoch': 26.29}
 69%|██████▉   | 345/500 [59:39<26:47, 10.37s/it] 69%|██████▉   | 346/500 [59:49<26:37, 10.37s/it]                                                 {'loss': 0.4602, 'learning_rate': 0.00308, 'epoch': 26.36}
 69%|██████▉   | 346/500 [59:49<26:37, 10.37s/it] 69%|██████▉   | 347/500 [59:59<26:27, 10.37s/it]                                                 {'loss': 0.3768, 'learning_rate': 0.0030600000000000002, 'epoch': 26.44}
 69%|██████▉   | 347/500 [59:59<26:27, 10.37s/it] 70%|██████▉   | 348/500 [1:00:10<26:17, 10.38s/it]                                                   {'loss': 0.4538, 'learning_rate': 0.00304, 'epoch': 26.51}
 70%|██████▉   | 348/500 [1:00:10<26:17, 10.38s/it] 70%|██████▉   | 349/500 [1:00:20<26:07, 10.38s/it]                                                   {'loss': 0.4071, 'learning_rate': 0.00302, 'epoch': 26.59}
 70%|██████▉   | 349/500 [1:00:20<26:07, 10.38s/it] 70%|███████   | 350/500 [1:00:31<25:56, 10.38s/it]                                                   {'loss': 0.381, 'learning_rate': 0.003, 'epoch': 26.67}
 70%|███████   | 350/500 [1:00:31<25:56, 10.38s/it] 70%|███████   | 351/500 [1:00:41<25:46, 10.38s/it]                                                   {'loss': 0.5251, 'learning_rate': 0.00298, 'epoch': 26.74}
 70%|███████   | 351/500 [1:00:41<25:46, 10.38s/it] 70%|███████   | 352/500 [1:00:51<25:35, 10.38s/it]                                                   {'loss': 0.4008, 'learning_rate': 0.00296, 'epoch': 26.82}
 70%|███████   | 352/500 [1:00:51<25:35, 10.38s/it] 71%|███████   | 353/500 [1:01:02<25:24, 10.37s/it]                                                   {'loss': 0.3798, 'learning_rate': 0.00294, 'epoch': 26.9}
 71%|███████   | 353/500 [1:01:02<25:24, 10.37s/it] 71%|███████   | 354/500 [1:01:12<25:13, 10.37s/it]                                                   {'loss': 0.3724, 'learning_rate': 0.00292, 'epoch': 26.97}
 71%|███████   | 354/500 [1:01:12<25:13, 10.37s/it] 71%|███████   | 355/500 [1:01:22<25:03, 10.37s/it]                                                   {'loss': 0.3728, 'learning_rate': 0.0029, 'epoch': 27.05}
 71%|███████   | 355/500 [1:01:22<25:03, 10.37s/it] 71%|███████   | 356/500 [1:01:33<24:53, 10.37s/it]                                                   {'loss': 0.4434, 'learning_rate': 0.0028799999999999997, 'epoch': 27.12}
 71%|███████   | 356/500 [1:01:33<24:53, 10.37s/it] 71%|███████▏  | 357/500 [1:01:43<24:42, 10.37s/it]                                                   {'loss': 0.3784, 'learning_rate': 0.0028599999999999997, 'epoch': 27.2}
 71%|███████▏  | 357/500 [1:01:43<24:42, 10.37s/it] 72%|███████▏  | 358/500 [1:01:54<24:31, 10.36s/it]                                                   {'loss': 0.3674, 'learning_rate': 0.0028399999999999996, 'epoch': 27.28}
 72%|███████▏  | 358/500 [1:01:54<24:31, 10.36s/it] 72%|███████▏  | 359/500 [1:02:04<24:21, 10.37s/it]                                                   {'loss': 0.4469, 'learning_rate': 0.0028199999999999996, 'epoch': 27.35}
 72%|███████▏  | 359/500 [1:02:04<24:21, 10.37s/it] 72%|███████▏  | 360/500 [1:02:14<24:11, 10.37s/it]                                                   {'loss': 0.5038, 'learning_rate': 0.0028000000000000004, 'epoch': 27.43}
 72%|███████▏  | 360/500 [1:02:14<24:11, 10.37s/it] 72%|███████▏  | 361/500 [1:02:25<24:01, 10.37s/it]                                                   {'loss': 0.4164, 'learning_rate': 0.0027800000000000004, 'epoch': 27.5}
 72%|███████▏  | 361/500 [1:02:25<24:01, 10.37s/it] 72%|███████▏  | 362/500 [1:02:35<23:50, 10.36s/it]                                                   {'loss': 0.4434, 'learning_rate': 0.0027600000000000003, 'epoch': 27.58}
 72%|███████▏  | 362/500 [1:02:35<23:50, 10.36s/it] 73%|███████▎  | 363/500 [1:02:45<23:40, 10.37s/it]                                                   {'loss': 0.3322, 'learning_rate': 0.0027400000000000002, 'epoch': 27.66}
 73%|███████▎  | 363/500 [1:02:45<23:40, 10.37s/it] 73%|███████▎  | 364/500 [1:02:56<23:30, 10.37s/it]                                                   {'loss': 0.4671, 'learning_rate': 0.00272, 'epoch': 27.73}
 73%|███████▎  | 364/500 [1:02:56<23:30, 10.37s/it] 73%|███████▎  | 365/500 [1:03:06<23:20, 10.37s/it]                                                   {'loss': 0.4143, 'learning_rate': 0.0027, 'epoch': 27.81}
 73%|███████▎  | 365/500 [1:03:06<23:20, 10.37s/it] 73%|███████▎  | 366/500 [1:03:17<23:09, 10.37s/it]                                                   {'loss': 0.4606, 'learning_rate': 0.00268, 'epoch': 27.89}
 73%|███████▎  | 366/500 [1:03:17<23:09, 10.37s/it] 73%|███████▎  | 367/500 [1:03:27<22:59, 10.37s/it]                                                   {'loss': 0.3333, 'learning_rate': 0.00266, 'epoch': 27.96}
 73%|███████▎  | 367/500 [1:03:27<22:59, 10.37s/it] 74%|███████▎  | 368/500 [1:03:37<22:48, 10.37s/it]                                                   {'loss': 0.4438, 'learning_rate': 0.00264, 'epoch': 28.04}
 74%|███████▎  | 368/500 [1:03:37<22:48, 10.37s/it] 74%|███████▍  | 369/500 [1:03:48<22:38, 10.37s/it]                                                   {'loss': 0.4284, 'learning_rate': 0.0026200000000000004, 'epoch': 28.11}
 74%|███████▍  | 369/500 [1:03:48<22:38, 10.37s/it] 74%|███████▍  | 370/500 [1:03:58<22:29, 10.38s/it]                                                   {'loss': 0.397, 'learning_rate': 0.0026000000000000003, 'epoch': 28.19}
 74%|███████▍  | 370/500 [1:03:58<22:29, 10.38s/it] 74%|███████▍  | 371/500 [1:04:08<22:18, 10.38s/it]                                                   {'loss': 0.4189, 'learning_rate': 0.0025800000000000003, 'epoch': 28.27}
 74%|███████▍  | 371/500 [1:04:08<22:18, 10.38s/it] 74%|███████▍  | 372/500 [1:04:19<22:07, 10.37s/it]                                                   {'loss': 0.4406, 'learning_rate': 0.00256, 'epoch': 28.34}
 74%|███████▍  | 372/500 [1:04:19<22:07, 10.37s/it] 75%|███████▍  | 373/500 [1:04:29<21:56, 10.37s/it]                                                   {'loss': 0.4433, 'learning_rate': 0.00254, 'epoch': 28.42}
 75%|███████▍  | 373/500 [1:04:29<21:56, 10.37s/it] 75%|███████▍  | 374/500 [1:04:40<21:46, 10.37s/it]                                                   {'loss': 0.4165, 'learning_rate': 0.00252, 'epoch': 28.5}
 75%|███████▍  | 374/500 [1:04:40<21:46, 10.37s/it] 75%|███████▌  | 375/500 [1:04:50<21:35, 10.37s/it]                                                   {'loss': 0.4607, 'learning_rate': 0.0025, 'epoch': 28.57}
 75%|███████▌  | 375/500 [1:04:50<21:35, 10.37s/it] 75%|███████▌  | 376/500 [1:05:00<21:25, 10.37s/it]                                                   {'loss': 0.4262, 'learning_rate': 0.00248, 'epoch': 28.65}
 75%|███████▌  | 376/500 [1:05:00<21:25, 10.37s/it] 75%|███████▌  | 377/500 [1:05:11<21:15, 10.37s/it]                                                   {'loss': 0.4594, 'learning_rate': 0.00246, 'epoch': 28.72}
 75%|███████▌  | 377/500 [1:05:11<21:15, 10.37s/it] 76%|███████▌  | 378/500 [1:05:21<21:05, 10.37s/it]                                                   {'loss': 0.4037, 'learning_rate': 0.00244, 'epoch': 28.8}
 76%|███████▌  | 378/500 [1:05:21<21:05, 10.37s/it] 76%|███████▌  | 379/500 [1:05:31<20:54, 10.37s/it]                                                   {'loss': 0.3891, 'learning_rate': 0.00242, 'epoch': 28.88}
 76%|███████▌  | 379/500 [1:05:31<20:54, 10.37s/it] 76%|███████▌  | 380/500 [1:05:42<20:44, 10.37s/it]                                                   {'loss': 0.4469, 'learning_rate': 0.0024, 'epoch': 28.95}
 76%|███████▌  | 380/500 [1:05:42<20:44, 10.37s/it] 76%|███████▌  | 381/500 [1:05:52<20:34, 10.37s/it]                                                   {'loss': 0.3609, 'learning_rate': 0.0023799999999999997, 'epoch': 29.03}
 76%|███████▌  | 381/500 [1:05:52<20:34, 10.37s/it] 76%|███████▋  | 382/500 [1:06:03<20:24, 10.38s/it]                                                   {'loss': 0.3927, 'learning_rate': 0.00236, 'epoch': 29.1}
 76%|███████▋  | 382/500 [1:06:03<20:24, 10.38s/it] 77%|███████▋  | 383/500 [1:06:13<20:14, 10.38s/it]                                                   {'loss': 0.4806, 'learning_rate': 0.00234, 'epoch': 29.18}
 77%|███████▋  | 383/500 [1:06:13<20:14, 10.38s/it] 77%|███████▋  | 384/500 [1:06:23<20:03, 10.37s/it]                                                   {'loss': 0.4232, 'learning_rate': 0.00232, 'epoch': 29.26}
 77%|███████▋  | 384/500 [1:06:23<20:03, 10.37s/it] 77%|███████▋  | 385/500 [1:06:34<19:52, 10.37s/it]                                                   {'loss': 0.3914, 'learning_rate': 0.0023, 'epoch': 29.33}
 77%|███████▋  | 385/500 [1:06:34<19:52, 10.37s/it] 77%|███████▋  | 386/500 [1:06:44<19:42, 10.37s/it]                                                   {'loss': 0.4391, 'learning_rate': 0.0022800000000000003, 'epoch': 29.41}
 77%|███████▋  | 386/500 [1:06:44<19:42, 10.37s/it] 77%|███████▋  | 387/500 [1:06:54<19:32, 10.37s/it]                                                   {'loss': 0.4762, 'learning_rate': 0.0022600000000000003, 'epoch': 29.49}
 77%|███████▋  | 387/500 [1:06:54<19:32, 10.37s/it] 78%|███████▊  | 388/500 [1:07:05<19:22, 10.38s/it]                                                   {'loss': 0.3756, 'learning_rate': 0.0022400000000000002, 'epoch': 29.56}
 78%|███████▊  | 388/500 [1:07:05<19:22, 10.38s/it] 78%|███████▊  | 389/500 [1:07:15<19:12, 10.38s/it]                                                   {'loss': 0.4344, 'learning_rate': 0.00222, 'epoch': 29.64}
 78%|███████▊  | 389/500 [1:07:15<19:12, 10.38s/it] 78%|███████▊  | 390/500 [1:07:26<19:01, 10.38s/it]                                                   {'loss': 0.4158, 'learning_rate': 0.0022, 'epoch': 29.71}
 78%|███████▊  | 390/500 [1:07:26<19:01, 10.38s/it] 78%|███████▊  | 391/500 [1:07:36<18:50, 10.37s/it]                                                   {'loss': 0.4991, 'learning_rate': 0.00218, 'epoch': 29.79}
 78%|███████▊  | 391/500 [1:07:36<18:50, 10.37s/it] 78%|███████▊  | 392/500 [1:07:46<18:39, 10.37s/it]                                                   {'loss': 0.4084, 'learning_rate': 0.00216, 'epoch': 29.87}
 78%|███████▊  | 392/500 [1:07:46<18:39, 10.37s/it] 79%|███████▊  | 393/500 [1:07:57<18:29, 10.37s/it]                                                   {'loss': 0.4084, 'learning_rate': 0.00214, 'epoch': 29.94}
 79%|███████▊  | 393/500 [1:07:57<18:29, 10.37s/it] 79%|███████▉  | 394/500 [1:08:07<18:19, 10.37s/it]                                                   {'loss': 0.4547, 'learning_rate': 0.00212, 'epoch': 30.02}
 79%|███████▉  | 394/500 [1:08:07<18:19, 10.37s/it] 79%|███████▉  | 395/500 [1:08:17<18:09, 10.38s/it]                                                   {'loss': 0.5305, 'learning_rate': 0.0021, 'epoch': 30.1}
 79%|███████▉  | 395/500 [1:08:17<18:09, 10.38s/it] 79%|███████▉  | 396/500 [1:08:28<17:59, 10.38s/it]                                                   {'loss': 0.4387, 'learning_rate': 0.00208, 'epoch': 30.17}
 79%|███████▉  | 396/500 [1:08:28<17:59, 10.38s/it] 79%|███████▉  | 397/500 [1:08:38<17:47, 10.37s/it]                                                   {'loss': 0.4475, 'learning_rate': 0.0020599999999999998, 'epoch': 30.25}
 79%|███████▉  | 397/500 [1:08:38<17:47, 10.37s/it] 80%|███████▉  | 398/500 [1:08:48<17:37, 10.37s/it]                                                   {'loss': 0.4619, 'learning_rate': 0.0020399999999999997, 'epoch': 30.32}
 80%|███████▉  | 398/500 [1:08:48<17:37, 10.37s/it] 80%|███████▉  | 399/500 [1:08:59<17:26, 10.37s/it]                                                   {'loss': 0.4649, 'learning_rate': 0.00202, 'epoch': 30.4}
 80%|███████▉  | 399/500 [1:08:59<17:26, 10.37s/it] 80%|████████  | 400/500 [1:09:09<17:16, 10.37s/it]                                                   {'loss': 0.4048, 'learning_rate': 0.002, 'epoch': 30.48}
 80%|████████  | 400/500 [1:09:09<17:16, 10.37s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:483] 2024-01-14 01:10:29,955 >> Configuration saved in output/test-202401132355-128-1e-2/tmp-checkpoint-400/config.json
[INFO|configuration_utils.py:594] 2024-01-14 01:10:29,955 >> Configuration saved in output/test-202401132355-128-1e-2/tmp-checkpoint-400/generation_config.json
[INFO|modeling_utils.py:2382] 2024-01-14 01:10:29,965 >> Model weights saved in output/test-202401132355-128-1e-2/tmp-checkpoint-400/pytorch_model.bin
[INFO|tokenization_utils_base.py:2432] 2024-01-14 01:10:29,966 >> tokenizer config file saved in output/test-202401132355-128-1e-2/tmp-checkpoint-400/tokenizer_config.json
[INFO|tokenization_utils_base.py:2441] 2024-01-14 01:10:29,966 >> Special tokens file saved in output/test-202401132355-128-1e-2/tmp-checkpoint-400/special_tokens_map.json
/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
 80%|████████  | 401/500 [1:09:20<17:07, 10.38s/it]                                                   {'loss': 0.3715, 'learning_rate': 0.00198, 'epoch': 30.55}
 80%|████████  | 401/500 [1:09:20<17:07, 10.38s/it] 80%|████████  | 402/500 [1:09:30<16:57, 10.38s/it]                                                   {'loss': 0.388, 'learning_rate': 0.00196, 'epoch': 30.63}
 80%|████████  | 402/500 [1:09:30<16:57, 10.38s/it] 81%|████████  | 403/500 [1:09:40<16:46, 10.38s/it]                                                   {'loss': 0.4022, 'learning_rate': 0.00194, 'epoch': 30.7}
 81%|████████  | 403/500 [1:09:40<16:46, 10.38s/it] 81%|████████  | 404/500 [1:09:51<16:36, 10.38s/it]                                                   {'loss': 0.3753, 'learning_rate': 0.00192, 'epoch': 30.78}
 81%|████████  | 404/500 [1:09:51<16:36, 10.38s/it] 81%|████████  | 405/500 [1:10:01<16:25, 10.38s/it]                                                   {'loss': 0.4576, 'learning_rate': 0.0019, 'epoch': 30.86}
 81%|████████  | 405/500 [1:10:01<16:25, 10.38s/it] 81%|████████  | 406/500 [1:10:11<16:14, 10.37s/it]                                                   {'loss': 0.4332, 'learning_rate': 0.00188, 'epoch': 30.93}
 81%|████████  | 406/500 [1:10:11<16:14, 10.37s/it] 81%|████████▏ | 407/500 [1:10:22<16:04, 10.37s/it]                                                   {'loss': 0.4142, 'learning_rate': 0.00186, 'epoch': 31.01}
 81%|████████▏ | 407/500 [1:10:22<16:04, 10.37s/it] 82%|████████▏ | 408/500 [1:10:32<15:53, 10.37s/it]                                                   {'loss': 0.414, 'learning_rate': 0.00184, 'epoch': 31.09}
 82%|████████▏ | 408/500 [1:10:32<15:53, 10.37s/it] 82%|████████▏ | 409/500 [1:10:43<15:43, 10.37s/it]                                                   {'loss': 0.4694, 'learning_rate': 0.00182, 'epoch': 31.16}
 82%|████████▏ | 409/500 [1:10:43<15:43, 10.37s/it] 82%|████████▏ | 410/500 [1:10:53<15:32, 10.37s/it]                                                   {'loss': 0.4131, 'learning_rate': 0.0018, 'epoch': 31.24}
 82%|████████▏ | 410/500 [1:10:53<15:32, 10.37s/it] 82%|████████▏ | 411/500 [1:11:03<15:22, 10.37s/it]                                                   {'loss': 0.4333, 'learning_rate': 0.00178, 'epoch': 31.31}
 82%|████████▏ | 411/500 [1:11:03<15:22, 10.37s/it] 82%|████████▏ | 412/500 [1:11:14<15:12, 10.37s/it]                                                   {'loss': 0.39, 'learning_rate': 0.0017599999999999998, 'epoch': 31.39}
 82%|████████▏ | 412/500 [1:11:14<15:12, 10.37s/it] 83%|████████▎ | 413/500 [1:11:24<15:02, 10.37s/it]                                                   {'loss': 0.3536, 'learning_rate': 0.00174, 'epoch': 31.47}
 83%|████████▎ | 413/500 [1:11:24<15:02, 10.37s/it] 83%|████████▎ | 414/500 [1:11:34<14:51, 10.37s/it]                                                   {'loss': 0.4547, 'learning_rate': 0.00172, 'epoch': 31.54}
 83%|████████▎ | 414/500 [1:11:34<14:51, 10.37s/it] 83%|████████▎ | 415/500 [1:11:45<14:41, 10.38s/it]                                                   {'loss': 0.4799, 'learning_rate': 0.0017000000000000001, 'epoch': 31.62}
 83%|████████▎ | 415/500 [1:11:45<14:41, 10.38s/it] 83%|████████▎ | 416/500 [1:11:55<14:31, 10.37s/it]                                                   {'loss': 0.4398, 'learning_rate': 0.00168, 'epoch': 31.7}
 83%|████████▎ | 416/500 [1:11:55<14:31, 10.37s/it] 83%|████████▎ | 417/500 [1:12:06<14:21, 10.38s/it]                                                   {'loss': 0.4928, 'learning_rate': 0.00166, 'epoch': 31.77}
 83%|████████▎ | 417/500 [1:12:06<14:21, 10.38s/it] 84%|████████▎ | 418/500 [1:12:16<14:11, 10.38s/it]                                                   {'loss': 0.4445, 'learning_rate': 0.0016400000000000002, 'epoch': 31.85}
 84%|████████▎ | 418/500 [1:12:16<14:11, 10.38s/it] 84%|████████▍ | 419/500 [1:12:26<14:01, 10.38s/it]                                                   {'loss': 0.4494, 'learning_rate': 0.0016200000000000001, 'epoch': 31.92}
 84%|████████▍ | 419/500 [1:12:26<14:01, 10.38s/it] 84%|████████▍ | 420/500 [1:12:37<13:49, 10.37s/it]                                                   {'loss': 0.3544, 'learning_rate': 0.0016, 'epoch': 32.0}
 84%|████████▍ | 420/500 [1:12:37<13:49, 10.37s/it] 84%|████████▍ | 421/500 [1:12:47<13:39, 10.37s/it]                                                   {'loss': 0.3947, 'learning_rate': 0.00158, 'epoch': 32.08}
 84%|████████▍ | 421/500 [1:12:47<13:39, 10.37s/it] 84%|████████▍ | 422/500 [1:12:57<13:29, 10.38s/it]                                                   {'loss': 0.5143, 'learning_rate': 0.00156, 'epoch': 32.15}
 84%|████████▍ | 422/500 [1:12:57<13:29, 10.38s/it] 85%|████████▍ | 423/500 [1:13:08<13:19, 10.38s/it]                                                   {'loss': 0.5183, 'learning_rate': 0.00154, 'epoch': 32.23}
 85%|████████▍ | 423/500 [1:13:08<13:19, 10.38s/it] 85%|████████▍ | 424/500 [1:13:18<13:08, 10.38s/it]                                                   {'loss': 0.415, 'learning_rate': 0.00152, 'epoch': 32.3}
 85%|████████▍ | 424/500 [1:13:18<13:08, 10.38s/it] 85%|████████▌ | 425/500 [1:13:29<12:58, 10.38s/it]                                                   {'loss': 0.4285, 'learning_rate': 0.0015, 'epoch': 32.38}
 85%|████████▌ | 425/500 [1:13:29<12:58, 10.38s/it] 85%|████████▌ | 426/500 [1:13:39<12:48, 10.38s/it]                                                   {'loss': 0.3882, 'learning_rate': 0.00148, 'epoch': 32.46}
 85%|████████▌ | 426/500 [1:13:39<12:48, 10.38s/it] 85%|████████▌ | 427/500 [1:13:49<12:37, 10.38s/it]                                                   {'loss': 0.4664, 'learning_rate': 0.00146, 'epoch': 32.53}
 85%|████████▌ | 427/500 [1:13:49<12:37, 10.38s/it] 86%|████████▌ | 428/500 [1:14:00<12:27, 10.38s/it]                                                   {'loss': 0.4518, 'learning_rate': 0.0014399999999999999, 'epoch': 32.61}
 86%|████████▌ | 428/500 [1:14:00<12:27, 10.38s/it] 86%|████████▌ | 429/500 [1:14:10<12:16, 10.37s/it]                                                   {'loss': 0.4252, 'learning_rate': 0.0014199999999999998, 'epoch': 32.69}
 86%|████████▌ | 429/500 [1:14:10<12:16, 10.37s/it] 86%|████████▌ | 430/500 [1:14:20<12:05, 10.37s/it]                                                   {'loss': 0.4547, 'learning_rate': 0.0014000000000000002, 'epoch': 32.76}
 86%|████████▌ | 430/500 [1:14:20<12:05, 10.37s/it] 86%|████████▌ | 431/500 [1:14:31<11:55, 10.37s/it]                                                   {'loss': 0.4168, 'learning_rate': 0.0013800000000000002, 'epoch': 32.84}
 86%|████████▌ | 431/500 [1:14:31<11:55, 10.37s/it] 86%|████████▋ | 432/500 [1:14:41<11:44, 10.36s/it]                                                   {'loss': 0.4671, 'learning_rate': 0.00136, 'epoch': 32.91}
 86%|████████▋ | 432/500 [1:14:41<11:44, 10.36s/it] 87%|████████▋ | 433/500 [1:14:52<11:34, 10.36s/it]                                                   {'loss': 0.3625, 'learning_rate': 0.00134, 'epoch': 32.99}
 87%|████████▋ | 433/500 [1:14:52<11:34, 10.36s/it] 87%|████████▋ | 434/500 [1:15:02<11:24, 10.37s/it]                                                   {'loss': 0.4118, 'learning_rate': 0.00132, 'epoch': 33.07}
 87%|████████▋ | 434/500 [1:15:02<11:24, 10.37s/it] 87%|████████▋ | 435/500 [1:15:12<11:14, 10.37s/it]                                                   {'loss': 0.4726, 'learning_rate': 0.0013000000000000002, 'epoch': 33.14}
 87%|████████▋ | 435/500 [1:15:12<11:14, 10.37s/it] 87%|████████▋ | 436/500 [1:15:23<11:03, 10.37s/it]                                                   {'loss': 0.4929, 'learning_rate': 0.00128, 'epoch': 33.22}
 87%|████████▋ | 436/500 [1:15:23<11:03, 10.37s/it] 87%|████████▋ | 437/500 [1:15:33<10:53, 10.37s/it]                                                   {'loss': 0.4234, 'learning_rate': 0.00126, 'epoch': 33.3}
 87%|████████▋ | 437/500 [1:15:33<10:53, 10.37s/it] 88%|████████▊ | 438/500 [1:15:43<10:42, 10.36s/it]                                                   {'loss': 0.3983, 'learning_rate': 0.00124, 'epoch': 33.37}
 88%|████████▊ | 438/500 [1:15:43<10:42, 10.36s/it] 88%|████████▊ | 439/500 [1:15:54<10:32, 10.36s/it]                                                   {'loss': 0.4307, 'learning_rate': 0.00122, 'epoch': 33.45}
 88%|████████▊ | 439/500 [1:15:54<10:32, 10.36s/it] 88%|████████▊ | 440/500 [1:16:04<10:21, 10.36s/it]                                                   {'loss': 0.4529, 'learning_rate': 0.0012, 'epoch': 33.52}
 88%|████████▊ | 440/500 [1:16:04<10:21, 10.36s/it] 88%|████████▊ | 441/500 [1:16:14<10:11, 10.37s/it]                                                   {'loss': 0.4641, 'learning_rate': 0.00118, 'epoch': 33.6}
 88%|████████▊ | 441/500 [1:16:14<10:11, 10.37s/it] 88%|████████▊ | 442/500 [1:16:25<10:01, 10.37s/it]                                                   {'loss': 0.4568, 'learning_rate': 0.00116, 'epoch': 33.68}
 88%|████████▊ | 442/500 [1:16:25<10:01, 10.37s/it] 89%|████████▊ | 443/500 [1:16:35<09:51, 10.37s/it]                                                   {'loss': 0.3335, 'learning_rate': 0.0011400000000000002, 'epoch': 33.75}
 89%|████████▊ | 443/500 [1:16:35<09:51, 10.37s/it] 89%|████████▉ | 444/500 [1:16:46<09:40, 10.37s/it]                                                   {'loss': 0.4719, 'learning_rate': 0.0011200000000000001, 'epoch': 33.83}
 89%|████████▉ | 444/500 [1:16:46<09:40, 10.37s/it] 89%|████████▉ | 445/500 [1:16:56<09:30, 10.37s/it]                                                   {'loss': 0.456, 'learning_rate': 0.0011, 'epoch': 33.9}
 89%|████████▉ | 445/500 [1:16:56<09:30, 10.37s/it] 89%|████████▉ | 446/500 [1:17:06<09:20, 10.38s/it]                                                   {'loss': 0.4372, 'learning_rate': 0.00108, 'epoch': 33.98}
 89%|████████▉ | 446/500 [1:17:06<09:20, 10.38s/it] 89%|████████▉ | 447/500 [1:17:17<09:10, 10.38s/it]                                                   {'loss': 0.3848, 'learning_rate': 0.00106, 'epoch': 34.06}
 89%|████████▉ | 447/500 [1:17:17<09:10, 10.38s/it] 90%|████████▉ | 448/500 [1:17:27<08:59, 10.38s/it]                                                   {'loss': 0.389, 'learning_rate': 0.00104, 'epoch': 34.13}
 90%|████████▉ | 448/500 [1:17:27<08:59, 10.38s/it] 90%|████████▉ | 449/500 [1:17:38<08:49, 10.39s/it]                                                   {'loss': 0.4522, 'learning_rate': 0.0010199999999999999, 'epoch': 34.21}
 90%|████████▉ | 449/500 [1:17:38<08:49, 10.39s/it] 90%|█████████ | 450/500 [1:17:48<08:38, 10.38s/it]                                                   {'loss': 0.3644, 'learning_rate': 0.001, 'epoch': 34.29}
 90%|█████████ | 450/500 [1:17:48<08:38, 10.38s/it] 90%|█████████ | 451/500 [1:17:58<08:28, 10.37s/it]                                                   {'loss': 0.4313, 'learning_rate': 0.00098, 'epoch': 34.36}
 90%|█████████ | 451/500 [1:17:58<08:28, 10.37s/it] 90%|█████████ | 452/500 [1:18:09<08:18, 10.38s/it]                                                   {'loss': 0.466, 'learning_rate': 0.00096, 'epoch': 34.44}
 90%|█████████ | 452/500 [1:18:09<08:18, 10.38s/it] 91%|█████████ | 453/500 [1:18:19<08:07, 10.37s/it]                                                   {'loss': 0.3867, 'learning_rate': 0.00094, 'epoch': 34.51}
 91%|█████████ | 453/500 [1:18:19<08:07, 10.37s/it] 91%|█████████ | 454/500 [1:18:29<07:57, 10.38s/it]                                                   {'loss': 0.5134, 'learning_rate': 0.00092, 'epoch': 34.59}
 91%|█████████ | 454/500 [1:18:29<07:57, 10.38s/it] 91%|█████████ | 455/500 [1:18:40<07:46, 10.37s/it]                                                   {'loss': 0.4152, 'learning_rate': 0.0009, 'epoch': 34.67}
 91%|█████████ | 455/500 [1:18:40<07:46, 10.37s/it] 91%|█████████ | 456/500 [1:18:50<07:36, 10.37s/it]                                                   {'loss': 0.4913, 'learning_rate': 0.0008799999999999999, 'epoch': 34.74}
 91%|█████████ | 456/500 [1:18:50<07:36, 10.37s/it] 91%|█████████▏| 457/500 [1:19:00<07:25, 10.37s/it]                                                   {'loss': 0.4903, 'learning_rate': 0.00086, 'epoch': 34.82}
 91%|█████████▏| 457/500 [1:19:00<07:25, 10.37s/it] 92%|█████████▏| 458/500 [1:19:11<07:15, 10.37s/it]                                                   {'loss': 0.4373, 'learning_rate': 0.00084, 'epoch': 34.9}
 92%|█████████▏| 458/500 [1:19:11<07:15, 10.37s/it] 92%|█████████▏| 459/500 [1:19:21<07:05, 10.37s/it]                                                   {'loss': 0.4973, 'learning_rate': 0.0008200000000000001, 'epoch': 34.97}
 92%|█████████▏| 459/500 [1:19:21<07:05, 10.37s/it] 92%|█████████▏| 460/500 [1:19:32<06:54, 10.37s/it]                                                   {'loss': 0.3606, 'learning_rate': 0.0008, 'epoch': 35.05}
 92%|█████████▏| 460/500 [1:19:32<06:54, 10.37s/it] 92%|█████████▏| 461/500 [1:19:42<06:44, 10.37s/it]                                                   {'loss': 0.4188, 'learning_rate': 0.00078, 'epoch': 35.12}
 92%|█████████▏| 461/500 [1:19:42<06:44, 10.37s/it] 92%|█████████▏| 462/500 [1:19:52<06:33, 10.36s/it]                                                   {'loss': 0.4093, 'learning_rate': 0.00076, 'epoch': 35.2}
 92%|█████████▏| 462/500 [1:19:52<06:33, 10.36s/it] 93%|█████████▎| 463/500 [1:20:03<06:23, 10.36s/it]                                                   {'loss': 0.507, 'learning_rate': 0.00074, 'epoch': 35.28}
 93%|█████████▎| 463/500 [1:20:03<06:23, 10.36s/it] 93%|█████████▎| 464/500 [1:20:13<06:12, 10.36s/it]                                                   {'loss': 0.3865, 'learning_rate': 0.0007199999999999999, 'epoch': 35.35}
 93%|█████████▎| 464/500 [1:20:13<06:12, 10.36s/it] 93%|█████████▎| 465/500 [1:20:23<06:02, 10.36s/it]                                                   {'loss': 0.4946, 'learning_rate': 0.0007000000000000001, 'epoch': 35.43}
 93%|█████████▎| 465/500 [1:20:23<06:02, 10.36s/it] 93%|█████████▎| 466/500 [1:20:34<05:52, 10.36s/it]                                                   {'loss': 0.4118, 'learning_rate': 0.00068, 'epoch': 35.5}
 93%|█████████▎| 466/500 [1:20:34<05:52, 10.36s/it] 93%|█████████▎| 467/500 [1:20:44<05:41, 10.36s/it]                                                   {'loss': 0.3611, 'learning_rate': 0.00066, 'epoch': 35.58}
 93%|█████████▎| 467/500 [1:20:44<05:41, 10.36s/it] 94%|█████████▎| 468/500 [1:20:54<05:31, 10.36s/it]                                                   {'loss': 0.4665, 'learning_rate': 0.00064, 'epoch': 35.66}
 94%|█████████▎| 468/500 [1:20:54<05:31, 10.36s/it] 94%|█████████▍| 469/500 [1:21:05<05:21, 10.37s/it]                                                   {'loss': 0.3962, 'learning_rate': 0.00062, 'epoch': 35.73}
 94%|█████████▍| 469/500 [1:21:05<05:21, 10.37s/it] 94%|█████████▍| 470/500 [1:21:15<05:11, 10.37s/it]                                                   {'loss': 0.4839, 'learning_rate': 0.0006, 'epoch': 35.81}
 94%|█████████▍| 470/500 [1:21:15<05:11, 10.37s/it] 94%|█████████▍| 471/500 [1:21:26<05:00, 10.37s/it]                                                   {'loss': 0.5095, 'learning_rate': 0.00058, 'epoch': 35.89}
 94%|█████████▍| 471/500 [1:21:26<05:00, 10.37s/it] 94%|█████████▍| 472/500 [1:21:36<04:50, 10.37s/it]                                                   {'loss': 0.4984, 'learning_rate': 0.0005600000000000001, 'epoch': 35.96}
 94%|█████████▍| 472/500 [1:21:36<04:50, 10.37s/it] 95%|█████████▍| 473/500 [1:21:46<04:40, 10.37s/it]                                                   {'loss': 0.4704, 'learning_rate': 0.00054, 'epoch': 36.04}
 95%|█████████▍| 473/500 [1:21:46<04:40, 10.37s/it] 95%|█████████▍| 474/500 [1:21:57<04:29, 10.38s/it]                                                   {'loss': 0.3887, 'learning_rate': 0.00052, 'epoch': 36.11}
 95%|█████████▍| 474/500 [1:21:57<04:29, 10.38s/it] 95%|█████████▌| 475/500 [1:22:07<04:19, 10.37s/it]                                                   {'loss': 0.3884, 'learning_rate': 0.0005, 'epoch': 36.19}
 95%|█████████▌| 475/500 [1:22:07<04:19, 10.37s/it] 95%|█████████▌| 476/500 [1:22:17<04:08, 10.37s/it]                                                   {'loss': 0.3712, 'learning_rate': 0.00048, 'epoch': 36.27}
 95%|█████████▌| 476/500 [1:22:17<04:08, 10.37s/it] 95%|█████████▌| 477/500 [1:22:28<03:58, 10.37s/it]                                                   {'loss': 0.4371, 'learning_rate': 0.00046, 'epoch': 36.34}
 95%|█████████▌| 477/500 [1:22:28<03:58, 10.37s/it] 96%|█████████▌| 478/500 [1:22:38<03:48, 10.37s/it]                                                   {'loss': 0.4104, 'learning_rate': 0.00043999999999999996, 'epoch': 36.42}
 96%|█████████▌| 478/500 [1:22:38<03:48, 10.37s/it] 96%|█████████▌| 479/500 [1:22:49<03:37, 10.37s/it]                                                   {'loss': 0.5156, 'learning_rate': 0.00042, 'epoch': 36.5}
 96%|█████████▌| 479/500 [1:22:49<03:37, 10.37s/it] 96%|█████████▌| 480/500 [1:22:59<03:27, 10.37s/it]                                                   {'loss': 0.4763, 'learning_rate': 0.0004, 'epoch': 36.57}
 96%|█████████▌| 480/500 [1:22:59<03:27, 10.37s/it] 96%|█████████▌| 481/500 [1:23:09<03:17, 10.37s/it]                                                   {'loss': 0.4204, 'learning_rate': 0.00038, 'epoch': 36.65}
 96%|█████████▌| 481/500 [1:23:09<03:17, 10.37s/it] 96%|█████████▋| 482/500 [1:23:20<03:06, 10.37s/it]                                                   {'loss': 0.5401, 'learning_rate': 0.00035999999999999997, 'epoch': 36.72}
 96%|█████████▋| 482/500 [1:23:20<03:06, 10.37s/it] 97%|█████████▋| 483/500 [1:23:30<02:56, 10.37s/it]                                                   {'loss': 0.4165, 'learning_rate': 0.00034, 'epoch': 36.8}
 97%|█████████▋| 483/500 [1:23:30<02:56, 10.37s/it] 97%|█████████▋| 484/500 [1:23:40<02:46, 10.38s/it]                                                   {'loss': 0.4835, 'learning_rate': 0.00032, 'epoch': 36.88}
 97%|█████████▋| 484/500 [1:23:40<02:46, 10.38s/it] 97%|█████████▋| 485/500 [1:23:51<02:35, 10.38s/it]                                                   {'loss': 0.502, 'learning_rate': 0.0003, 'epoch': 36.95}
 97%|█████████▋| 485/500 [1:23:51<02:35, 10.38s/it] 97%|█████████▋| 486/500 [1:24:01<02:25, 10.39s/it]                                                   {'loss': 0.4928, 'learning_rate': 0.00028000000000000003, 'epoch': 37.03}
 97%|█████████▋| 486/500 [1:24:01<02:25, 10.39s/it] 97%|█████████▋| 487/500 [1:24:12<02:14, 10.38s/it]                                                   {'loss': 0.4718, 'learning_rate': 0.00026, 'epoch': 37.1}
 97%|█████████▋| 487/500 [1:24:12<02:14, 10.38s/it] 98%|█████████▊| 488/500 [1:24:22<02:04, 10.38s/it]                                                   {'loss': 0.4046, 'learning_rate': 0.00024, 'epoch': 37.18}
 98%|█████████▊| 488/500 [1:24:22<02:04, 10.38s/it] 98%|█████████▊| 489/500 [1:24:32<01:54, 10.37s/it]                                                   {'loss': 0.4487, 'learning_rate': 0.00021999999999999998, 'epoch': 37.26}
 98%|█████████▊| 489/500 [1:24:32<01:54, 10.37s/it] 98%|█████████▊| 490/500 [1:24:43<01:43, 10.37s/it]                                                   {'loss': 0.4652, 'learning_rate': 0.0002, 'epoch': 37.33}
 98%|█████████▊| 490/500 [1:24:43<01:43, 10.37s/it] 98%|█████████▊| 491/500 [1:24:53<01:33, 10.38s/it]                                                   {'loss': 0.4781, 'learning_rate': 0.00017999999999999998, 'epoch': 37.41}
 98%|█████████▊| 491/500 [1:24:53<01:33, 10.38s/it] 98%|█████████▊| 492/500 [1:25:03<01:23, 10.38s/it]                                                   {'loss': 0.4539, 'learning_rate': 0.00016, 'epoch': 37.49}
 98%|█████████▊| 492/500 [1:25:03<01:23, 10.38s/it] 99%|█████████▊| 493/500 [1:25:14<01:12, 10.38s/it]                                                   {'loss': 0.4074, 'learning_rate': 0.00014000000000000001, 'epoch': 37.56}
 99%|█████████▊| 493/500 [1:25:14<01:12, 10.38s/it] 99%|█████████▉| 494/500 [1:25:24<01:02, 10.37s/it]                                                   {'loss': 0.4907, 'learning_rate': 0.00012, 'epoch': 37.64}
 99%|█████████▉| 494/500 [1:25:24<01:02, 10.37s/it] 99%|█████████▉| 495/500 [1:25:35<00:51, 10.36s/it]                                                   {'loss': 0.2863, 'learning_rate': 0.0001, 'epoch': 37.71}
 99%|█████████▉| 495/500 [1:25:35<00:51, 10.36s/it] 99%|█████████▉| 496/500 [1:25:45<00:41, 10.37s/it]                                                   {'loss': 0.4697, 'learning_rate': 8e-05, 'epoch': 37.79}
 99%|█████████▉| 496/500 [1:25:45<00:41, 10.37s/it] 99%|█████████▉| 497/500 [1:25:55<00:31, 10.36s/it]                                                   {'loss': 0.4333, 'learning_rate': 6e-05, 'epoch': 37.87}
 99%|█████████▉| 497/500 [1:25:55<00:31, 10.36s/it]100%|█████████▉| 498/500 [1:26:06<00:20, 10.37s/it]                                                   {'loss': 0.4223, 'learning_rate': 4e-05, 'epoch': 37.94}
100%|█████████▉| 498/500 [1:26:06<00:20, 10.37s/it]100%|█████████▉| 499/500 [1:26:16<00:10, 10.37s/it]                                                   {'loss': 0.4927, 'learning_rate': 2e-05, 'epoch': 38.02}
100%|█████████▉| 499/500 [1:26:16<00:10, 10.37s/it]100%|██████████| 500/500 [1:26:26<00:00, 10.38s/it]                                                   {'loss': 0.4681, 'learning_rate': 0.0, 'epoch': 38.1}
100%|██████████| 500/500 [1:26:26<00:00, 10.38s/it]Saving PrefixEncoder
[INFO|configuration_utils.py:483] 2024-01-14 01:27:47,210 >> Configuration saved in output/test-202401132355-128-1e-2/tmp-checkpoint-500/config.json
[INFO|configuration_utils.py:594] 2024-01-14 01:27:47,210 >> Configuration saved in output/test-202401132355-128-1e-2/tmp-checkpoint-500/generation_config.json
[INFO|modeling_utils.py:2382] 2024-01-14 01:27:47,220 >> Model weights saved in output/test-202401132355-128-1e-2/tmp-checkpoint-500/pytorch_model.bin
[INFO|tokenization_utils_base.py:2432] 2024-01-14 01:27:47,221 >> tokenizer config file saved in output/test-202401132355-128-1e-2/tmp-checkpoint-500/tokenizer_config.json
[INFO|tokenization_utils_base.py:2441] 2024-01-14 01:27:47,221 >> Special tokens file saved in output/test-202401132355-128-1e-2/tmp-checkpoint-500/special_tokens_map.json
[INFO|trainer.py:1947] 2024-01-14 01:27:47,252 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                   {'train_runtime': 5187.0067, 'train_samples_per_second': 1.542, 'train_steps_per_second': 0.096, 'train_loss': 0.49224569702148435, 'epoch': 38.1}
100%|██████████| 500/500 [1:26:27<00:00, 10.38s/it]100%|██████████| 500/500 [1:26:27<00:00, 10.37s/it]
Saving PrefixEncoder
[INFO|configuration_utils.py:483] 2024-01-14 01:27:47,261 >> Configuration saved in output/test-202401132355-128-1e-2/config.json
[INFO|configuration_utils.py:594] 2024-01-14 01:27:47,261 >> Configuration saved in output/test-202401132355-128-1e-2/generation_config.json
[INFO|modeling_utils.py:2382] 2024-01-14 01:27:47,270 >> Model weights saved in output/test-202401132355-128-1e-2/pytorch_model.bin
[INFO|tokenization_utils_base.py:2432] 2024-01-14 01:27:47,271 >> tokenizer config file saved in output/test-202401132355-128-1e-2/tokenizer_config.json
[INFO|tokenization_utils_base.py:2441] 2024-01-14 01:27:47,271 >> Special tokens file saved in output/test-202401132355-128-1e-2/special_tokens_map.json
