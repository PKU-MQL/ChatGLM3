{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 38.095238095238095,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08,
      "learning_rate": 0.009980000000000001,
      "loss": 1.3438,
      "step": 1
    },
    {
      "epoch": 0.15,
      "learning_rate": 0.00996,
      "loss": 1.3173,
      "step": 2
    },
    {
      "epoch": 0.23,
      "learning_rate": 0.009940000000000001,
      "loss": 1.1197,
      "step": 3
    },
    {
      "epoch": 0.3,
      "learning_rate": 0.00992,
      "loss": 1.1328,
      "step": 4
    },
    {
      "epoch": 0.38,
      "learning_rate": 0.0099,
      "loss": 1.2343,
      "step": 5
    },
    {
      "epoch": 0.46,
      "learning_rate": 0.00988,
      "loss": 1.1754,
      "step": 6
    },
    {
      "epoch": 0.53,
      "learning_rate": 0.00986,
      "loss": 1.1226,
      "step": 7
    },
    {
      "epoch": 0.61,
      "learning_rate": 0.00984,
      "loss": 1.0839,
      "step": 8
    },
    {
      "epoch": 0.69,
      "learning_rate": 0.00982,
      "loss": 1.0497,
      "step": 9
    },
    {
      "epoch": 0.76,
      "learning_rate": 0.0098,
      "loss": 0.9764,
      "step": 10
    },
    {
      "epoch": 0.84,
      "learning_rate": 0.00978,
      "loss": 0.988,
      "step": 11
    },
    {
      "epoch": 0.91,
      "learning_rate": 0.00976,
      "loss": 0.9867,
      "step": 12
    },
    {
      "epoch": 0.99,
      "learning_rate": 0.00974,
      "loss": 1.11,
      "step": 13
    },
    {
      "epoch": 1.07,
      "learning_rate": 0.00972,
      "loss": 0.979,
      "step": 14
    },
    {
      "epoch": 1.14,
      "learning_rate": 0.0097,
      "loss": 0.8116,
      "step": 15
    },
    {
      "epoch": 1.22,
      "learning_rate": 0.00968,
      "loss": 0.868,
      "step": 16
    },
    {
      "epoch": 1.3,
      "learning_rate": 0.00966,
      "loss": 0.8417,
      "step": 17
    },
    {
      "epoch": 1.37,
      "learning_rate": 0.00964,
      "loss": 0.9575,
      "step": 18
    },
    {
      "epoch": 1.45,
      "learning_rate": 0.00962,
      "loss": 0.9228,
      "step": 19
    },
    {
      "epoch": 1.52,
      "learning_rate": 0.0096,
      "loss": 0.9866,
      "step": 20
    },
    {
      "epoch": 1.6,
      "learning_rate": 0.00958,
      "loss": 0.9213,
      "step": 21
    },
    {
      "epoch": 1.68,
      "learning_rate": 0.009559999999999999,
      "loss": 0.783,
      "step": 22
    },
    {
      "epoch": 1.75,
      "learning_rate": 0.00954,
      "loss": 0.8888,
      "step": 23
    },
    {
      "epoch": 1.83,
      "learning_rate": 0.009519999999999999,
      "loss": 0.8792,
      "step": 24
    },
    {
      "epoch": 1.9,
      "learning_rate": 0.0095,
      "loss": 0.8625,
      "step": 25
    },
    {
      "epoch": 1.98,
      "learning_rate": 0.00948,
      "loss": 0.7648,
      "step": 26
    },
    {
      "epoch": 2.06,
      "learning_rate": 0.00946,
      "loss": 0.8282,
      "step": 27
    },
    {
      "epoch": 2.13,
      "learning_rate": 0.00944,
      "loss": 0.7382,
      "step": 28
    },
    {
      "epoch": 2.21,
      "learning_rate": 0.00942,
      "loss": 0.7784,
      "step": 29
    },
    {
      "epoch": 2.29,
      "learning_rate": 0.0094,
      "loss": 0.7722,
      "step": 30
    },
    {
      "epoch": 2.36,
      "learning_rate": 0.00938,
      "loss": 0.8201,
      "step": 31
    },
    {
      "epoch": 2.44,
      "learning_rate": 0.00936,
      "loss": 0.8628,
      "step": 32
    },
    {
      "epoch": 2.51,
      "learning_rate": 0.009340000000000001,
      "loss": 0.7178,
      "step": 33
    },
    {
      "epoch": 2.59,
      "learning_rate": 0.00932,
      "loss": 0.8847,
      "step": 34
    },
    {
      "epoch": 2.67,
      "learning_rate": 0.009300000000000001,
      "loss": 0.771,
      "step": 35
    },
    {
      "epoch": 2.74,
      "learning_rate": 0.00928,
      "loss": 0.7915,
      "step": 36
    },
    {
      "epoch": 2.82,
      "learning_rate": 0.009260000000000001,
      "loss": 0.7498,
      "step": 37
    },
    {
      "epoch": 2.9,
      "learning_rate": 0.00924,
      "loss": 0.7777,
      "step": 38
    },
    {
      "epoch": 2.97,
      "learning_rate": 0.00922,
      "loss": 0.7219,
      "step": 39
    },
    {
      "epoch": 3.05,
      "learning_rate": 0.0092,
      "loss": 0.7502,
      "step": 40
    },
    {
      "epoch": 3.12,
      "learning_rate": 0.00918,
      "loss": 0.7581,
      "step": 41
    },
    {
      "epoch": 3.2,
      "learning_rate": 0.00916,
      "loss": 0.7929,
      "step": 42
    },
    {
      "epoch": 3.28,
      "learning_rate": 0.00914,
      "loss": 0.6973,
      "step": 43
    },
    {
      "epoch": 3.35,
      "learning_rate": 0.009120000000000001,
      "loss": 0.6606,
      "step": 44
    },
    {
      "epoch": 3.43,
      "learning_rate": 0.0091,
      "loss": 0.7022,
      "step": 45
    },
    {
      "epoch": 3.5,
      "learning_rate": 0.009080000000000001,
      "loss": 0.7217,
      "step": 46
    },
    {
      "epoch": 3.58,
      "learning_rate": 0.00906,
      "loss": 0.6975,
      "step": 47
    },
    {
      "epoch": 3.66,
      "learning_rate": 0.009040000000000001,
      "loss": 0.6798,
      "step": 48
    },
    {
      "epoch": 3.73,
      "learning_rate": 0.00902,
      "loss": 0.786,
      "step": 49
    },
    {
      "epoch": 3.81,
      "learning_rate": 0.009000000000000001,
      "loss": 0.6945,
      "step": 50
    },
    {
      "epoch": 3.89,
      "learning_rate": 0.00898,
      "loss": 0.7313,
      "step": 51
    },
    {
      "epoch": 3.96,
      "learning_rate": 0.008960000000000001,
      "loss": 0.7411,
      "step": 52
    },
    {
      "epoch": 4.04,
      "learning_rate": 0.00894,
      "loss": 0.6761,
      "step": 53
    },
    {
      "epoch": 4.11,
      "learning_rate": 0.00892,
      "loss": 0.6741,
      "step": 54
    },
    {
      "epoch": 4.19,
      "learning_rate": 0.0089,
      "loss": 0.676,
      "step": 55
    },
    {
      "epoch": 4.27,
      "learning_rate": 0.00888,
      "loss": 0.6722,
      "step": 56
    },
    {
      "epoch": 4.34,
      "learning_rate": 0.00886,
      "loss": 0.7346,
      "step": 57
    },
    {
      "epoch": 4.42,
      "learning_rate": 0.00884,
      "loss": 0.6234,
      "step": 58
    },
    {
      "epoch": 4.5,
      "learning_rate": 0.00882,
      "loss": 0.5996,
      "step": 59
    },
    {
      "epoch": 4.57,
      "learning_rate": 0.0088,
      "loss": 0.666,
      "step": 60
    },
    {
      "epoch": 4.65,
      "learning_rate": 0.00878,
      "loss": 0.6434,
      "step": 61
    },
    {
      "epoch": 4.72,
      "learning_rate": 0.00876,
      "loss": 0.6982,
      "step": 62
    },
    {
      "epoch": 4.8,
      "learning_rate": 0.00874,
      "loss": 0.6212,
      "step": 63
    },
    {
      "epoch": 4.88,
      "learning_rate": 0.00872,
      "loss": 0.5961,
      "step": 64
    },
    {
      "epoch": 4.95,
      "learning_rate": 0.0087,
      "loss": 0.6223,
      "step": 65
    },
    {
      "epoch": 5.03,
      "learning_rate": 0.00868,
      "loss": 0.5859,
      "step": 66
    },
    {
      "epoch": 5.1,
      "learning_rate": 0.00866,
      "loss": 0.5892,
      "step": 67
    },
    {
      "epoch": 5.18,
      "learning_rate": 0.00864,
      "loss": 0.6813,
      "step": 68
    },
    {
      "epoch": 5.26,
      "learning_rate": 0.008620000000000001,
      "loss": 0.566,
      "step": 69
    },
    {
      "epoch": 5.33,
      "learning_rate": 0.0086,
      "loss": 0.6311,
      "step": 70
    },
    {
      "epoch": 5.41,
      "learning_rate": 0.00858,
      "loss": 0.5818,
      "step": 71
    },
    {
      "epoch": 5.49,
      "learning_rate": 0.00856,
      "loss": 0.6239,
      "step": 72
    },
    {
      "epoch": 5.56,
      "learning_rate": 0.00854,
      "loss": 0.602,
      "step": 73
    },
    {
      "epoch": 5.64,
      "learning_rate": 0.00852,
      "loss": 0.5783,
      "step": 74
    },
    {
      "epoch": 5.71,
      "learning_rate": 0.0085,
      "loss": 0.5931,
      "step": 75
    },
    {
      "epoch": 5.79,
      "learning_rate": 0.00848,
      "loss": 0.5982,
      "step": 76
    },
    {
      "epoch": 5.87,
      "learning_rate": 0.00846,
      "loss": 0.5227,
      "step": 77
    },
    {
      "epoch": 5.94,
      "learning_rate": 0.00844,
      "loss": 0.5826,
      "step": 78
    },
    {
      "epoch": 6.02,
      "learning_rate": 0.00842,
      "loss": 0.6328,
      "step": 79
    },
    {
      "epoch": 6.1,
      "learning_rate": 0.0084,
      "loss": 0.6158,
      "step": 80
    },
    {
      "epoch": 6.17,
      "learning_rate": 0.00838,
      "loss": 0.5384,
      "step": 81
    },
    {
      "epoch": 6.25,
      "learning_rate": 0.00836,
      "loss": 0.5381,
      "step": 82
    },
    {
      "epoch": 6.32,
      "learning_rate": 0.00834,
      "loss": 0.5679,
      "step": 83
    },
    {
      "epoch": 6.4,
      "learning_rate": 0.00832,
      "loss": 0.4654,
      "step": 84
    },
    {
      "epoch": 6.48,
      "learning_rate": 0.0083,
      "loss": 0.63,
      "step": 85
    },
    {
      "epoch": 6.55,
      "learning_rate": 0.00828,
      "loss": 0.5218,
      "step": 86
    },
    {
      "epoch": 6.63,
      "learning_rate": 0.00826,
      "loss": 0.6058,
      "step": 87
    },
    {
      "epoch": 6.7,
      "learning_rate": 0.008239999999999999,
      "loss": 0.6261,
      "step": 88
    },
    {
      "epoch": 6.78,
      "learning_rate": 0.00822,
      "loss": 0.5237,
      "step": 89
    },
    {
      "epoch": 6.86,
      "learning_rate": 0.008199999999999999,
      "loss": 0.5274,
      "step": 90
    },
    {
      "epoch": 6.93,
      "learning_rate": 0.00818,
      "loss": 0.5142,
      "step": 91
    },
    {
      "epoch": 7.01,
      "learning_rate": 0.008159999999999999,
      "loss": 0.555,
      "step": 92
    },
    {
      "epoch": 7.09,
      "learning_rate": 0.00814,
      "loss": 0.5441,
      "step": 93
    },
    {
      "epoch": 7.16,
      "learning_rate": 0.00812,
      "loss": 0.5019,
      "step": 94
    },
    {
      "epoch": 7.24,
      "learning_rate": 0.008100000000000001,
      "loss": 0.5868,
      "step": 95
    },
    {
      "epoch": 7.31,
      "learning_rate": 0.00808,
      "loss": 0.5361,
      "step": 96
    },
    {
      "epoch": 7.39,
      "learning_rate": 0.008060000000000001,
      "loss": 0.491,
      "step": 97
    },
    {
      "epoch": 7.47,
      "learning_rate": 0.00804,
      "loss": 0.5465,
      "step": 98
    },
    {
      "epoch": 7.54,
      "learning_rate": 0.008020000000000001,
      "loss": 0.4524,
      "step": 99
    },
    {
      "epoch": 7.62,
      "learning_rate": 0.008,
      "loss": 0.6135,
      "step": 100
    },
    {
      "epoch": 7.7,
      "learning_rate": 0.007980000000000001,
      "loss": 0.5243,
      "step": 101
    },
    {
      "epoch": 7.77,
      "learning_rate": 0.00796,
      "loss": 0.4991,
      "step": 102
    },
    {
      "epoch": 7.85,
      "learning_rate": 0.007940000000000001,
      "loss": 0.5914,
      "step": 103
    },
    {
      "epoch": 7.92,
      "learning_rate": 0.00792,
      "loss": 0.457,
      "step": 104
    },
    {
      "epoch": 8.0,
      "learning_rate": 0.0079,
      "loss": 0.5095,
      "step": 105
    },
    {
      "epoch": 8.08,
      "learning_rate": 0.00788,
      "loss": 0.5564,
      "step": 106
    },
    {
      "epoch": 8.15,
      "learning_rate": 0.00786,
      "loss": 0.4802,
      "step": 107
    },
    {
      "epoch": 8.23,
      "learning_rate": 0.00784,
      "loss": 0.5322,
      "step": 108
    },
    {
      "epoch": 8.3,
      "learning_rate": 0.00782,
      "loss": 0.4811,
      "step": 109
    },
    {
      "epoch": 8.38,
      "learning_rate": 0.0078000000000000005,
      "loss": 0.4809,
      "step": 110
    },
    {
      "epoch": 8.46,
      "learning_rate": 0.0077800000000000005,
      "loss": 0.5249,
      "step": 111
    },
    {
      "epoch": 8.53,
      "learning_rate": 0.00776,
      "loss": 0.4914,
      "step": 112
    },
    {
      "epoch": 8.61,
      "learning_rate": 0.00774,
      "loss": 0.4683,
      "step": 113
    },
    {
      "epoch": 8.69,
      "learning_rate": 0.00772,
      "loss": 0.4873,
      "step": 114
    },
    {
      "epoch": 8.76,
      "learning_rate": 0.0077,
      "loss": 0.4893,
      "step": 115
    },
    {
      "epoch": 8.84,
      "learning_rate": 0.00768,
      "loss": 0.5465,
      "step": 116
    },
    {
      "epoch": 8.91,
      "learning_rate": 0.00766,
      "loss": 0.4728,
      "step": 117
    },
    {
      "epoch": 8.99,
      "learning_rate": 0.00764,
      "loss": 0.5571,
      "step": 118
    },
    {
      "epoch": 9.07,
      "learning_rate": 0.00762,
      "loss": 0.5766,
      "step": 119
    },
    {
      "epoch": 9.14,
      "learning_rate": 0.0076,
      "loss": 0.4551,
      "step": 120
    },
    {
      "epoch": 9.22,
      "learning_rate": 0.00758,
      "loss": 0.5382,
      "step": 121
    },
    {
      "epoch": 9.3,
      "learning_rate": 0.00756,
      "loss": 0.4834,
      "step": 122
    },
    {
      "epoch": 9.37,
      "learning_rate": 0.00754,
      "loss": 0.4538,
      "step": 123
    },
    {
      "epoch": 9.45,
      "learning_rate": 0.00752,
      "loss": 0.5338,
      "step": 124
    },
    {
      "epoch": 9.52,
      "learning_rate": 0.0075,
      "loss": 0.5375,
      "step": 125
    },
    {
      "epoch": 9.6,
      "learning_rate": 0.0074800000000000005,
      "loss": 0.4343,
      "step": 126
    },
    {
      "epoch": 9.68,
      "learning_rate": 0.0074600000000000005,
      "loss": 0.4252,
      "step": 127
    },
    {
      "epoch": 9.75,
      "learning_rate": 0.00744,
      "loss": 0.5136,
      "step": 128
    },
    {
      "epoch": 9.83,
      "learning_rate": 0.00742,
      "loss": 0.4042,
      "step": 129
    },
    {
      "epoch": 9.9,
      "learning_rate": 0.0074,
      "loss": 0.4649,
      "step": 130
    },
    {
      "epoch": 9.98,
      "learning_rate": 0.00738,
      "loss": 0.5025,
      "step": 131
    },
    {
      "epoch": 10.06,
      "learning_rate": 0.00736,
      "loss": 0.4763,
      "step": 132
    },
    {
      "epoch": 10.13,
      "learning_rate": 0.00734,
      "loss": 0.4488,
      "step": 133
    },
    {
      "epoch": 10.21,
      "learning_rate": 0.00732,
      "loss": 0.4366,
      "step": 134
    },
    {
      "epoch": 10.29,
      "learning_rate": 0.0073,
      "loss": 0.5185,
      "step": 135
    },
    {
      "epoch": 10.36,
      "learning_rate": 0.00728,
      "loss": 0.4204,
      "step": 136
    },
    {
      "epoch": 10.44,
      "learning_rate": 0.00726,
      "loss": 0.4431,
      "step": 137
    },
    {
      "epoch": 10.51,
      "learning_rate": 0.00724,
      "loss": 0.4634,
      "step": 138
    },
    {
      "epoch": 10.59,
      "learning_rate": 0.00722,
      "loss": 0.514,
      "step": 139
    },
    {
      "epoch": 10.67,
      "learning_rate": 0.0072,
      "loss": 0.4348,
      "step": 140
    },
    {
      "epoch": 10.74,
      "learning_rate": 0.00718,
      "loss": 0.4585,
      "step": 141
    },
    {
      "epoch": 10.82,
      "learning_rate": 0.00716,
      "loss": 0.5069,
      "step": 142
    },
    {
      "epoch": 10.9,
      "learning_rate": 0.00714,
      "loss": 0.4435,
      "step": 143
    },
    {
      "epoch": 10.97,
      "learning_rate": 0.00712,
      "loss": 0.4996,
      "step": 144
    },
    {
      "epoch": 11.05,
      "learning_rate": 0.0070999999999999995,
      "loss": 0.5507,
      "step": 145
    },
    {
      "epoch": 11.12,
      "learning_rate": 0.0070799999999999995,
      "loss": 0.5351,
      "step": 146
    },
    {
      "epoch": 11.2,
      "learning_rate": 0.0070599999999999994,
      "loss": 0.5237,
      "step": 147
    },
    {
      "epoch": 11.28,
      "learning_rate": 0.007039999999999999,
      "loss": 0.478,
      "step": 148
    },
    {
      "epoch": 11.35,
      "learning_rate": 0.007019999999999999,
      "loss": 0.3619,
      "step": 149
    },
    {
      "epoch": 11.43,
      "learning_rate": 0.006999999999999999,
      "loss": 0.4719,
      "step": 150
    },
    {
      "epoch": 11.5,
      "learning_rate": 0.00698,
      "loss": 0.4538,
      "step": 151
    },
    {
      "epoch": 11.58,
      "learning_rate": 0.00696,
      "loss": 0.3762,
      "step": 152
    },
    {
      "epoch": 11.66,
      "learning_rate": 0.00694,
      "loss": 0.4255,
      "step": 153
    },
    {
      "epoch": 11.73,
      "learning_rate": 0.00692,
      "loss": 0.4201,
      "step": 154
    },
    {
      "epoch": 11.81,
      "learning_rate": 0.0069,
      "loss": 0.4746,
      "step": 155
    },
    {
      "epoch": 11.89,
      "learning_rate": 0.00688,
      "loss": 0.4528,
      "step": 156
    },
    {
      "epoch": 11.96,
      "learning_rate": 0.006860000000000001,
      "loss": 0.4114,
      "step": 157
    },
    {
      "epoch": 12.04,
      "learning_rate": 0.006840000000000001,
      "loss": 0.4713,
      "step": 158
    },
    {
      "epoch": 12.11,
      "learning_rate": 0.0068200000000000005,
      "loss": 0.4707,
      "step": 159
    },
    {
      "epoch": 12.19,
      "learning_rate": 0.0068000000000000005,
      "loss": 0.4868,
      "step": 160
    },
    {
      "epoch": 12.27,
      "learning_rate": 0.0067800000000000004,
      "loss": 0.4409,
      "step": 161
    },
    {
      "epoch": 12.34,
      "learning_rate": 0.00676,
      "loss": 0.4075,
      "step": 162
    },
    {
      "epoch": 12.42,
      "learning_rate": 0.00674,
      "loss": 0.488,
      "step": 163
    },
    {
      "epoch": 12.5,
      "learning_rate": 0.00672,
      "loss": 0.5195,
      "step": 164
    },
    {
      "epoch": 12.57,
      "learning_rate": 0.0067,
      "loss": 0.4555,
      "step": 165
    },
    {
      "epoch": 12.65,
      "learning_rate": 0.00668,
      "loss": 0.3877,
      "step": 166
    },
    {
      "epoch": 12.72,
      "learning_rate": 0.00666,
      "loss": 0.42,
      "step": 167
    },
    {
      "epoch": 12.8,
      "learning_rate": 0.00664,
      "loss": 0.3823,
      "step": 168
    },
    {
      "epoch": 12.88,
      "learning_rate": 0.006620000000000001,
      "loss": 0.4488,
      "step": 169
    },
    {
      "epoch": 12.95,
      "learning_rate": 0.006600000000000001,
      "loss": 0.405,
      "step": 170
    },
    {
      "epoch": 13.03,
      "learning_rate": 0.006580000000000001,
      "loss": 0.425,
      "step": 171
    },
    {
      "epoch": 13.1,
      "learning_rate": 0.006560000000000001,
      "loss": 0.4121,
      "step": 172
    },
    {
      "epoch": 13.18,
      "learning_rate": 0.006540000000000001,
      "loss": 0.3885,
      "step": 173
    },
    {
      "epoch": 13.26,
      "learning_rate": 0.006520000000000001,
      "loss": 0.4212,
      "step": 174
    },
    {
      "epoch": 13.33,
      "learning_rate": 0.006500000000000001,
      "loss": 0.4755,
      "step": 175
    },
    {
      "epoch": 13.41,
      "learning_rate": 0.0064800000000000005,
      "loss": 0.4553,
      "step": 176
    },
    {
      "epoch": 13.49,
      "learning_rate": 0.0064600000000000005,
      "loss": 0.4662,
      "step": 177
    },
    {
      "epoch": 13.56,
      "learning_rate": 0.00644,
      "loss": 0.3917,
      "step": 178
    },
    {
      "epoch": 13.64,
      "learning_rate": 0.00642,
      "loss": 0.4163,
      "step": 179
    },
    {
      "epoch": 13.71,
      "learning_rate": 0.0064,
      "loss": 0.3974,
      "step": 180
    },
    {
      "epoch": 13.79,
      "learning_rate": 0.00638,
      "loss": 0.4976,
      "step": 181
    },
    {
      "epoch": 13.87,
      "learning_rate": 0.00636,
      "loss": 0.3607,
      "step": 182
    },
    {
      "epoch": 13.94,
      "learning_rate": 0.00634,
      "loss": 0.4873,
      "step": 183
    },
    {
      "epoch": 14.02,
      "learning_rate": 0.00632,
      "loss": 0.5017,
      "step": 184
    },
    {
      "epoch": 14.1,
      "learning_rate": 0.0063,
      "loss": 0.3945,
      "step": 185
    },
    {
      "epoch": 14.17,
      "learning_rate": 0.00628,
      "loss": 0.3736,
      "step": 186
    },
    {
      "epoch": 14.25,
      "learning_rate": 0.00626,
      "loss": 0.44,
      "step": 187
    },
    {
      "epoch": 14.32,
      "learning_rate": 0.00624,
      "loss": 0.4801,
      "step": 188
    },
    {
      "epoch": 14.4,
      "learning_rate": 0.00622,
      "loss": 0.4318,
      "step": 189
    },
    {
      "epoch": 14.48,
      "learning_rate": 0.0062,
      "loss": 0.4921,
      "step": 190
    },
    {
      "epoch": 14.55,
      "learning_rate": 0.00618,
      "loss": 0.3328,
      "step": 191
    },
    {
      "epoch": 14.63,
      "learning_rate": 0.00616,
      "loss": 0.4026,
      "step": 192
    },
    {
      "epoch": 14.7,
      "learning_rate": 0.00614,
      "loss": 0.4289,
      "step": 193
    },
    {
      "epoch": 14.78,
      "learning_rate": 0.0061200000000000004,
      "loss": 0.4024,
      "step": 194
    },
    {
      "epoch": 14.86,
      "learning_rate": 0.0061,
      "loss": 0.423,
      "step": 195
    },
    {
      "epoch": 14.93,
      "learning_rate": 0.00608,
      "loss": 0.4735,
      "step": 196
    },
    {
      "epoch": 15.01,
      "learning_rate": 0.00606,
      "loss": 0.3857,
      "step": 197
    },
    {
      "epoch": 15.09,
      "learning_rate": 0.00604,
      "loss": 0.4279,
      "step": 198
    },
    {
      "epoch": 15.16,
      "learning_rate": 0.00602,
      "loss": 0.3059,
      "step": 199
    },
    {
      "epoch": 15.24,
      "learning_rate": 0.006,
      "loss": 0.4167,
      "step": 200
    },
    {
      "epoch": 15.31,
      "learning_rate": 0.00598,
      "loss": 0.4371,
      "step": 201
    },
    {
      "epoch": 15.39,
      "learning_rate": 0.00596,
      "loss": 0.3838,
      "step": 202
    },
    {
      "epoch": 15.47,
      "learning_rate": 0.00594,
      "loss": 0.4004,
      "step": 203
    },
    {
      "epoch": 15.54,
      "learning_rate": 0.00592,
      "loss": 0.4395,
      "step": 204
    },
    {
      "epoch": 15.62,
      "learning_rate": 0.0059,
      "loss": 0.5148,
      "step": 205
    },
    {
      "epoch": 15.7,
      "learning_rate": 0.00588,
      "loss": 0.4709,
      "step": 206
    },
    {
      "epoch": 15.77,
      "learning_rate": 0.00586,
      "loss": 0.3325,
      "step": 207
    },
    {
      "epoch": 15.85,
      "learning_rate": 0.00584,
      "loss": 0.4546,
      "step": 208
    },
    {
      "epoch": 15.92,
      "learning_rate": 0.00582,
      "loss": 0.4597,
      "step": 209
    },
    {
      "epoch": 16.0,
      "learning_rate": 0.0058,
      "loss": 0.3374,
      "step": 210
    },
    {
      "epoch": 16.08,
      "learning_rate": 0.0057799999999999995,
      "loss": 0.411,
      "step": 211
    },
    {
      "epoch": 16.15,
      "learning_rate": 0.0057599999999999995,
      "loss": 0.4164,
      "step": 212
    },
    {
      "epoch": 16.23,
      "learning_rate": 0.0057399999999999994,
      "loss": 0.3782,
      "step": 213
    },
    {
      "epoch": 16.3,
      "learning_rate": 0.005719999999999999,
      "loss": 0.4264,
      "step": 214
    },
    {
      "epoch": 16.38,
      "learning_rate": 0.005699999999999999,
      "loss": 0.3785,
      "step": 215
    },
    {
      "epoch": 16.46,
      "learning_rate": 0.005679999999999999,
      "loss": 0.364,
      "step": 216
    },
    {
      "epoch": 16.53,
      "learning_rate": 0.005659999999999999,
      "loss": 0.438,
      "step": 217
    },
    {
      "epoch": 16.61,
      "learning_rate": 0.005639999999999999,
      "loss": 0.4422,
      "step": 218
    },
    {
      "epoch": 16.69,
      "learning_rate": 0.005620000000000001,
      "loss": 0.4055,
      "step": 219
    },
    {
      "epoch": 16.76,
      "learning_rate": 0.005600000000000001,
      "loss": 0.4128,
      "step": 220
    },
    {
      "epoch": 16.84,
      "learning_rate": 0.005580000000000001,
      "loss": 0.4363,
      "step": 221
    },
    {
      "epoch": 16.91,
      "learning_rate": 0.005560000000000001,
      "loss": 0.3953,
      "step": 222
    },
    {
      "epoch": 16.99,
      "learning_rate": 0.005540000000000001,
      "loss": 0.4241,
      "step": 223
    },
    {
      "epoch": 17.07,
      "learning_rate": 0.005520000000000001,
      "loss": 0.3927,
      "step": 224
    },
    {
      "epoch": 17.14,
      "learning_rate": 0.0055000000000000005,
      "loss": 0.4322,
      "step": 225
    },
    {
      "epoch": 17.22,
      "learning_rate": 0.0054800000000000005,
      "loss": 0.4158,
      "step": 226
    },
    {
      "epoch": 17.3,
      "learning_rate": 0.0054600000000000004,
      "loss": 0.3312,
      "step": 227
    },
    {
      "epoch": 17.37,
      "learning_rate": 0.00544,
      "loss": 0.3676,
      "step": 228
    },
    {
      "epoch": 17.45,
      "learning_rate": 0.00542,
      "loss": 0.4514,
      "step": 229
    },
    {
      "epoch": 17.52,
      "learning_rate": 0.0054,
      "loss": 0.4699,
      "step": 230
    },
    {
      "epoch": 17.6,
      "learning_rate": 0.00538,
      "loss": 0.4584,
      "step": 231
    },
    {
      "epoch": 17.68,
      "learning_rate": 0.00536,
      "loss": 0.4098,
      "step": 232
    },
    {
      "epoch": 17.75,
      "learning_rate": 0.00534,
      "loss": 0.3984,
      "step": 233
    },
    {
      "epoch": 17.83,
      "learning_rate": 0.00532,
      "loss": 0.3999,
      "step": 234
    },
    {
      "epoch": 17.9,
      "learning_rate": 0.0053,
      "loss": 0.347,
      "step": 235
    },
    {
      "epoch": 17.98,
      "learning_rate": 0.00528,
      "loss": 0.4025,
      "step": 236
    },
    {
      "epoch": 18.06,
      "learning_rate": 0.00526,
      "loss": 0.4209,
      "step": 237
    },
    {
      "epoch": 18.13,
      "learning_rate": 0.005240000000000001,
      "loss": 0.4504,
      "step": 238
    },
    {
      "epoch": 18.21,
      "learning_rate": 0.005220000000000001,
      "loss": 0.4138,
      "step": 239
    },
    {
      "epoch": 18.29,
      "learning_rate": 0.005200000000000001,
      "loss": 0.3544,
      "step": 240
    },
    {
      "epoch": 18.36,
      "learning_rate": 0.005180000000000001,
      "loss": 0.3714,
      "step": 241
    },
    {
      "epoch": 18.44,
      "learning_rate": 0.0051600000000000005,
      "loss": 0.3516,
      "step": 242
    },
    {
      "epoch": 18.51,
      "learning_rate": 0.0051400000000000005,
      "loss": 0.43,
      "step": 243
    },
    {
      "epoch": 18.59,
      "learning_rate": 0.00512,
      "loss": 0.3672,
      "step": 244
    },
    {
      "epoch": 18.67,
      "learning_rate": 0.0051,
      "loss": 0.4141,
      "step": 245
    },
    {
      "epoch": 18.74,
      "learning_rate": 0.00508,
      "loss": 0.4265,
      "step": 246
    },
    {
      "epoch": 18.82,
      "learning_rate": 0.00506,
      "loss": 0.3551,
      "step": 247
    },
    {
      "epoch": 18.9,
      "learning_rate": 0.00504,
      "loss": 0.442,
      "step": 248
    },
    {
      "epoch": 18.97,
      "learning_rate": 0.00502,
      "loss": 0.3901,
      "step": 249
    },
    {
      "epoch": 19.05,
      "learning_rate": 0.005,
      "loss": 0.4392,
      "step": 250
    },
    {
      "epoch": 19.12,
      "learning_rate": 0.00498,
      "loss": 0.4057,
      "step": 251
    },
    {
      "epoch": 19.2,
      "learning_rate": 0.00496,
      "loss": 0.3455,
      "step": 252
    },
    {
      "epoch": 19.28,
      "learning_rate": 0.00494,
      "loss": 0.4086,
      "step": 253
    },
    {
      "epoch": 19.35,
      "learning_rate": 0.00492,
      "loss": 0.3583,
      "step": 254
    },
    {
      "epoch": 19.43,
      "learning_rate": 0.0049,
      "loss": 0.4292,
      "step": 255
    },
    {
      "epoch": 19.5,
      "learning_rate": 0.00488,
      "loss": 0.3848,
      "step": 256
    },
    {
      "epoch": 19.58,
      "learning_rate": 0.00486,
      "loss": 0.3879,
      "step": 257
    },
    {
      "epoch": 19.66,
      "learning_rate": 0.00484,
      "loss": 0.4517,
      "step": 258
    },
    {
      "epoch": 19.73,
      "learning_rate": 0.00482,
      "loss": 0.3357,
      "step": 259
    },
    {
      "epoch": 19.81,
      "learning_rate": 0.0048,
      "loss": 0.404,
      "step": 260
    },
    {
      "epoch": 19.89,
      "learning_rate": 0.0047799999999999995,
      "loss": 0.4408,
      "step": 261
    },
    {
      "epoch": 19.96,
      "learning_rate": 0.0047599999999999995,
      "loss": 0.4387,
      "step": 262
    },
    {
      "epoch": 20.04,
      "learning_rate": 0.00474,
      "loss": 0.3608,
      "step": 263
    },
    {
      "epoch": 20.11,
      "learning_rate": 0.00472,
      "loss": 0.3772,
      "step": 264
    },
    {
      "epoch": 20.19,
      "learning_rate": 0.0047,
      "loss": 0.3885,
      "step": 265
    },
    {
      "epoch": 20.27,
      "learning_rate": 0.00468,
      "loss": 0.3399,
      "step": 266
    },
    {
      "epoch": 20.34,
      "learning_rate": 0.00466,
      "loss": 0.3775,
      "step": 267
    },
    {
      "epoch": 20.42,
      "learning_rate": 0.00464,
      "loss": 0.3193,
      "step": 268
    },
    {
      "epoch": 20.5,
      "learning_rate": 0.00462,
      "loss": 0.3928,
      "step": 269
    },
    {
      "epoch": 20.57,
      "learning_rate": 0.0046,
      "loss": 0.4362,
      "step": 270
    },
    {
      "epoch": 20.65,
      "learning_rate": 0.00458,
      "loss": 0.36,
      "step": 271
    },
    {
      "epoch": 20.72,
      "learning_rate": 0.004560000000000001,
      "loss": 0.4454,
      "step": 272
    },
    {
      "epoch": 20.8,
      "learning_rate": 0.004540000000000001,
      "loss": 0.3849,
      "step": 273
    },
    {
      "epoch": 20.88,
      "learning_rate": 0.004520000000000001,
      "loss": 0.4507,
      "step": 274
    },
    {
      "epoch": 20.95,
      "learning_rate": 0.0045000000000000005,
      "loss": 0.4471,
      "step": 275
    },
    {
      "epoch": 21.03,
      "learning_rate": 0.0044800000000000005,
      "loss": 0.4837,
      "step": 276
    },
    {
      "epoch": 21.1,
      "learning_rate": 0.00446,
      "loss": 0.417,
      "step": 277
    },
    {
      "epoch": 21.18,
      "learning_rate": 0.00444,
      "loss": 0.3521,
      "step": 278
    },
    {
      "epoch": 21.26,
      "learning_rate": 0.00442,
      "loss": 0.4344,
      "step": 279
    },
    {
      "epoch": 21.33,
      "learning_rate": 0.0044,
      "loss": 0.3861,
      "step": 280
    },
    {
      "epoch": 21.41,
      "learning_rate": 0.00438,
      "loss": 0.4687,
      "step": 281
    },
    {
      "epoch": 21.49,
      "learning_rate": 0.00436,
      "loss": 0.4582,
      "step": 282
    },
    {
      "epoch": 21.56,
      "learning_rate": 0.00434,
      "loss": 0.3828,
      "step": 283
    },
    {
      "epoch": 21.64,
      "learning_rate": 0.00432,
      "loss": 0.4717,
      "step": 284
    },
    {
      "epoch": 21.71,
      "learning_rate": 0.0043,
      "loss": 0.3939,
      "step": 285
    },
    {
      "epoch": 21.79,
      "learning_rate": 0.00428,
      "loss": 0.3067,
      "step": 286
    },
    {
      "epoch": 21.87,
      "learning_rate": 0.00426,
      "loss": 0.3752,
      "step": 287
    },
    {
      "epoch": 21.94,
      "learning_rate": 0.00424,
      "loss": 0.377,
      "step": 288
    },
    {
      "epoch": 22.02,
      "learning_rate": 0.00422,
      "loss": 0.4151,
      "step": 289
    },
    {
      "epoch": 22.1,
      "learning_rate": 0.0042,
      "loss": 0.3518,
      "step": 290
    },
    {
      "epoch": 22.17,
      "learning_rate": 0.00418,
      "loss": 0.3374,
      "step": 291
    },
    {
      "epoch": 22.25,
      "learning_rate": 0.00416,
      "loss": 0.4228,
      "step": 292
    },
    {
      "epoch": 22.32,
      "learning_rate": 0.00414,
      "loss": 0.4171,
      "step": 293
    },
    {
      "epoch": 22.4,
      "learning_rate": 0.0041199999999999995,
      "loss": 0.4387,
      "step": 294
    },
    {
      "epoch": 22.48,
      "learning_rate": 0.0040999999999999995,
      "loss": 0.3861,
      "step": 295
    },
    {
      "epoch": 22.55,
      "learning_rate": 0.004079999999999999,
      "loss": 0.4059,
      "step": 296
    },
    {
      "epoch": 22.63,
      "learning_rate": 0.00406,
      "loss": 0.3845,
      "step": 297
    },
    {
      "epoch": 22.7,
      "learning_rate": 0.00404,
      "loss": 0.412,
      "step": 298
    },
    {
      "epoch": 22.78,
      "learning_rate": 0.00402,
      "loss": 0.3916,
      "step": 299
    },
    {
      "epoch": 22.86,
      "learning_rate": 0.004,
      "loss": 0.3964,
      "step": 300
    },
    {
      "epoch": 22.93,
      "learning_rate": 0.00398,
      "loss": 0.4788,
      "step": 301
    },
    {
      "epoch": 23.01,
      "learning_rate": 0.00396,
      "loss": 0.4517,
      "step": 302
    },
    {
      "epoch": 23.09,
      "learning_rate": 0.00394,
      "loss": 0.3864,
      "step": 303
    },
    {
      "epoch": 23.16,
      "learning_rate": 0.00392,
      "loss": 0.4201,
      "step": 304
    },
    {
      "epoch": 23.24,
      "learning_rate": 0.0039000000000000003,
      "loss": 0.4292,
      "step": 305
    },
    {
      "epoch": 23.31,
      "learning_rate": 0.00388,
      "loss": 0.4229,
      "step": 306
    },
    {
      "epoch": 23.39,
      "learning_rate": 0.00386,
      "loss": 0.4426,
      "step": 307
    },
    {
      "epoch": 23.47,
      "learning_rate": 0.00384,
      "loss": 0.4496,
      "step": 308
    },
    {
      "epoch": 23.54,
      "learning_rate": 0.00382,
      "loss": 0.4187,
      "step": 309
    },
    {
      "epoch": 23.62,
      "learning_rate": 0.0038,
      "loss": 0.3819,
      "step": 310
    },
    {
      "epoch": 23.7,
      "learning_rate": 0.00378,
      "loss": 0.4225,
      "step": 311
    },
    {
      "epoch": 23.77,
      "learning_rate": 0.00376,
      "loss": 0.3733,
      "step": 312
    },
    {
      "epoch": 23.85,
      "learning_rate": 0.0037400000000000003,
      "loss": 0.3715,
      "step": 313
    },
    {
      "epoch": 23.92,
      "learning_rate": 0.00372,
      "loss": 0.3557,
      "step": 314
    },
    {
      "epoch": 24.0,
      "learning_rate": 0.0037,
      "loss": 0.418,
      "step": 315
    },
    {
      "epoch": 24.08,
      "learning_rate": 0.00368,
      "loss": 0.4306,
      "step": 316
    },
    {
      "epoch": 24.15,
      "learning_rate": 0.00366,
      "loss": 0.4149,
      "step": 317
    },
    {
      "epoch": 24.23,
      "learning_rate": 0.00364,
      "loss": 0.3655,
      "step": 318
    },
    {
      "epoch": 24.3,
      "learning_rate": 0.00362,
      "loss": 0.4093,
      "step": 319
    },
    {
      "epoch": 24.38,
      "learning_rate": 0.0036,
      "loss": 0.4467,
      "step": 320
    },
    {
      "epoch": 24.46,
      "learning_rate": 0.00358,
      "loss": 0.3196,
      "step": 321
    },
    {
      "epoch": 24.53,
      "learning_rate": 0.00356,
      "loss": 0.4206,
      "step": 322
    },
    {
      "epoch": 24.61,
      "learning_rate": 0.0035399999999999997,
      "loss": 0.3799,
      "step": 323
    },
    {
      "epoch": 24.69,
      "learning_rate": 0.0035199999999999997,
      "loss": 0.439,
      "step": 324
    },
    {
      "epoch": 24.76,
      "learning_rate": 0.0034999999999999996,
      "loss": 0.4146,
      "step": 325
    },
    {
      "epoch": 24.84,
      "learning_rate": 0.00348,
      "loss": 0.4028,
      "step": 326
    },
    {
      "epoch": 24.91,
      "learning_rate": 0.00346,
      "loss": 0.3971,
      "step": 327
    },
    {
      "epoch": 24.99,
      "learning_rate": 0.00344,
      "loss": 0.4732,
      "step": 328
    },
    {
      "epoch": 25.07,
      "learning_rate": 0.0034200000000000003,
      "loss": 0.3487,
      "step": 329
    },
    {
      "epoch": 25.14,
      "learning_rate": 0.0034000000000000002,
      "loss": 0.374,
      "step": 330
    },
    {
      "epoch": 25.22,
      "learning_rate": 0.00338,
      "loss": 0.4149,
      "step": 331
    },
    {
      "epoch": 25.3,
      "learning_rate": 0.00336,
      "loss": 0.4566,
      "step": 332
    },
    {
      "epoch": 25.37,
      "learning_rate": 0.00334,
      "loss": 0.4077,
      "step": 333
    },
    {
      "epoch": 25.45,
      "learning_rate": 0.00332,
      "loss": 0.3864,
      "step": 334
    },
    {
      "epoch": 25.52,
      "learning_rate": 0.0033000000000000004,
      "loss": 0.4026,
      "step": 335
    },
    {
      "epoch": 25.6,
      "learning_rate": 0.0032800000000000004,
      "loss": 0.3604,
      "step": 336
    },
    {
      "epoch": 25.68,
      "learning_rate": 0.0032600000000000003,
      "loss": 0.4472,
      "step": 337
    },
    {
      "epoch": 25.75,
      "learning_rate": 0.0032400000000000003,
      "loss": 0.418,
      "step": 338
    },
    {
      "epoch": 25.83,
      "learning_rate": 0.00322,
      "loss": 0.3644,
      "step": 339
    },
    {
      "epoch": 25.9,
      "learning_rate": 0.0032,
      "loss": 0.4773,
      "step": 340
    },
    {
      "epoch": 25.98,
      "learning_rate": 0.00318,
      "loss": 0.4206,
      "step": 341
    },
    {
      "epoch": 26.06,
      "learning_rate": 0.00316,
      "loss": 0.506,
      "step": 342
    },
    {
      "epoch": 26.13,
      "learning_rate": 0.00314,
      "loss": 0.3848,
      "step": 343
    },
    {
      "epoch": 26.21,
      "learning_rate": 0.00312,
      "loss": 0.4066,
      "step": 344
    },
    {
      "epoch": 26.29,
      "learning_rate": 0.0031,
      "loss": 0.3505,
      "step": 345
    },
    {
      "epoch": 26.36,
      "learning_rate": 0.00308,
      "loss": 0.4602,
      "step": 346
    },
    {
      "epoch": 26.44,
      "learning_rate": 0.0030600000000000002,
      "loss": 0.3768,
      "step": 347
    },
    {
      "epoch": 26.51,
      "learning_rate": 0.00304,
      "loss": 0.4538,
      "step": 348
    },
    {
      "epoch": 26.59,
      "learning_rate": 0.00302,
      "loss": 0.4071,
      "step": 349
    },
    {
      "epoch": 26.67,
      "learning_rate": 0.003,
      "loss": 0.381,
      "step": 350
    },
    {
      "epoch": 26.74,
      "learning_rate": 0.00298,
      "loss": 0.5251,
      "step": 351
    },
    {
      "epoch": 26.82,
      "learning_rate": 0.00296,
      "loss": 0.4008,
      "step": 352
    },
    {
      "epoch": 26.9,
      "learning_rate": 0.00294,
      "loss": 0.3798,
      "step": 353
    },
    {
      "epoch": 26.97,
      "learning_rate": 0.00292,
      "loss": 0.3724,
      "step": 354
    },
    {
      "epoch": 27.05,
      "learning_rate": 0.0029,
      "loss": 0.3728,
      "step": 355
    },
    {
      "epoch": 27.12,
      "learning_rate": 0.0028799999999999997,
      "loss": 0.4434,
      "step": 356
    },
    {
      "epoch": 27.2,
      "learning_rate": 0.0028599999999999997,
      "loss": 0.3784,
      "step": 357
    },
    {
      "epoch": 27.28,
      "learning_rate": 0.0028399999999999996,
      "loss": 0.3674,
      "step": 358
    },
    {
      "epoch": 27.35,
      "learning_rate": 0.0028199999999999996,
      "loss": 0.4469,
      "step": 359
    },
    {
      "epoch": 27.43,
      "learning_rate": 0.0028000000000000004,
      "loss": 0.5038,
      "step": 360
    },
    {
      "epoch": 27.5,
      "learning_rate": 0.0027800000000000004,
      "loss": 0.4164,
      "step": 361
    },
    {
      "epoch": 27.58,
      "learning_rate": 0.0027600000000000003,
      "loss": 0.4434,
      "step": 362
    },
    {
      "epoch": 27.66,
      "learning_rate": 0.0027400000000000002,
      "loss": 0.3322,
      "step": 363
    },
    {
      "epoch": 27.73,
      "learning_rate": 0.00272,
      "loss": 0.4671,
      "step": 364
    },
    {
      "epoch": 27.81,
      "learning_rate": 0.0027,
      "loss": 0.4143,
      "step": 365
    },
    {
      "epoch": 27.89,
      "learning_rate": 0.00268,
      "loss": 0.4606,
      "step": 366
    },
    {
      "epoch": 27.96,
      "learning_rate": 0.00266,
      "loss": 0.3333,
      "step": 367
    },
    {
      "epoch": 28.04,
      "learning_rate": 0.00264,
      "loss": 0.4438,
      "step": 368
    },
    {
      "epoch": 28.11,
      "learning_rate": 0.0026200000000000004,
      "loss": 0.4284,
      "step": 369
    },
    {
      "epoch": 28.19,
      "learning_rate": 0.0026000000000000003,
      "loss": 0.397,
      "step": 370
    },
    {
      "epoch": 28.27,
      "learning_rate": 0.0025800000000000003,
      "loss": 0.4189,
      "step": 371
    },
    {
      "epoch": 28.34,
      "learning_rate": 0.00256,
      "loss": 0.4406,
      "step": 372
    },
    {
      "epoch": 28.42,
      "learning_rate": 0.00254,
      "loss": 0.4433,
      "step": 373
    },
    {
      "epoch": 28.5,
      "learning_rate": 0.00252,
      "loss": 0.4165,
      "step": 374
    },
    {
      "epoch": 28.57,
      "learning_rate": 0.0025,
      "loss": 0.4607,
      "step": 375
    },
    {
      "epoch": 28.65,
      "learning_rate": 0.00248,
      "loss": 0.4262,
      "step": 376
    },
    {
      "epoch": 28.72,
      "learning_rate": 0.00246,
      "loss": 0.4594,
      "step": 377
    },
    {
      "epoch": 28.8,
      "learning_rate": 0.00244,
      "loss": 0.4037,
      "step": 378
    },
    {
      "epoch": 28.88,
      "learning_rate": 0.00242,
      "loss": 0.3891,
      "step": 379
    },
    {
      "epoch": 28.95,
      "learning_rate": 0.0024,
      "loss": 0.4469,
      "step": 380
    },
    {
      "epoch": 29.03,
      "learning_rate": 0.0023799999999999997,
      "loss": 0.3609,
      "step": 381
    },
    {
      "epoch": 29.1,
      "learning_rate": 0.00236,
      "loss": 0.3927,
      "step": 382
    },
    {
      "epoch": 29.18,
      "learning_rate": 0.00234,
      "loss": 0.4806,
      "step": 383
    },
    {
      "epoch": 29.26,
      "learning_rate": 0.00232,
      "loss": 0.4232,
      "step": 384
    },
    {
      "epoch": 29.33,
      "learning_rate": 0.0023,
      "loss": 0.3914,
      "step": 385
    },
    {
      "epoch": 29.41,
      "learning_rate": 0.0022800000000000003,
      "loss": 0.4391,
      "step": 386
    },
    {
      "epoch": 29.49,
      "learning_rate": 0.0022600000000000003,
      "loss": 0.4762,
      "step": 387
    },
    {
      "epoch": 29.56,
      "learning_rate": 0.0022400000000000002,
      "loss": 0.3756,
      "step": 388
    },
    {
      "epoch": 29.64,
      "learning_rate": 0.00222,
      "loss": 0.4344,
      "step": 389
    },
    {
      "epoch": 29.71,
      "learning_rate": 0.0022,
      "loss": 0.4158,
      "step": 390
    },
    {
      "epoch": 29.79,
      "learning_rate": 0.00218,
      "loss": 0.4991,
      "step": 391
    },
    {
      "epoch": 29.87,
      "learning_rate": 0.00216,
      "loss": 0.4084,
      "step": 392
    },
    {
      "epoch": 29.94,
      "learning_rate": 0.00214,
      "loss": 0.4084,
      "step": 393
    },
    {
      "epoch": 30.02,
      "learning_rate": 0.00212,
      "loss": 0.4547,
      "step": 394
    },
    {
      "epoch": 30.1,
      "learning_rate": 0.0021,
      "loss": 0.5305,
      "step": 395
    },
    {
      "epoch": 30.17,
      "learning_rate": 0.00208,
      "loss": 0.4387,
      "step": 396
    },
    {
      "epoch": 30.25,
      "learning_rate": 0.0020599999999999998,
      "loss": 0.4475,
      "step": 397
    },
    {
      "epoch": 30.32,
      "learning_rate": 0.0020399999999999997,
      "loss": 0.4619,
      "step": 398
    },
    {
      "epoch": 30.4,
      "learning_rate": 0.00202,
      "loss": 0.4649,
      "step": 399
    },
    {
      "epoch": 30.48,
      "learning_rate": 0.002,
      "loss": 0.4048,
      "step": 400
    },
    {
      "epoch": 30.55,
      "learning_rate": 0.00198,
      "loss": 0.3715,
      "step": 401
    },
    {
      "epoch": 30.63,
      "learning_rate": 0.00196,
      "loss": 0.388,
      "step": 402
    },
    {
      "epoch": 30.7,
      "learning_rate": 0.00194,
      "loss": 0.4022,
      "step": 403
    },
    {
      "epoch": 30.78,
      "learning_rate": 0.00192,
      "loss": 0.3753,
      "step": 404
    },
    {
      "epoch": 30.86,
      "learning_rate": 0.0019,
      "loss": 0.4576,
      "step": 405
    },
    {
      "epoch": 30.93,
      "learning_rate": 0.00188,
      "loss": 0.4332,
      "step": 406
    },
    {
      "epoch": 31.01,
      "learning_rate": 0.00186,
      "loss": 0.4142,
      "step": 407
    },
    {
      "epoch": 31.09,
      "learning_rate": 0.00184,
      "loss": 0.414,
      "step": 408
    },
    {
      "epoch": 31.16,
      "learning_rate": 0.00182,
      "loss": 0.4694,
      "step": 409
    },
    {
      "epoch": 31.24,
      "learning_rate": 0.0018,
      "loss": 0.4131,
      "step": 410
    },
    {
      "epoch": 31.31,
      "learning_rate": 0.00178,
      "loss": 0.4333,
      "step": 411
    },
    {
      "epoch": 31.39,
      "learning_rate": 0.0017599999999999998,
      "loss": 0.39,
      "step": 412
    },
    {
      "epoch": 31.47,
      "learning_rate": 0.00174,
      "loss": 0.3536,
      "step": 413
    },
    {
      "epoch": 31.54,
      "learning_rate": 0.00172,
      "loss": 0.4547,
      "step": 414
    },
    {
      "epoch": 31.62,
      "learning_rate": 0.0017000000000000001,
      "loss": 0.4799,
      "step": 415
    },
    {
      "epoch": 31.7,
      "learning_rate": 0.00168,
      "loss": 0.4398,
      "step": 416
    },
    {
      "epoch": 31.77,
      "learning_rate": 0.00166,
      "loss": 0.4928,
      "step": 417
    },
    {
      "epoch": 31.85,
      "learning_rate": 0.0016400000000000002,
      "loss": 0.4445,
      "step": 418
    },
    {
      "epoch": 31.92,
      "learning_rate": 0.0016200000000000001,
      "loss": 0.4494,
      "step": 419
    },
    {
      "epoch": 32.0,
      "learning_rate": 0.0016,
      "loss": 0.3544,
      "step": 420
    },
    {
      "epoch": 32.08,
      "learning_rate": 0.00158,
      "loss": 0.3947,
      "step": 421
    },
    {
      "epoch": 32.15,
      "learning_rate": 0.00156,
      "loss": 0.5143,
      "step": 422
    },
    {
      "epoch": 32.23,
      "learning_rate": 0.00154,
      "loss": 0.5183,
      "step": 423
    },
    {
      "epoch": 32.3,
      "learning_rate": 0.00152,
      "loss": 0.415,
      "step": 424
    },
    {
      "epoch": 32.38,
      "learning_rate": 0.0015,
      "loss": 0.4285,
      "step": 425
    },
    {
      "epoch": 32.46,
      "learning_rate": 0.00148,
      "loss": 0.3882,
      "step": 426
    },
    {
      "epoch": 32.53,
      "learning_rate": 0.00146,
      "loss": 0.4664,
      "step": 427
    },
    {
      "epoch": 32.61,
      "learning_rate": 0.0014399999999999999,
      "loss": 0.4518,
      "step": 428
    },
    {
      "epoch": 32.69,
      "learning_rate": 0.0014199999999999998,
      "loss": 0.4252,
      "step": 429
    },
    {
      "epoch": 32.76,
      "learning_rate": 0.0014000000000000002,
      "loss": 0.4547,
      "step": 430
    },
    {
      "epoch": 32.84,
      "learning_rate": 0.0013800000000000002,
      "loss": 0.4168,
      "step": 431
    },
    {
      "epoch": 32.91,
      "learning_rate": 0.00136,
      "loss": 0.4671,
      "step": 432
    },
    {
      "epoch": 32.99,
      "learning_rate": 0.00134,
      "loss": 0.3625,
      "step": 433
    },
    {
      "epoch": 33.07,
      "learning_rate": 0.00132,
      "loss": 0.4118,
      "step": 434
    },
    {
      "epoch": 33.14,
      "learning_rate": 0.0013000000000000002,
      "loss": 0.4726,
      "step": 435
    },
    {
      "epoch": 33.22,
      "learning_rate": 0.00128,
      "loss": 0.4929,
      "step": 436
    },
    {
      "epoch": 33.3,
      "learning_rate": 0.00126,
      "loss": 0.4234,
      "step": 437
    },
    {
      "epoch": 33.37,
      "learning_rate": 0.00124,
      "loss": 0.3983,
      "step": 438
    },
    {
      "epoch": 33.45,
      "learning_rate": 0.00122,
      "loss": 0.4307,
      "step": 439
    },
    {
      "epoch": 33.52,
      "learning_rate": 0.0012,
      "loss": 0.4529,
      "step": 440
    },
    {
      "epoch": 33.6,
      "learning_rate": 0.00118,
      "loss": 0.4641,
      "step": 441
    },
    {
      "epoch": 33.68,
      "learning_rate": 0.00116,
      "loss": 0.4568,
      "step": 442
    },
    {
      "epoch": 33.75,
      "learning_rate": 0.0011400000000000002,
      "loss": 0.3335,
      "step": 443
    },
    {
      "epoch": 33.83,
      "learning_rate": 0.0011200000000000001,
      "loss": 0.4719,
      "step": 444
    },
    {
      "epoch": 33.9,
      "learning_rate": 0.0011,
      "loss": 0.456,
      "step": 445
    },
    {
      "epoch": 33.98,
      "learning_rate": 0.00108,
      "loss": 0.4372,
      "step": 446
    },
    {
      "epoch": 34.06,
      "learning_rate": 0.00106,
      "loss": 0.3848,
      "step": 447
    },
    {
      "epoch": 34.13,
      "learning_rate": 0.00104,
      "loss": 0.389,
      "step": 448
    },
    {
      "epoch": 34.21,
      "learning_rate": 0.0010199999999999999,
      "loss": 0.4522,
      "step": 449
    },
    {
      "epoch": 34.29,
      "learning_rate": 0.001,
      "loss": 0.3644,
      "step": 450
    },
    {
      "epoch": 34.36,
      "learning_rate": 0.00098,
      "loss": 0.4313,
      "step": 451
    },
    {
      "epoch": 34.44,
      "learning_rate": 0.00096,
      "loss": 0.466,
      "step": 452
    },
    {
      "epoch": 34.51,
      "learning_rate": 0.00094,
      "loss": 0.3867,
      "step": 453
    },
    {
      "epoch": 34.59,
      "learning_rate": 0.00092,
      "loss": 0.5134,
      "step": 454
    },
    {
      "epoch": 34.67,
      "learning_rate": 0.0009,
      "loss": 0.4152,
      "step": 455
    },
    {
      "epoch": 34.74,
      "learning_rate": 0.0008799999999999999,
      "loss": 0.4913,
      "step": 456
    },
    {
      "epoch": 34.82,
      "learning_rate": 0.00086,
      "loss": 0.4903,
      "step": 457
    },
    {
      "epoch": 34.9,
      "learning_rate": 0.00084,
      "loss": 0.4373,
      "step": 458
    },
    {
      "epoch": 34.97,
      "learning_rate": 0.0008200000000000001,
      "loss": 0.4973,
      "step": 459
    },
    {
      "epoch": 35.05,
      "learning_rate": 0.0008,
      "loss": 0.3606,
      "step": 460
    },
    {
      "epoch": 35.12,
      "learning_rate": 0.00078,
      "loss": 0.4188,
      "step": 461
    },
    {
      "epoch": 35.2,
      "learning_rate": 0.00076,
      "loss": 0.4093,
      "step": 462
    },
    {
      "epoch": 35.28,
      "learning_rate": 0.00074,
      "loss": 0.507,
      "step": 463
    },
    {
      "epoch": 35.35,
      "learning_rate": 0.0007199999999999999,
      "loss": 0.3865,
      "step": 464
    },
    {
      "epoch": 35.43,
      "learning_rate": 0.0007000000000000001,
      "loss": 0.4946,
      "step": 465
    },
    {
      "epoch": 35.5,
      "learning_rate": 0.00068,
      "loss": 0.4118,
      "step": 466
    },
    {
      "epoch": 35.58,
      "learning_rate": 0.00066,
      "loss": 0.3611,
      "step": 467
    },
    {
      "epoch": 35.66,
      "learning_rate": 0.00064,
      "loss": 0.4665,
      "step": 468
    },
    {
      "epoch": 35.73,
      "learning_rate": 0.00062,
      "loss": 0.3962,
      "step": 469
    },
    {
      "epoch": 35.81,
      "learning_rate": 0.0006,
      "loss": 0.4839,
      "step": 470
    },
    {
      "epoch": 35.89,
      "learning_rate": 0.00058,
      "loss": 0.5095,
      "step": 471
    },
    {
      "epoch": 35.96,
      "learning_rate": 0.0005600000000000001,
      "loss": 0.4984,
      "step": 472
    },
    {
      "epoch": 36.04,
      "learning_rate": 0.00054,
      "loss": 0.4704,
      "step": 473
    },
    {
      "epoch": 36.11,
      "learning_rate": 0.00052,
      "loss": 0.3887,
      "step": 474
    },
    {
      "epoch": 36.19,
      "learning_rate": 0.0005,
      "loss": 0.3884,
      "step": 475
    },
    {
      "epoch": 36.27,
      "learning_rate": 0.00048,
      "loss": 0.3712,
      "step": 476
    },
    {
      "epoch": 36.34,
      "learning_rate": 0.00046,
      "loss": 0.4371,
      "step": 477
    },
    {
      "epoch": 36.42,
      "learning_rate": 0.00043999999999999996,
      "loss": 0.4104,
      "step": 478
    },
    {
      "epoch": 36.5,
      "learning_rate": 0.00042,
      "loss": 0.5156,
      "step": 479
    },
    {
      "epoch": 36.57,
      "learning_rate": 0.0004,
      "loss": 0.4763,
      "step": 480
    },
    {
      "epoch": 36.65,
      "learning_rate": 0.00038,
      "loss": 0.4204,
      "step": 481
    },
    {
      "epoch": 36.72,
      "learning_rate": 0.00035999999999999997,
      "loss": 0.5401,
      "step": 482
    },
    {
      "epoch": 36.8,
      "learning_rate": 0.00034,
      "loss": 0.4165,
      "step": 483
    },
    {
      "epoch": 36.88,
      "learning_rate": 0.00032,
      "loss": 0.4835,
      "step": 484
    },
    {
      "epoch": 36.95,
      "learning_rate": 0.0003,
      "loss": 0.502,
      "step": 485
    },
    {
      "epoch": 37.03,
      "learning_rate": 0.00028000000000000003,
      "loss": 0.4928,
      "step": 486
    },
    {
      "epoch": 37.1,
      "learning_rate": 0.00026,
      "loss": 0.4718,
      "step": 487
    },
    {
      "epoch": 37.18,
      "learning_rate": 0.00024,
      "loss": 0.4046,
      "step": 488
    },
    {
      "epoch": 37.26,
      "learning_rate": 0.00021999999999999998,
      "loss": 0.4487,
      "step": 489
    },
    {
      "epoch": 37.33,
      "learning_rate": 0.0002,
      "loss": 0.4652,
      "step": 490
    },
    {
      "epoch": 37.41,
      "learning_rate": 0.00017999999999999998,
      "loss": 0.4781,
      "step": 491
    },
    {
      "epoch": 37.49,
      "learning_rate": 0.00016,
      "loss": 0.4539,
      "step": 492
    },
    {
      "epoch": 37.56,
      "learning_rate": 0.00014000000000000001,
      "loss": 0.4074,
      "step": 493
    },
    {
      "epoch": 37.64,
      "learning_rate": 0.00012,
      "loss": 0.4907,
      "step": 494
    },
    {
      "epoch": 37.71,
      "learning_rate": 0.0001,
      "loss": 0.2863,
      "step": 495
    },
    {
      "epoch": 37.79,
      "learning_rate": 8e-05,
      "loss": 0.4697,
      "step": 496
    },
    {
      "epoch": 37.87,
      "learning_rate": 6e-05,
      "loss": 0.4333,
      "step": 497
    },
    {
      "epoch": 37.94,
      "learning_rate": 4e-05,
      "loss": 0.4223,
      "step": 498
    },
    {
      "epoch": 38.02,
      "learning_rate": 2e-05,
      "loss": 0.4927,
      "step": 499
    },
    {
      "epoch": 38.1,
      "learning_rate": 0.0,
      "loss": 0.4681,
      "step": 500
    },
    {
      "epoch": 38.1,
      "step": 500,
      "total_flos": 2.93793580449792e+17,
      "train_loss": 0.49224569702148435,
      "train_runtime": 5187.0067,
      "train_samples_per_second": 1.542,
      "train_steps_per_second": 0.096
    }
  ],
  "logging_steps": 1.0,
  "max_steps": 500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 39,
  "save_steps": 100,
  "total_flos": 2.93793580449792e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
